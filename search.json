[{"title":"FastDFS单机环境下的搭建","url":"/2019/04/19/2019-04-19-FastDFS%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%90%AD%E5%BB%BA/","content":"\n\nFastDFS简单介绍FastDFS是一个开源的分布式文件系统，主要由跟踪服务器（Tracker Server）、存储服务器（Storage Server）、客户端（client）三部分组成。\nStorage Server以组（Group）为单位组织，一个Group内包含多台Storage机器，数据互为备份，存储空间以Group内容量最小的Storage为准，所以建议Group内的多个Storage尽量配置相同，以免造成存储空间的浪费。\nTracker是FastDFS的协调者，负责管理所有的Storage Server和Group，每个Storage在启动后会连接Tracker，告知自己所属的Group、剩余存储空间等信息，并且和Tracker保持心跳响应。\n正式搭建我搭建这个FastDFS主要是用来进行图片存储，选择的是阿里云的轻量应用服务器，主要是能够以学生身份9.9买到，系统选择的是CentOS 7。\n\n下载并安装libfastcommon\n 如果下载速度慢，可以先看看我的另外一篇文件来提高下载速度，Post not found: 解决浏览器访问GitHub和git-clone龟速的问题 链接奉上。\n wget https://github.com/happyfish100/libfastcommon/archive/V1.0.7.tar.gztar -zxvf V1.0.7.tar.gz\n 进入解压出来的文件夹libfastcommon-1.0.7，执行编译与安装。\n cd libfastcommon-1.0.7make.shmake.sh install\n\n下载并安装FastDFS\n wget https://github.com/happyfish100/fastdfs/archive/V5.05.tar.gztar -zxvf V5.05.tar.gzcd fastdfs-5.05make.shmake.sh install\n 安装完成后，会在系统&#x2F;etc&#x2F;fdfs&#x2F;目录下生成两个启动脚本（fdfs_tracker, fdfs_storage）和三个配置模板文件（client.conf.sample, storage.conf.sample, tracker.conf.sample），另外附带安装的还有一些命令行工具，比如用于测试文件上传的fdfs_upload_file等。\n\nTracker参数配置\n 配置文件在&#x2F;etc&#x2F;fdfs&#x2F;下，需要自行将tracker.conf.sample模板拷贝并重命名为tracker.conf。配置文件主要修改如下几项配置：\n # 配置文件是否不生效，false 为生效disabled=false# 提供服务的端口port=22122# Tracker数据和日志目录地址(这里指定的路径要保证存在)base_path=/home/eva/fastdfs/tracker# HTTP 服务端口http.server_port=80\n\nstorage参数配置 操作同步骤3类似，不过这次操作的是storage配置文件，主要修改的参数如下：\n # 配置文件是否不生效，false 为生效disabled=false # 指定此 storage server 所在 组(卷)group_name=group1# storage server 服务端口port=23000# 心跳间隔时间，单位为秒 (这里是指主动向tracker server发送心跳)heart_beat_interval=30# Storage 数据和日志目录地址(需要确保指定路径存在)base_path=/home/eva/fastdfs/tracker# 存放文件时storage server支持多个路径。这里配置存放文件的基路径数目，通常只配一个目录。store_path_count=1# 逐一配置store_path_count个路径，索引号基于0。# 如果不配置store_path0，那它就和base_path对应的路径一样(上传的文件就存储在这个目录，需要保证存在)。store_path0=/home/eva/fastdfs/path0# FastDFS 存储文件时，采用了两级目录。这里配置存放文件的目录个数。 # 如果本参数只为N（如： 256），那么storage server在初次运行时，会在store_path下自动创建N * N个存放文件的子目录。subdir_count_per_path=256tracker_server 的列表 ，会主动连接 tracker_server# 有多个 tracker server 时，每个 tracker server 写一行tracker_server=ali:22122# 允许系统同步的时间段 (默认是全天) 。一般用于避免高峰同步产生一些问题而设定。sync_start_time=00:00sync_end_time=23:59# 访问端口http.server_port=80\n\n修改client.conf配置文件\n# Client 的数据和日志目录(同样需要保证路径存在)base_path=/home/eva/fastdfs/client# Tracker端口tracker_server=ali:22122\n\n开放服务端口 主要是开放三个端口 22122， 23000， 80，我这里使用的是CentOS 7操作系统，相应的指令为：\n firewall-cmd --zone=public --add-port=端口号/tcp --permanet\n 另外要注意的是，如果你使用的是云服务器，那么还需要配置云端防火墙规则，比如我的阿里云服务器配置规则如下：\n \n\n启动测试 分别启动tracker和storage服务，指令如下：\n fdfs_trackerd /etc/fdfs/tracker.conf startfdfs_storaged /etc/fdfs/storage.conf start\n 查看服务启动情况(root身份下执行)：\n netstat -anp | grep fdfs\n 出现下图所示结果，便说明服务启动成功。\n \n 测试文件上传，执行如下命令，会返回一个存储路径，记下这个路径，然后前往你在storage.conf文件中配置的store_path0&#x2F;data&#x2F;目录下，查看返回的路径下是否有你刚刚上传的文件，如果有，则说明上传是没有问题的。\n /usr/bin/fdfs_upload_file 待上传文件的路径\n\n测试下载 下载需要借助于nginx服务器，所以我们先安装nginx，过程中缺少的安装环境请通过包管理工具自行安装解决。\n\n下载并安装nginx，执行如下指令执行即可(过程可能需要以root身份执行)。\n  # 下载wget -c https://nginx.org/download/nginx-1.12.1.tar.gz# 解压tar -zxvf nginx-1.12.1.tar.gz# 配置cd nginx-1.12.1configure# 编译安装makemake install\n  操作完成后，如果执行\n  /usr/local/nginx/sbin/nginx -V\n  出现下图结果，则表示nginx安装成功。\n  \n\n为nginx安装FastDFS模块\n\n对fastdfs-nginx-module 的说明：FastDFS 通过 Tracker 服务器，将文件放在 Storage 服务器存储， 但是同组存储服务器之间需要进行文件复制，有同步延迟的问题。 假设 Tracker 服务器将文件上传到192.168.51.128，上传成功后文件 ID已经返回给客户端。此时 FastDFS 存储集群机制会将这个文件同步到同组存储服务器192.168.51.129上，在文件还没有复制完成的情况下，客户端如果用这个文件 ID 在 192.168.51.129 上取文件,就会出现文件无法访问的错误。而 fastdfs-nginx-module 可以重定向文件链接到源服务器取文件，避免客户端由于复制延迟导致的文件无法访问错误。\n\n  a. 下载解压重命名  # 下载wget https://github.com/happyfish100/fastdfs-nginx-module/archive/5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip# 解压unzip 5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip# 重命名mv fastdfs-nginx-module-5e5f3566bbfa57418b5506aaefbe107a42c9fcb1  fastdfs-nginx-module-master  b .在Nginx中添加FastDFS模块  # 进入解压包目录cd /softpackages/nginx-1.12.1/# 添加模块./configure --add-module=../fastdfs-nginx-module-master/src# 重新编译、安装make &amp;&amp; make install  c. 查看添加的FastDFS模块  /usr/local/nginx/sbin/nginx -V\n  \n  d. 复制 fastdfs-nginx-module 源码中的配置文件到&#x2F;etc&#x2F;fdfs 目录， 并修改  # 复制cd /softpackages/fastdfs-nginx-module-master/srccp mod_fastdfs.conf /etc/fdfs/  # 连接超时时间connect_timeout=10# Tracker Servertracker_server=ali:22122# StorageServer 默认端口storage_server_port=23000# 如果文件ID的uri中包含/group**，则要设置为trueurl_have_group_name = true# Storage 配置的store_path0路径，必须和storage.conf中的一致store_path0=/home/eva/fastdfs/path0  e. 复制FastDFS的部分配置文件到&#x2F;etc&#x2F;fdfs目录  cd /softpackages/fastdfs-5.05/conf/cp http.conf /etc/fdfs/cp mime.types /etc/fdfs/  f. 为nginx添加一条FastDFS的路由映射(即在80端口Server节点下添加以下内容)  vi /usr/local/nginx/conf/nginx.conf  # 将这个内容加在80端口的server节点下location ~/group([0-9])/M00 &#123;     ngx_fastdfs_module;&#125;\n  \n\n启动Nginx（需要以root身份执行），测试下载\n  # 启动Nginx服务器nginx -s start# 查看监听状态netstat -anpt | grep nginx\n\n  在浏览器输入如下地址，查看下载结果。\n  http:&#x2F;&#x2F;服务器IP地址&#x2F;group1&#x2F;上传文件时返回的相应地址\n\n\n\n\n参考\n分布式文件系统FastDFS设计原理\n\n用FastDFS一步步搭建文件管理系统\n\n\n","categories":["后端开发"],"tags":["FastDFS","Linux"]},{"title":"解决浏览器访问GitHub和git clone龟速的问题","url":"/2019/04/19/2019-04-19-%E8%A7%A3%E5%86%B3%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AE%BF%E9%97%AEGitHub%E5%92%8Cgit-clone%E9%BE%9F%E9%80%9F%E7%9A%84%E9%97%AE%E9%A2%98/","content":"\n\n写在前面只是一些吐槽，咱们大天朝屏蔽掉一些负面信息的网站都能理解，为什么作为代码托管网站的GitHub也要躺着中枪呢？？因为下面的内容需要用到一些翻墙的技巧，所以不会的小伙伴还请先自行搜寻方法，由于可能违反相关规定，我这里不进行说明。\n正文GitHub主要是有两个方面的慢，一是通过浏览器进行GitHub网站的访问，巨慢有木有？？然后就是通过命令行工具进行clone操作时，正常情况下，我是没有高过10KB&#x2F;s的。（关于这两种情况，只是我自己的理解，也不知道对不对，但是以下内容亲测有效）。\n\n通过浏览器访问GitHub慢\n  解决这个问题需要修改host文件，在其中加入如下两行即可。注意根据你所在地区的不同，下面的两个ip还需要你根据查询的情况进行适当的修改才行，顺带附上查询地址（如果失效自行搜索）。\n  192.30.253.113  github.com151.101.185.194 global-ssl.fastly.netgithub.com\n\n通过git clone命令行慢  根据我的理解，经过上述操作后，按理说git clone的速度应该就能得到保障的，但是实测的效果是速度基本没有提升。这样的话，我们就需要一部梯子，然后git通过内部代理走梯子来加速clone的速度。具体只需要在命令行执行如下两条指令即可，注意这里的端口号要根据自己的翻墙工具实际设置的端口来进行修改。下图就是我的翻墙工具的实际端口（这里一定要用Socks5的端口，因为我的电脑使用http的端口，速度是没有提升的）。\n  \n  git config --global http.proxy socks5://127.0.0.1:1086git config --global https.proxy socks5://127.0.0.1:1086\n  上述两条指令执行后，可以通过通过查看~&#x2F;.gitconfig中的内容来确定是否设置代理成功，出现如下两个新增项就代表设置成功，快去体验一下满速的git clone吧。\n  [http]    proxy = socks5://127.0.0.1:1086[https]    proxy = socks5://127.0.0.1:1086\n\n问题这里的Socks5是个什么东西呢？有时间了了解一下。\n","categories":["小技巧"],"tags":["Git"]},{"title":"Java开发常用工具类汇总","url":"/2019/04/20/2019-04-20-Java%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%B1%87%E6%80%BB/","content":"\n\n前言用于记录一些常用的工具类，方便以后使用时的查找。各位小伙伴如果有什么其他的推荐，还请在文章末尾留言哈。\n正文\n编解码相关，比如MD5、BASE64\n  &lt;dependency&gt;    &lt;groupId&gt;commons-codec&lt;/groupId&gt;    &lt;artifactId&gt;commons-codec&lt;/artifactId&gt;    &lt;version&gt;1.10&lt;/version&gt;&lt;/dependency&gt;\n\n基础通用操作相关，比如字符串操作、日期操作\n  &lt;dependency&gt;    &lt;groupId&gt;commons-lang&lt;/groupId&gt;    &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;    &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt;\n\n文件IO操作，如删除文件、删除目录、拷贝文件\n  &lt;dependency&gt;    &lt;groupId&gt;commons-io&lt;/groupId&gt;    &lt;artifactId&gt;commons-io&lt;/artifactId&gt;    &lt;version&gt;2.4&lt;/version&gt;&lt;/dependency&gt;\n\nJavaBean操作，可以省去getter、setter方法\n  &lt;dependency&gt;    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;    &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt;\n\nJson操作相关\n  &lt;dependency&gt;    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;    &lt;version&gt;1.2.31&lt;/version&gt;&lt;/dependency&gt;\n\nYaml文件操作相关\n  &lt;dependency&gt;    &lt;groupId&gt;org.yaml&lt;/groupId&gt;    &lt;artifactId&gt;snakeyaml&lt;/artifactId&gt;    &lt;version&gt;1.10&lt;/version&gt;&lt;/dependency&gt;\n\n\n未完待续~~","categories":["开发工具"],"tags":["Maven"]},{"title":"通过FastDFS的Java客户端上传图片连接超时的解决过程","url":"/2019/04/20/2019-04-20-%E9%80%9A%E8%BF%87FastDFS%E7%9A%84Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E8%BF%9E%E6%8E%A5%E8%B6%85%E6%97%B6%E7%9A%84%E8%A7%A3%E5%86%B3%E8%BF%87%E7%A8%8B/","content":"\n\n问题描述在 Post not found: FastDFS单机环境下的搭建 FastDFS单机环境下的搭建 这篇文章中，我搭建了一个 FastDFS 图片服务器，这里我通过FastDFS提供的命令行工具进行文件上传是成功的，然后就是测试一下通过Java客户端来进行图片的上传操作，很遗憾测试没有通过，控制台打印如下错误信息：\njava.net.SocketTimeoutException: connect timed out\tat java.net.PlainSocketImpl.socketConnect(Native Method)\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\tat java.net.Socket.connect(Socket.java:589)\tat org.csource.fastdfs.ClientGlobal.getSocket(ClientGlobal.java:208)\tat org.csource.fastdfs.StorageServer.&lt;init&gt;(StorageServer.java:43)\tat org.csource.fastdfs.TrackerClient.getStoreStorage(TrackerClient.java:144)\tat org.csource.fastdfs.StorageClient.newWritableStorageConnection(StorageClient.java:1627)\tat org.csource.fastdfs.StorageClient.do_upload_file(StorageClient.java:639)\tat org.csource.fastdfs.StorageClient.upload_file(StorageClient.java:120)\tat org.csource.fastdfs.StorageClient.upload_file(StorageClient.java:91)\tat org.csource.fastdfs.StorageClient.upload_file(StorageClient.java:73)\tat org.csource.fastdfs.StorageClient1.upload_file1(StorageClient1.java:64)\tat com.eva.utils.FastDFSClient.uploadFile(FastDFSClient.java:36)\tat com.eva.utils.FastDFSClient.uploadFile(FastDFSClient.java:41)\tat com.eva.fastdfs.TestFastDFS.testFastDfsClient(TestFastDFS.java:34)\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\tat java.lang.reflect.Method.invoke(Method.java:498)\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n\n问题分析\n我的 FastDFS 搭建在阿里云服务器上，公网IP地址为 119.23.247.86。\n\n通过打印的 stack dump 信息，可以看到最终报错点是个native方法，native方法对于我来说就是一个黑盒，我只能是跟踪他的上一级调用，通过打一个断点进行调试可以看到此方法为 java.net.AbstractPlainSocketImpl.socketConnect(address, port, timeout)，它有三个参数，当前调试的值如下图：\n\njava.net.AbstractPlainSocketImpl\n\n\n可以看到当前的端口为 22122 ，也就是说这里将要连接 Tracker 服务器，貌似没啥问题啊？那就直接下一步，发现被调用的 native 方法并没有抛出异常，并且顺利的执行到了 java.net.AbstractPlainSocketImpl.socketConnect(address, port, timeout) 的下一行，控制台也没有任何异常信息，现象如下图：\n\njava.net.AbstractPlainSocketImpl\n\n\n这就说明并不是Java客户端和tracker建立连接发生错误，于是全速执行，发现代码又重新的停在了 java.net.AbstractPlainSocketImpl.socketConnect(address, port, timeout) 处，现象如下：\n\njava.net.AbstractPlainSocketImpl\n\n\n注意了！！ address 变成了 172.17.45.253，这个值怎么跟跟我的阿里云服务器公网地址不一样呢？另外 port 变成了 23000 这就说明当前是在与 storage 进行连接，先不管那么多，直接下一步看看能不能通过吧，现象如下：\n\njava.net.AbstractPlainSocketImpl\n\n\n可以看到代码是直接跳到了 finally 代码块，这就说明在 native 方法的执行过程中发生了异常，根据传入的参数可以推断，port 是么有问题的，唯一的可能就是 address ，毕竟他竟然不是我的阿里云服务器公网地址，那么为什么会出现这个地址呢？在我的 .properties 等相关配置文件中，都没有出现过这个可疑的 ip 地址，所以下一步就是来排查这个可疑的 ip 地址的来源了。\n通过 debug 过程的 stack dump 信息，进行往下跟踪（毕竟是个方法栈嘛~~），可以看到这个可疑的 ip 地址是通过 \norg.csource.fastdfs.TrackerClient#getStoreStorage(org.csource.fastdfs.TrackerServer, java.lang.String) \n\n这个函数的\nip_addr = new String(pkgInfo.body, ProtoCommon.FDFS_GROUP_NAME_MAX_LEN, ProtoCommon.FDFS_IPADDR_SIZE - 1).trim();\n\n这行代码构造出来的，里边的关键参数就是 pkgInfo.body，这个参数是通过当前方法的\nProtoCommon.RecvPackageInfo pkgInfo = ProtoCommon.recvPackage(trackerSocket.getInputStream(), ProtoCommon.TRACKER_PROTO_CMD_RESP, ProtoCommon.TRACKER_QUERY_STORAGE_STORE_BODY_LEN);\n\n构建的，这里的 trackerSocket.getInputStream() 是一个流对象，并且是从 trackerSocket 中获取的，于是猜测可疑 ip 就是通过 tracker 服务器传输过来的，现在我们需要深入这行代码，探究具体的接收过程，详细的操作在下边这个方法中执行。\npublic static RecvPackageInfo recvPackage(InputStream in, byte expect_cmd, long expect_body_len) throws IOException &#123;    // 输入流中数据的    RecvHeaderInfo header = recvHeader(in, expect_cmd, expect_body_len);    if (header.errno != 0) &#123;      return new RecvPackageInfo(header.errno, null);    &#125;    // 存储数据流中的数据    byte[] body = new byte[(int) header.body_len];    int totalBytes = 0;    int remainBytes = (int) header.body_len;    int bytes;    while (totalBytes &lt; header.body_len) &#123;      // 将流中的数据读入到boby中      if ((bytes = in.read(body, totalBytes, remainBytes)) &lt; 0) &#123;        break;      &#125;      totalBytes += bytes;      remainBytes -= bytes;    &#125;    if (totalBytes != header.body_len) &#123;      throw new IOException(&quot;recv package size &quot; + totalBytes + &quot; != &quot; + header.body_len);    &#125;    // 将body封装成RecvPackageInfo    return new RecvPackageInfo((byte) 0, body);  &#125;\n\n代码还是很简单的，这个方法返回后就是通过 RecvPackageInfo 来构造这个可疑的 storage 的 ip 地址了。\n既然可疑的 ip 地址来自 trackerSockt 的输入流，为什么 tracker 会返回这个 ip 地址呢？立即联想到这个 ip 可能是阿里云服务器的内网地址，于是进行查看，与所想一样，那么现在可以将问题缩小到 tracker 误将服务器的内网地址当公网地址返回给客户端了，于是核验 tracker 和 storage 配置文件，果然是自己在进行配置时，误将内网地址填写为了公网地址。\n总结\ntcp、ip、udp 相关的知识又淡忘了，抽空复习一下 tcp 拥塞控制、慢启动相关的内容。\n这里的公网 ip、内网 ip 啥意思呢？类似于虚拟机通过 nat 组网的那种模式吗？宿主机的 ip 地址就是公网ip，和虚拟机相连的那块虚拟网卡分配的 ip 为内网 ip？\n\n","categories":["后端开发"],"tags":["FastDFS","Java"]},{"title":"Git常用指令总结","url":"/2019/04/24/2019-04-24-Git%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E6%80%BB%E7%BB%93/","content":"\n\n前言自己在学习 Git 过程中摘录下来的一些常用指令，方便自己今后需要使用时进行查询，学习的途径主要是两个，在下面给出链接。\n廖雪峰老师Git教程\nGit版本视屏教程\n集中式 VS 分布式\n集中式\n\n必须联网才能工作，如果在局域网内还好，带宽够大，速度够快，可如果在互联网上，遇到网速慢的话，可能提交一个10M的文件就需要5分钟。\n\n必须存在中央服务器，干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。\n\n安全性不高，因为存在中央服务器，如果服务器出故障，将会导致整个版本控制系统崩溃。\n\n\n\n分布式\n\n分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。\n\n分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。\n\n\n\n\n常用 Git 指令\n创建 Git 版本库\n$ git init\n\n将文件添加到 Git 版本库\n$ git add\n\n提交更改内容\n$ git commit -m &quot;提交信息&quot;\n\n查看版本库状态\ngit status\n\n查看文件修改的内容\n$ git diff 文件名\n\n查看 Git 提交日志\n$ git log --oneline --graph\n\n版本回退\n# --hard 选项会导致代码也会被修改到版本ID时刻# HEAD^ 表示上一个版本，HEAD^^ 表示上上一个版本$ git reset --hard 版本ID号$ git reset --hard HEAD^\n\n查看历史命令，用来确定期望的回退版本号\n$ git reflog\n\n丢弃工作区的修改，即让文件回到最近一次 git commit 或 git add 时的状态，这个指令有时也可以用来作为恢复误删的文件\n  $ git checkout -- 文件名# git reset 命令既可以回退版本，也可以把暂存区的修改回退到工作区。$ git reset HEAD 文件名\n\n删除版本库中的文件\n$ git rm 文件名\n\n添加远程仓库\n$ git remote add 别名 远程仓库地址\n\n查看远程仓库信息\n$ git remote -v\n\n推送指定分支到远程仓库\n$ git push 远程仓库（别名） 分支名\n\n指定本地分支与远程分支的链接，未指定将会导致 git pull 失败\n  $ git branch --set-upstream-to 本地分支名 远程分支# 例如$ git branch --set-upstream-to dev origin/dev\n\n拉取远程仓库指定分支到本地\n$ git pull\n\n拷贝远程仓库全部分支到本地\n$ git clone 远程仓库地址\n\n创建并切换分支\n  $ git checkout -b 分支名字# 相当于以下两条命令$ git branch dev$ git checkout dev\n\n切换分支，需要分支存在\n$ git branch dev\n\n查看当前分支\n$ git branch\n\n合并目标分支到当前分支\n$ git merge 目标分支\n\n删除指定分支\n$ git branch -d 分支名\n\n临时存储当前工作现场\n$ git stash\n\n查看存储的工作现场\n$ git stash list\n\n恢复工作现场\n$ git stash pop# 上述指令等价于$ git stash apply$ git stash drop\n\n变基\n$ git rebase\n\n打一个新标签\n$ git tag v1.0\n\n查看所有标签\n$ git tag\n\n为指定提交打标签\n$ git tag v0.9 提交ID号 -m &quot;消息&quot;\n\n查看标签说明消息\n$ git show &lt;tagname&gt;\n\n删除标签\n$ ggit tag -d v0.1\n\n","categories":["开发工具"],"tags":["Git"]},{"title":"关于TCP你应该知道的那些事儿","url":"/2019/05/02/2019-05-02-%E5%85%B3%E4%BA%8ETCP%E4%BD%A0%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/","content":"\n\n\n本文内容摘录自：\n\nIshs博主的TCP系列文章\nTCP慢启动、拥塞避免、快速重传、快速恢复\n概述及协议头概述一句话就是：TCP是一个面向连接的(connection-oriented)、可靠的(reliable)、字节流式(byte stream)传输协议。\n\n面向连接：在应用TCP协议进行通信之前双方通常需要通过三次握手来建立TCP连接，连接建立后才能进行正常的数据传输，因此广播和多播不会承载在TCP协议上。\n\n可靠性：由于TCP处于多跳通信的IP层之上，而IP层并不提供可靠的传输，因此在TCP层看来就有四种常见传输错误问题，分别是 比特错误(packet bit errors)、包乱序(packet reordering)、包重复(packet duplication)、丢包(packet erasure或称为packet drops)。TCP要提供可靠的传输，就需要有额外的机制处理这几种错误。因此个人理解可靠性体现在三个方面，首先TCP通过超时重传和快速重传两个常见手段来保证数据包的正确传输，也就是说接收端在没有收到数据包或者收到错误的数据包的时候会触发发送端的数据包重传(处理比特错误和丢包)。其次TCP接收端会缓存接收到的乱序到达数据，重排序后在向应用层提供有序的数据(处理包乱序)。最后TCP发送端会维持一个发送”窗口”动态的调整发送速率以适用接收端缓存限制和网络拥塞情况，避免了网络拥塞或者接收端缓存满而大量丢包的问题(降低丢包率)。因此可靠性需要TCP协议具有超时与重传管理、窗口管理、流量控制、拥塞控制等功能。以上内容可以用一个表格进行表示。\n\n\n\n\n\n待解决的问题\n应对的方案\n\n\n\n比特错误，超时丢包\n数据包重传\n\n\n包乱序，包重复\n设置缓存区，统一对接收的一批数据进行处理\n\n\n传输速度过快，导致接收端来不及处理，从而大量丢包，或者致使网络拥塞\n通过发送窗口调整发送速率，以适应接收端缓存限制和网络拥塞状态\n\n\n\n字节流式：应用层发送的数据会在TCP的发送端缓存起来，统一分片(例如一个应用层的数据包分成两个TCP包)或者打包(例如两个或者多个应用层的数据包打包成一个TCP数据包)发送，到接收端的时候接收端也是直接按照字节流将数据传递给应用层(这种情况就会产生数据包的粘包和拆包问题)。\n\nTCP的封装和协议头的格式\n图 1 TCP封装在IP报文中的结构\n\n\n图 2 TCP报文头结构\n\n需要重点关注的字段如下：\n\nTCP源端口(Source Port)：16位的源端口其中包含发送方应用程序对应的端口。源端口和源IP地址标示报文发送端的地址。\n\nTCP目的端口(Destination port)：16位的目的端口域定义传输的目的。这个端口指明报文接收计算机上的应用程序地址接口。\n\n\nTCP的源端口、目的端口、以及IP层的源IP地址、目的IP地址四元组唯一的标识了一个TCP连接，一个IP地址和一个端口号的组合叫做一个endpoint或者socket。也即一对endpoint或者一对socket唯一的标识了一个TCP连接。接收端的TCP层就是根据不同的端口号来将数据包传送给应用层的不同程序，这个过程叫做解复用(demultiplex)。相应的发送端会把应用层不同程序的数据映射到不同的端口号，这个过程叫做复用(multiplex)。\n\nTCP序列号（序列码SN,Sequence　Number）：32位的序列号标识了TCP报文中第一个byte在对应方向的传输中对应的字节序号。当SYN出现，序列码实际上是初始序列码（ISN），而第一个数据字节是ISN+1，单位是byte。比如发送端发送的一个TCP包净荷(不包含TCP头)为12byte，SN为5，则发送端接着发送的下一个数据包的时候，SN应该设置为5+12&#x3D;17。通过系列号，TCP接收端可以识别出重复接收到的TCP包，从而丢弃重复包，同时对于乱序数据包也可以依靠系列号进行重排序，进而对高层提供有序的数据流。另外SYN标志和FIN标志在逻辑上也占用一个byte，当SYN标志位有效的时候，该字段也称为ISN(initial sequence number)，详细请参考后续的TCP连接管理。\n\nTCP应答号(Acknowledgment   Number简称ACK Number或简称为ACK Field)：32位的ACK Number标识了报文发送端期望接收的字节序列。如果设置了ACK控制位，这个值表示一个准备接收的包的序列码，注意是准备接收的包，比如当前接收端接收到一个净荷为12byte的数据包，SN为5，则接收端可能会回复一个确认收到的数据包，如果这个数据包之前的数据也都已经收到了，这个数据包中的ACK Number则设置为12+5&#x3D;17，表示17byte之前的数据都已经收到了。再举一个例子，如果在这个数据包之前有个SN为3，净荷为2byte的数据包丢失，则在接受端接收到这个SN为5的乱序数据包的时候，协议要求接收端必须要回复一个ACK确认包，这个确认包中的Ack Number只能设置为3。\n\n头长(Header Length)：4位包括TCP头大小，指示TCP头的长度，即数据从何处开始。最大为15，单位是32比特(32-bit word)。\n\n保留(Reserved)：4位值域，这些位必须是0。为了将来定义新的用途所保留，其中RFC3540将Reserved字段中的最后一位定义为Nonce标志。后续拥塞控制部分的讲解我们会简单介绍Nonce标志位。\n\n标志(Code Bits)：8位标志位。\n\nCWR(Congestion Window Reduce)：拥塞窗口减少标志被发送主机设置，用来表明它接收到了设置ECE标志的TCP包，发送端通过降低发送窗口的大小来降低发送速率\n\nECE(ECN Echo)：ECN响应标志被用来在TCP3次握手时表明一个TCP端是具备ECN功能的，并且表明接收到的TCP包的IP头部的ECN被设置为11。更多信息请参考RFC793。\n\nURG(Urgent)：该标志位置位表示紧急(The urgent pointer) 标志有效。该标志位目前已经很少使用参考后面流量控制和窗口管理部分的介绍。\n\nACK(Acknowledgment)：取值1代表Acknowledgment Number字段有效，这是一个确认的TCP包，取值0则不是确认包。后续文章介绍中当ACK标志位有效的时候我们称呼这个包为ACK包，使用大写的ACK称呼。\n\nPSH(Push)：该标志置位时，一般是表示发送端缓存中已经没有待发送的数据，接收端不将该数据进行队列处理，而是尽可能快将数据转由应用处理。在处理 telnet 或 rlogin 等交互模式的连接时，该标志总是置位的。\n\nRST(Reset)：用于复位相应的TCP连接。通常在发生异常或者错误的时候会触发复位TCP连接。\n\nSYN(Synchronize)：同步序列编号(Synchronize Sequence Numbers)有效。该标志仅在三次握手建立TCP连接时有效。它提示TCP连接的服务端检查序列编号，该序列编号为TCP连接初始端(一般是客户端)的初始序列编号。在这里，可以把TCP序列编号看作是一个范围从0到4294967295的32位计数器。通过TCP连接交换的数据中每一个字节都经过序列编号。在TCP报头中的序列编号栏包括了TCP分段中第一个字节的序列编号。类似的后续文章介绍中当这个SYN标志位有效的时候我们称呼这个包为SYN包。\n\nFIN(Finish)：带有该标志置位的数据包用来结束一个TCP会话，但对应端口仍处于开放状态，准备接收后续数据。当FIN标志有效的时候我们称呼这个包为FIN包。\n\n\n\n窗口大小(Window Size)：16位，该值指示了从Ack Number开始还愿意接收多少byte的数据量，也即用来表示当前接收端的接收窗还有多少剩余空间。用于TCP的流量控制。\n\n校验位(Checksum)：16位TCP头。发送端基于数据内容计算一个数值，接收端要与发送端数值结果完全一样，才能证明数据的有效性。接收端checksum校验失败的时候会直接丢掉这个数据包。CheckSum是根据伪头+TCP头+TCP数据三部分进行计算的。另外对于大的数据包，checksum并不能可靠的反应比特错误，应用层应该再添加自己的校验方式。\n\n优先指针（紧急,Urgent  Pointer）：16位，指向后面是优先数据的字节，在URG标志设置了时才有效。如果URG标志没有被设置，紧急域作为填充。加快处理标示为紧急的数据段。\n\n选项(Option)：长度不定，但长度必须以是32bits的整数倍。常见的选项包括MSS、SACK、Timestamp等等，后续的内容会分别介绍相关选项。\n\n\n另外我们一般称呼链路层的发出去的数据包为帧(frame)，称呼网络层发给链路层的数据包为包(packet)，称呼传输层发给网络层的数据包为段(segment)。但是正如我们描述所用，段、包、帧也经常统称为数据包或者数据报文。\n对应用层来说TCP是一个双向对称的全双工(full-duplex)协议，也就是说应用层可以同时发送数据和接收数据。这就意味着数据流在一个方向上的传输是独立于另一个方向的传输的，每个方向上都有独立的SN。\n三次握手与四次挥手TCP数据传输一般包含三个阶段，分别是连接建立(setup)、数据传输(established)和连接释放(teardown 也称为cleared 或 terminated)。\n在TCP的连接建立过程中一般需要处理下面三个问题\n\n要使每一方能够确知对方的存在。\n\n要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。\n\n能够对传输实体资源（如缓存大小等）进行分配\n\n\n三次握手三次握手的整个过程如下图所示，一般我们称呼主动发起连接(Active Opener)的一端为客户端(Client)，被动等待连接(Passive Opener)的称为服务器端(Server)。\n\n图 3 TCP三次握手\n\n详细过程：\n\nA和B的初始状态都是关闭状态，B进入LISTEN状态后被动打开，此时B等待接收客户端的SYN包建立连接。\n\nA主动打开时，A 的 TCP 向 B 发出连接请求报文段，其首部中的同步位 SYN &#x3D; 1，选择序号 seq &#x3D; x，表明传送报文时的第一个字节序号是 x，由于SYN标志在逻辑上占用一个系列号，因此实际数据传输的时候，TCP传输的数据中第一个Byte对应的系列号为x+1。这个SYN包发送以后，A则进入SYN_SENT状态，等待B回复ACK确认包。\n\nB 的 TCP 收到连接请求报文段后，则发回确认。B 在确认报文段中应使 SYN &#x3D; 1，使标志位 ACK &#x3D; 1， 其确认号ack &#x3D; x + 1，自己选择的序号 seq &#x3D; y。记得我们之前说过序列号SN实际代表传输了多少比特的数据净荷，实际上在TCP的SYN包中一般并不携带数据，但是由于SYN包和FIN包在协议规定在逻辑上面占1个Byte，因此B在接收到这个SYN包后回复的ack&#x3D;x + 1。后面我们会讲到消耗序列号SN就意味着这个数据包一旦丢失可以进行重传操作，由于SYN消耗一个byte的序列号，因此SYN数据包丢失的时候是会触发重传的。在B收到A的SYN包并且发送ACK确认包后，B则进入SYN_RCVD状态。\n\nA 收到此报文段后向 B 给出确认，其 ACK &#x3D; 1，确认号 ack &#x3D; y + 1。此时A进入ESTABLISHED状态，A 的 TCP 通知上层应用进程，连接已经建立。\n\nB 的 TCP 收到主机 A 的确认后，B也进入ESTABLISHED状态，同时通知其上层应用进程当前TCP 连接已经建立。\n\n\n一般来说上面用来建立连接的初始系列号ISN(即x和y)的值是随机选取的。\n四次挥手数据传输结束后，通信的双方都可释放连接。现在如下图假设A 的应用进程先向其 TCP 发出连接释放报文段，并停止发送数据，主动关闭 TCP连接。则四次挥手的过程如下图所示：\n\n图 4 TCP四次挥手\n\n详细过程：\n\n初始状态下A和B都是处于ESTABLISHED状态，当应用层没有待发数据而指示A关闭TCP连接的时候，A 设置连接释放报文段首部的标志位 FIN &#x3D; 1，ACK&#x3D;1，其序号seq &#x3D; u，确认号ack&#x3D;v，等待 B 的确认。此时A进入FIN_WAIT_1状态\n\nB 收到A的FIN包的时候，发出确认，由于FIN包与SYN包类似都在逻辑上占1byte，因此确认号 ack &#x3D; u + 1，而这个报文段自己的序号 seq &#x3D; v。此时B进入CLOSE_WAIT状态，TCP 服务器进程通知高层应用进程。\n\n当A收到B的ACK确认包后，A进入FIN_WAIT_2状态，关于这个状态我们后续在进一步介绍。\n\n若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。B 设置连接释放报文首部的FIN&#x3D;1，ACK&#x3D;1，报文序列号seq&#x3D;v，确认号ack&#x3D;u+1。此时B进入LAST_ACK状态。\n\nA 收到连接释放报文段后，必须发出确认，在确认报文段中 ACK &#x3D; 1，确认号 ack &#x3D; v + 1，自己的序号 seq &#x3D; u +1。 此时A进入TIME_WAIT状态。在TIME_WAIT状态下，A经过2MSL时间后就进入关闭状态，关于TIME_WAIT状态我们后续进一步介绍。\n\n在B接收到A的确认包后，B立即进入关闭状态。A和B都进入关闭状态后整个TCP连接释放。\n\n\n三次挥手在四次挥手关闭TCP连接的时候，有时会省略第二条ACK消息，只存在第一条FIN消息、第三条FIN+ACK消息以及第四条FIN消息，从上图四次挥手的过程中可以看到其实第二条消息的ACK Number和第三条消息的ACK Number是相同的，省略第二条的时候其实是第三条消息捎带了第二条消息的ACK，后面完整介绍TCP的状态机的时候，会看到这种省略第二条消息的状态消息。\nTCP慢启动、拥塞控制、快速重传、快速回复为了防止网络的拥塞现象，TCP提出了一系列的拥塞控制机制。最初由V. Jacobson在1988年的论文中提出的TCP的拥塞控制由“慢启动(Slow start)”和“拥塞避免(Congestion avoidance)”组成，后来TCP Reno版本中又针对性的加入了“快速重传(Fast retransmit)”、“快速恢复(Fast Recovery)”算法，再后来在TCP NewReno中又对“快速恢复”算法进行了改进，近些年又出现了选择性应答( selective acknowledgement,SACK)算法，还有其他方面的大大小小的改进，成为网络研究的一个热点。\nTCP的拥塞控制主要原理依赖于一个拥塞窗口(cwnd)来控制，在之前我们还讨论过TCP还有一个对端通告的接收窗口(rwnd)用于流量控制。窗口值的大小就代表能够发送出去的但还没有收到ACK的最大数据报文段，显然窗口越大那么数据发送的速度也就越快，但是也有越可能使得网络出现拥塞，如果窗口值为1，那么就简化为一个停等协议，每发送一个数据，都要等到对方的确认才能发送第二个数据包，显然数据传输效率低下。TCP的拥塞控制算法就是要在这两者之间权衡，选取最好的cwnd值，从而使得网络吞吐量最大化且不产生拥塞。\n由于需要考虑拥塞控制和流量控制两个方面的内容，因此TCP的真正的发送窗口&#x3D;min(rwnd, cwnd)。但是rwnd是由对端确定的，网络环境对其没有影响，所以在考虑拥塞的时候我们一般不考虑rwnd的值，我们暂时只讨论如何确定cwnd值的大小。关于cwnd的单位，在TCP中是以字节来做单位的，我们假设TCP每次传输都是按照MSS大小来发送数据的，因此你可以认为cwnd按照数据包个数来做单位也可以理解，所以有时我们说cwnd增加1也就是相当于字节数增加1个MSS大小。\n慢启动最初的TCP在连接建立成功后会向网络中发送大量的数据包，这样很容易导致网络中路由器缓存空间耗尽，从而发生拥塞。因此新建立的连接不能够一开始就大量发送数据包，而只能根据网络情况逐步增加每次发送的数据量，以避免上述现象的发生。具体来说，当新建连接时，cwnd初始化为1个最大报文段(MSS)大小，发送端开始按照拥塞窗口大小发送数据，每当有一个报文段被确认，cwnd就增加1个MSS大小。这样cwnd的值就随着网络往返时间(Round Trip Time,RTT)呈指数级增长，事实上，慢启动的速度一点也不慢，只是它的起点比较低一点而已。我们可以简单计算下：\n开始          —&gt;     cwnd &#x3D; 1\n经过1个RTT后   —&gt;     cwnd &#x3D; 2*1 &#x3D; 2\n经过2个RTT后   —&gt;     cwnd &#x3D; 2*2&#x3D; 4\n经过3个RTT后   —&gt;     cwnd &#x3D; 4*2 &#x3D; 8\n如果带宽为W，那么经过RTT*log2W时间就可以占满带宽。\n拥塞避免从慢启动可以看到，cwnd可以很快的增长上来，从而最大程度利用网络带宽资源，但是cwnd不能一直这样无限增长下去，一定需要某个限制。TCP使用了一个叫慢启动门限(ssthresh)的变量，当cwnd超过该值后，慢启动过程结束，进入拥塞避免阶段。对于大多数TCP实现来说，ssthresh的值是65536(同样以字节计算)。拥塞避免的主要思想是加法增大，也就是cwnd的值不再指数级往上升，开始加法增加。此时当窗口中所有的报文段都被确认时，cwnd的大小加1，cwnd的值就随着RTT开始线性增加，这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。\n上面讨论的两个机制都是没有检测到拥塞的情况下的行为，那么当发现拥塞了cwnd又该怎样去调整呢？\n首先来看TCP是如何确定网络进入了拥塞状态的，TCP认为网络拥塞的主要依据是它重传了一个报文段。上面提到过，TCP对每一个报文段都有一个定时器，称为重传定时器(RTO)，当RTO超时且还没有得到数据确认，那么TCP就会对该报文段进行重传，当发生超时时，那么出现拥塞的可能性就很大，某个报文段可能在网络中某处丢失，并且后续的报文段也没有了消息，在这种情况下，TCP反应比较“强烈”：\na. 把ssthresh降低为cwnd值的一半。\nb. 把cwnd重新设置为1。\nc. 重新进入慢启动过程。\n从整体上来讲，TCP拥塞控制窗口变化的原则是AIMD原则，即加法增大、乘法减小。可以看出TCP的该原则可以较好地保证流之间的公平性，因为一旦出现丢包，那么立即减半退避，可以给其他新建的流留有足够的空间，从而保证整个网络的公平性。\n快速重传其实TCP还有一种情况会进行重传：那就是收到3个相同的ACK。TCP在收到乱序到达包时就会立即发送ACK，TCP利用3个相同的ACK来判定数据包的丢失，此时进行快速重传，快速重传做的事情有：\na. 把ssthresh设置为cwnd的一半。\nb. 把cwnd再设置为ssthresh的值(具体实现有些为ssthresh+3)。\nc. 重新进入拥塞避免阶段（即加法递增的阶段）。\n快速回复后来的“快速恢复”算法是在上述的“快速重传”算法后添加的，当收到3个重复ACK时，TCP最后进入的不是拥塞避免阶段，而是快速恢复阶段。快速重传和快速恢复算法一般同时使用。快速恢复的思想是“数据包守恒”原则，即同一个时刻在网络中的数据包数量是恒定的，只有当“老”数据包离开了网络后，才能向网络中发送一个“新”的数据包，如果发送方收到一个重复的ACK，那么根据TCP的ACK机制就表明有一个数据包离开了网络，于是cwnd加1。如果能够严格按照该原则那么网络中很少会发生拥塞，事实上拥塞控制的目的也就在修正违反该原则的地方。\n具体来说快速恢复的主要步骤是：\na. 当收到3个重复ACK时，把ssthresh设置为cwnd的一半，把cwnd设置为ssthresh的值加3，然后重传丢失的报文段，加3的原因是因为收到3个重复的ACK，表明有3个“老”的数据包离开了网络。\nb. 再收到重复的ACK时，拥塞窗口增加1。\nc. 当收到新的数据包的ACK时，把cwnd设置为第一步中的ssthresh的值。原因是因为该ACK确认了新的数据，说明重复ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。\n可以看出Reno的快速重传算法是针对一个包的重传情况的，然而在实际中，一个重传超时可能导致许多的数据包的重传，因此当多个数据包从一个数据窗口中丢失时并且触发快速重传和快速恢复算法时，问题就产生了 (摘抄过来的内容，没太看懂啥意思)。 因此NewReno出现了，它在Reno快速恢复的基础上稍加了修改，可以恢复一个窗口内多个包丢失的情况。具体来讲就是：Reno在收到一个新的数据的ACK时就退出了快速恢复状态了，而NewReno需要收到该窗口内所有数据包的确认后才会退出快速恢复状态，从而更一步提高吞吐量。\n选择性重传SACK（选择性重传）就是改变TCP的确认机制，最初的TCP只确认当前已连续收到的数据，SACK则把乱序等信息会全部告诉对方，从而减少数据发送方重传的盲目性。比如说序号1，2，3，5，7的数据收到了，那么普通的ACK只会确认序列号4，而SACK会把当前的5，7已经收到的信息在SACK选项里面告知对端，从而提高性能，当使用SACK的时候，NewReno算法可以不使用，因为SACK本身携带的信息就可以使得发送方有足够的信息来知道需要重传哪些包，而不需要重传哪些包。\n","categories":["计算机网络"],"tags":["TCP/IP","计算机网络"]},{"title":"MySQL索引背后的数据结构及算法原理","url":"/2019/05/01/2019-05-01-MySQL%E7%B4%A2%E5%BC%95%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/","content":"\n\n\n 本文转载自 MySQL索引背后的数据结构及算法原理\n\n摘要本文以MySQL数据库为研究对象，讨论与数据库索引相关的一些话题。特别需要说明的是，MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，哈希索引，全文索引等等。为了避免混乱，本文将只关注于BTree索引，因为这是平常使用MySQL时主要打交道的索引，至于哈希索引和全文索引本文暂不讨论。\n文章主要内容分为三个部分。\n第一部分主要从数据结构及算法理论层面讨论MySQL数据库索引的数理基础。\n第二部分结合MySQL数据库中MyISAM和InnoDB数据存储引擎中索引的架构实现讨论聚集索引、非聚集索引及覆盖索引等话题。\n第三部分根据上面的理论基础，讨论MySQL中高性能使用索引的策略。\n数据结构及算法基础索引的本质MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。\n我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。\n看一个例子：\n\n图 1\n\n图1展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)的复杂度内获取到相应数据。\n虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。\nB-Tree和B+Tree目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。\nB-Tree为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：\n\nd为大于1的一个正整数，称为B-Tree的度。\n\nh为一个正整数，称为B-Tree的高度。\n\n每个非叶子节点由n-1个key和n个指针组成，其中d&lt;&#x3D;n&lt;&#x3D;2d。\n\n每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。\n\n所有叶节点具有相同的深度，等于树高h。\n\nkey和指针互相间隔，节点两端是指针。\n\n一个节点中的key从左到右非递减排列。\n\n所有节点组成树结构。\n\n每个指针要么为null，要么指向另外一个节点。\n\n如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)，其中v(key1)为node的第一个key的值。\n\n如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)，其中v(keym)为node的最后一个key的值。\n\n如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)。\n\n\n图2是一个d&#x3D;2的B-Tree示意图。\n\n图 2\n  \n由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：\nBTree_Search(node, key) &#123;    if(node == null) return null;    foreach(node.key)    &#123;        if(node.key[i] == key) return node.data[i];            if(node.key[i] &gt; key) return BTree_Search(point[i]-&gt;node);    &#125;    return BTree_Search(point[i+1]-&gt;node);&#125;data = BTree_Search(root, my_key);\n\n关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为logd((N+1)&#x2F;2)，检索一个key，其查找节点个数的渐进复杂度为O(logdN)。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。\nB+TreeB-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。\n与B-Tree相比，B+Tree有以下不同点：\n\n每个节点的指针上限为2d而不是2d+1。\n\n内节点不存储data，只存储key；叶子节点不存储指针。\n\n图3是一个简单的B+Tree示意。\n\n\n\n图 3\n\n由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。\n一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。\n带有顺序访问指针的B+Tree一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。\n\n图 4\n\n如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。\n这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。\n为什么使用B-Tree（B+Tree）上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-&#x2F;+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-&#x2F;+Tree作为索引的理论基础。\n一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I&#x2F;O消耗，相对于内存存取，I&#x2F;O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I&#x2F;O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I&#x2F;O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-&#x2F;+Tree作为索引的效率。\n主存存取原理目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。\n\n图 5\n\n从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。\n主存的存取过程如下：\n当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。\n写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。\n这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。\n磁盘存取原理上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I&#x2F;O操作。与主存不同，磁盘I&#x2F;O存在机械运动耗费，因此磁盘I&#x2F;O的时间消耗是巨大的。\n图6是磁盘的整体结构示意图。\n\n图 6\n\n一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。\n图7是磁盘结构的示意图。\n\n图 7\n  \n盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。\n当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。\n局部性原理与磁盘预读由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I&#x2F;O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：\n当一个数据被用到时，其附近的数据也通常会马上被使用。\n程序运行期间所需要的数据通常比较集中。\n由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I&#x2F;O效率。\n预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。\nB-&#x2F;+Tree索引的性能分析到这里终于可以分析B-&#x2F;+Tree索引的性能了。\n上文说过一般使用磁盘I&#x2F;O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I&#x2F;O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：\n每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I&#x2F;O。\nB-Tree中一次检索最多需要h-1次I&#x2F;O（根节点常驻内存），渐进复杂度为O(h)&#x3D;O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。\n综上所述，用B-Tree作为索引结构效率是非常高的。\n而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I&#x2F;O渐进复杂度也为O(h)，效率明显比B-Tree差很多。\n上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：\n$$dmax&#x3D;floor(pagesize&#x2F;(keysize+datasize+pointsize))$$\nfloor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。\n这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。\nMySQL索引实现在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。\nMyISAM索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：\n\n图 8\n\n这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：\n\n图 9\n\n同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。\nMyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。\nInnoDB索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。\n第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。\n\n图 10\n\n图10是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。\n第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引：\n\n图 11\n\n这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。\n下一章将具体讨论这些与索引有关的优化策略。\n索引使用策略及优化MySQL的优化主要分为结构优化（Scheme optimization）和查询优化（Query optimization）。本章讨论的高性能索引策略主要属于结构优化范畴。本章的内容完全基于上文的理论基础，实际上一旦理解了索引背后的机制，那么选择高性能的策略就变成了纯粹的推理，并且可以理解这些策略背后的逻辑。\n示例数据库为了讨论索引策略，需要一个数据量不算小的数据库作为示例。本文选用MySQL官方文档中提供的示例数据库之一：employees。这个数据库关系复杂度适中，且数据量较大。下图是这个数据库的E-R关系图（引用自MySQL官方手册）：\n\n图 12\n\nMySQL官方文档中关于此数据库的页面为http://dev.mysql.com/doc/employee/en/employee.html。里面详细介绍了此数据库，并提供了下载地址和导入方法，如果有兴趣导入此数据库到自己的MySQL可以参考文中内容。\n最左前缀原理与相关优化高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。\n这里先说一下联合索引的概念。在上文中，我们都是假设索引只引用了单个的列，实际上，MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组&lt;a1, a2, …, an&gt;，其中各个元素均为数据表的一列，实际上要严格定义索引需要用到关系代数，但是这里我不想讨论太多关系代数的话题，因为那样会显得很枯燥，所以这里就不再做严格定义。另外，单列索引可以看成联合索引元素数为1的特例。\n以employees.titles表为例，下面先查看其上都有哪些索引：\nSHOW INDEX FROM employees.titles;+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+| Table  | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Null | Index_type |+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+| titles |          0 | PRIMARY  |            1 | emp_no      | A         |        NULL |      | BTREE      || titles |          0 | PRIMARY  |            2 | title       | A         |        NULL |      | BTREE      || titles |          0 | PRIMARY  |            3 | from_date   | A         |      443308 |      | BTREE      || titles |          1 | emp_no   |            1 | emp_no      | A         |      443308 |      | BTREE      |+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+\n\n从结果中可以到titles表的主索引为&lt;emp_no, title, from_date&gt;，还有一个辅助索引。为了避免多个索引使事情变复杂（MySQL的SQL优化器在多索引时行为比较复杂），这里我们将辅助索引drop掉：\nALTER TABLE employees.titles DROP INDEX emp_no;\n\n这样就可以专心分析索引PRIMARY的行为了。\n情况一：全列匹配。EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND title=&#x27;Senior Engineer&#x27; AND from_date=&#x27;1986-06-26&#x27;;+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref               | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+|  1 | SIMPLE      | titles | const | PRIMARY       | PRIMARY | 59      | const,const,const |    1 |       |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+\n\n很明显，当按照索引中所有列进行精确匹配（这里精确匹配指“&#x3D;”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒：\nEXPLAIN SELECT * FROM employees.titles WHERE from_date=&#x27;1986-06-26&#x27; AND emp_no=&#x27;10001&#x27; AND title=&#x27;Senior Engineer&#x27;;+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref               | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+|  1 | SIMPLE      | titles | const | PRIMARY       | PRIMARY | 59      | const,const,const |    1 |       |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+\n\n效果是一样的。\n情况二：最左前缀匹配。EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27;;+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 |       |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+\n\n当查询条件精确匹配索引的左边连续一个或几个列时，如或&lt;emp_no, title&gt;，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。\n情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND from_date=&#x27;1986-06-26&#x27;;+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra       |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 | Using where |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+\n\n此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引&lt;emp_no, from_date&gt;，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。\n首先我们看下title一共有几种不同的值：\nSELECT DISTINCT(title) FROM employees.titles;+--------------------+| title              |+--------------------+| Senior Engineer    || Staff              || Engineer           || Senior Staff       || Assistant Engineer || Technique Leader   || Manager            |+--------------------+\n\n只有7种。在这种成为“坑”的列值比较少的情况下，可以考虑用“IN”来填补这个“坑”从而形成最左前缀：\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no=&#x27;10001&#x27;AND title IN (&#x27;Senior Engineer&#x27;, &#x27;Staff&#x27;, &#x27;Engineer&#x27;, &#x27;Senior Staff&#x27;, &#x27;Assistant Engineer&#x27;, &#x27;Technique Leader&#x27;, &#x27;Manager&#x27;)AND from_date=&#x27;1986-06-26&#x27;;+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 59      | NULL |    7 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+\n\n这次key_len为59，说明索引被用全了，但是从type和rows看出IN实际上执行了一个range查询，这里检查了7个key。看下两种查询的性能比较：\nSHOW PROFILES;+----------+------------+-------------------------------------------------------------------------------+| Query_ID | Duration   | Query                                                                         |+----------+------------+-------------------------------------------------------------------------------+|       10 | 0.00058000 | SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND from_date=&#x27;1986-06-26&#x27;||       11 | 0.00052500 | SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND title IN ...          |+----------+------------+-------------------------------------------------------------------------------+\n\n“填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。\n情况四：查询条件没有指定索引第一列。EXPLAIN SELECT * FROM employees.titles WHERE from_date=&#x27;1986-06-26&#x27;;+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra       |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+|  1 | SIMPLE      | titles | ALL  | NULL          | NULL | NULL    | NULL | 443308 | Using where |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+\n\n由于不是最左前缀，索引这样的查询显然用不到索引。\n情况五：匹配某列的前缀字符串。EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND title LIKE &#x27;Senior%&#x27;;+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 56      | NULL |    1 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+\n\n此时可以用到索引，但是如果通配符不是只出现在末尾，则无法使用索引。（原文表述有误，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀）\n情况六：范围查询。EXPLAIN SELECT * FROM employees.titles WHERE emp_no &lt; &#x27;10010&#x27; and title=&#x27;Senior Engineer&#x27;;+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 4       | NULL |   16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+\n\n范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no &lt; &#x27;10010&#x27;AND title=&#x27;Senior Engineer&#x27;AND from_date BETWEEN &#x27;1986-01-01&#x27; AND &#x27;1986-12-31&#x27;;+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 4       | NULL |   16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+\n\n可以看到索引对第二个范围索引无能为力。这里特别要说明MySQL一个有意思的地方，那就是仅用explain可能无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询，例如下面的查询：\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no BETWEEN &#x27;10001&#x27; AND &#x27;10010&#x27;AND title=&#x27;Senior Engineer&#x27;AND from_date BETWEEN &#x27;1986-01-01&#x27; AND &#x27;1986-12-31&#x27;;+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 59      | NULL |   16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+\n\n看起来是用了两个范围查询，但作用于emp_no上的“BETWEEN”实际上相当于“IN”，也就是说emp_no实际是多值精确匹配。可以看到这个查询用到了索引全部三个列。因此在MySQL中要谨慎地区分多值匹配和范围匹配，否则会对MySQL的行为产生困惑。\n情况七：查询条件中含有函数或表达式。很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）。例如：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND left(title, 6)=&#x27;Senior&#x27;;+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra       |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 | Using where |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+\n\n虽然这个查询和情况五中功能相同，但是由于使用了函数left，则无法为title列应用索引，而情况五中用LIKE则可以。再如：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no - 1=&#x27;10000&#x27;;+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra       |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+|  1 | SIMPLE      | titles | ALL  | NULL          | NULL | NULL    | NULL | 443308 | Using where |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+\n\n显然这个查询等价于查询emp_no为10001的函数，但是由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。\n索引选择性与前缀索引既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。\n第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。\n另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：\nIndex Selectivity &#x3D; Cardinality &#x2F; #T\n显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。例如，上文用到的employees.titles表，如果title字段经常被单独查询，是否需要建索引，我们看一下它的选择性：\nSELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;+-------------+| Selectivity |+-------------+|      0.0000 |+-------------+\n\ntitle的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。\n有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。下面以employees.employees表为例介绍前缀索引的选择和使用。\n从图12可以看到employees表只有一个索引，那么如果我们想按名字搜索一个人，就只能全表扫描了：\nEXPLAIN SELECT * FROM employees.employees WHERE first_name=&#x27;Eric&#x27; AND last_name=&#x27;Anido&#x27;;+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table     | type | possible_keys | key  | key_len | ref  | rows   | Extra       |+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+|  1 | SIMPLE      | employees | ALL  | NULL          | NULL | NULL    | NULL | 300024 | Using where |+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+\n\n如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建或&lt;first_name, last_name&gt;，看下两个索引的选择性：\nSELECT count(DISTINCT(first_name))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+|      0.0042 |+-------------+SELECT count(DISTINCT(concat(first_name, last_name)))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+|      0.9313 |+-------------+\n\n显然选择性太低，&lt;first_name, last_name&gt;选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如&lt;first_name, left(last_name, 3)&gt;，看看其选择性：\nSELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+|      0.7879 |+-------------+\n\n选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：\nSELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+|      0.9007 |+-------------+\n\n这时选择性已经很理想了，而这个索引的长度只有18，比&lt;first_name, last_name&gt;短了接近一半，我们把这个前缀索引 建上：\nALTER TABLE employees.employeesADD INDEX `first_name_last_name4` (first_name, last_name(4));\n\n此时再执行一遍按名字查询，比较分析一下与建索引前的结果：\nSHOW PROFILES;+----------+------------+---------------------------------------------------------------------------------+| Query_ID | Duration   | Query                                                                           |+----------+------------+---------------------------------------------------------------------------------+|       87 | 0.11941700 | SELECT * FROM employees.employees WHERE first_name=&#x27;Eric&#x27; AND last_name=&#x27;Anido&#x27; ||       90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name=&#x27;Eric&#x27; AND last_name=&#x27;Anido&#x27; |+----------+------------+---------------------------------------------------------------------------------+\n\n性能的提升是显著的，查询速度提高了120多倍。\n前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。\nInnoDB的主键选择与插入优化在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。\n经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。\n上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15&#x2F;16），则开辟一个新的页（节点）。\n如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：\n\n图 13\n\n这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。\n如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：\n\n图 14\n\n此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。\n因此，只要可以，请尽量在InnoDB上采用自增字段做主键。\n后记这篇文章断断续续写了半个月，主要内容就是上面这些了。不可否认，这篇文章在一定程度上有纸上谈兵之嫌，因为我本人对MySQL的使用属于菜鸟级别，更没有太多数据库调优的经验，在这里大谈数据库索引调优有点大言不惭。就当是我个人的一篇学习笔记了。\n其实数据库索引调优是一项技术活，不能仅仅靠理论，因为实际情况千变万化，而且MySQL本身存在很复杂的机制，如查询优化策略和各种引擎的实现差异等都会使情况变得更加复杂。但同时这些理论是索引调优的基础，只有在明白理论的基础上，才能对调优策略进行合理推断并了解其背后的机制，然后结合实践中不断的实验和摸索，从而真正达到高效使用MySQL索引的目的。\n另外，MySQL索引及其优化涵盖范围非常广，本文只是涉及到其中一部分。如与排序（ORDER BY）相关的索引优化及覆盖索引（Covering index）的话题本文并未涉及，同时除B-Tree索引外MySQL还根据不同引擎支持的哈希索引、全文索引等等本文也并未涉及。如果有机会，希望再对本文未涉及的部分进行补充吧。\n参考文献[1] Baron Scbwartz等 著，王小东等 译；高性能MySQL（High Performance MySQL）；电子工业出版社，2010\n[2] Michael Kofler 著，杨晓云等 译；MySQL5权威指南（The Definitive Guide to MySQL5）；人民邮电出版社，2006\n[3] 姜承尧 著；MySQL技术内幕-InnoDB存储引擎；机械工业出版社，2011\n[4] D Comer, Ubiquitous B-tree; ACM Computing Surveys (CSUR), 1979\n[5] Codd, E. F. (1970). “A relational model of data for large shared data banks”. Communications of the ACM, , Vol. 13, No. 6, pp. 377-387\n[6] MySQL5.1参考手册 - http://dev.mysql.com/doc/refman/5.1/zh/index.html\n","categories":["数据库"],"tags":["MySQL","索引","数据结构"]},{"title":"JVM内存区域相关干货","url":"/2019/05/06/2019-05-06-JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E7%9B%B8%E5%85%B3%E5%B9%B2%E8%B4%A7/","content":"\n本文转载自微信公众号：JavaGuide\n\n概述对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像C&#x2F;C++程序开发程序员这样为每一个 new 操作去写对应的 delete&#x2F;free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。\n运行时数据区Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同，下面会介绍到。\nJDK 1.8之前：\n\n\nJDK 1.8：\n\n\n线程私有的：\n\n程序计数器\n\n虚拟机栈\n\n本地方法栈\n\n\n线程共享的：\n\n堆\n\n方法区\n\n直接内存(非运行时数据区的一部分)\n\n\n程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完。\n另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。\n从上面的介绍中我们知道程序计数器主要有两个作用：\n\n字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。\n\n在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。\n\n\n注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。\nJava 虚拟机栈与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。\nJava 内存可以粗糙的区分为堆内存（Heap）和栈内存(Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 （实际上，Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）\n局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。\nJava 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。\nStackOverFlowError： 若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError异常。\nOutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出OutOfMemoryError异常。\nJava 虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。\n扩展：那么方法&#x2F;函数如何调用？\nJava 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入Java栈，每一个函数调用结束后，都会有一个栈帧被弹出。\nJava方法有两种返回方式：\n\nreturn 语句。\n\n抛出异常。\n\n\n不管哪种返回方式都会导致栈帧被弹出。\n本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中本地方法栈和 Java 虚拟机栈合二为一。\n本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。\n方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。\n堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。\nJava 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、From Survivor、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。\n\n\n上图所示的 eden区、s0区、s1区都属于新生代，tentired 区属于老年代。大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden区-&gt;Survivor 区后对象的初始年龄变为1)，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。\nHotSpot 虚拟机中方法区也常被称为 “永久代”，本质上两者并不等价。仅仅是因为 HotSpot 虚拟机设计团队用永久代来实现方法区而已，这样 HotSpot 虚拟机的垃圾收集器就可以像管理 Java 堆一样管理这部分内存了。但是这并不是一个好主意，因为这样更容易遇到内存溢出问题。\n相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。\nJDK 1.8 的时候，方法区被彻底移除了（JDK1.7就已经开始了），取而代之是元空间，元空间使用的是直接内存。\n我们可以使用参数： -XX:MetaspaceSize 来指定元数据区的大小。与永久区很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。\n运行时常量池运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）\n既然运行时常量池时方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。\nJDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。\n\n\n\n图片来源：https://blog.csdn.net/wangbiao007/article/details/78545189\n\n直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。\nJDK1.4 中新加入的 NIO(New Input&#x2F;Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer） 的 I&#x2F;O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。\n本机直接内存的分配不会收到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。\nHotSpot 虚拟机对象探秘通过上面的介绍我们大概知道了虚拟机的内存情况，下面我们来详细的了解一下 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。\n对象的创建下图便是 Java 对象的创建过程，我建议最好是能默写出来，并且要掌握每一步在做什么。\n\n\n①类加载检查： 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程（加载 -&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化 -&gt; 使用 -&gt; 卸载）。\n②分配内存： 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n内存分配的两种方式：\n选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。\n\n\n\n内存分配两种方式\n使用场合\n原理\nGC 收集器\n\n\n\n指针碰撞\n堆内存规整（没有内存碎片）\n将用过的内存和未用过的内存分成两边，中间用分界指针隔开，分配内存时，只需要将该指针移动对象大小即可\nSerial，ParNew\n\n\n空闲列表\n堆内存不规整的情况\n虚拟机维护一个记录内存使用状态的列表，分配内存时，找一个足够大的内存块分配给对象实例，然后更新被维护的列表\nCMS（并发标记清除）\n\n\n\n\n内存分配并发问题:\n在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：\n\nCAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。\n\n为每一个线程预先在Eden区分配一块儿内存，JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配\n\n\n③初始化零值： 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n④设置对象头： 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n⑤执行 init 方法： 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始， 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行  方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。\n对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为3块区域：对象头、实例数据和对齐填充。\nHotspot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。\n实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。\n对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为Hotspot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。\n对象的访问定位建立对象就是为了使用对象，我们的Java程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式有虚拟机实现而定，目前主流的访问方式有句柄和直接指针两种：\n\n句柄：如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；\n\n\n\n\n直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。\n\n\n\n这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。\n重点补充内容String 类和常量池String 对象的两种创建方式：String str1 = &quot;abcd&quot;;String str2 = new String(&quot;abcd&quot;);System.out.println(str1==str2);//false\n\n这两种不同的创建方法是有差别的，第一种方式是在常量池中拿对象，第二种方式是直接在堆内存空间创建一个新的对象。\n\n\n记住：只要使用new方法，便需要创建新的对象。\nString 类型的常量池比较特殊。它的主要使用方法有两种：\n直接使用双引号声明出来的 String 对象会直接存储在常量池中。\n\n如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。 String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用。\n\n\nString s1 = new String(&quot;计算机&quot;);String s2 = s1.intern();String s3 = &quot;计算机&quot;;System.out.println(s2);//计算机System.out.println(s1 == s2);//false，因为一个是堆内存中的String对象一个是常量池中的String对象，System.out.println(s3 == s2);//true，因为两个都是常量池中的String对象\n\nString 字符串拼接String str1 = &quot;str&quot;;String str2 = &quot;ing&quot;;String str3 = &quot;str&quot; + &quot;ing&quot;;//常量池中的对象String str4 = str1 + str2; //在堆上创建的新的对象      String str5 = &quot;string&quot;;//常量池中的对象System.out.println(str3 == str4);//falseSystem.out.println(str3 == str5);//trueSystem.out.println(str4 == str5);//false\n\n\n\n尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。\nString s1 &#x3D; new String(“abc”);这句话创建了几个对象？创建了两个对象。\n验证：\nString s1 = new String(&quot;abc&quot;);// 堆内存的地址值String s2 = &quot;abc&quot;;System.out.println(s1 == s2);// 输出false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。System.out.println(s1.equals(s2));// 输出true\n\n结果：\nfalsetrue\n\n8种基本类型的包装类和常量池Java 基本类型的包装类的大部分都实现了常量池技术，即Byte,Short,Integer,Long,Character,Boolean；这5种包装类默认创建了数值[-128，127]的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。\n两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。\nInteger i1 = 33;Integer i2 = 33;System.out.println(i1 == i2);// 输出trueInteger i11 = 333;Integer i22 = 333;System.out.println(i11 == i22);// 输出falseDouble i3 = 1.2;Double i4 = 1.2;System.out.println(i3 == i4);// 输出false\n\njava.lang.Integer#valueOf(int)的实现就能说明这一点。\n/**  * Returns an &#123;@code Integer&#125; instance representing the specified  * &#123;@code int&#125; value.  If a new &#123;@code Integer&#125; instance is not  * required, this method should generally be used in preference to  * the constructor &#123;@link #Integer(int)&#125;, as this method is likely  * to yield significantly better space and time performance by  * caching frequently requested values.  *  * This method will always cache values in the range -128 to 127,  * inclusive, and may cache other values outside of this range.  *  * @param  i an &#123;@code int&#125; value.  * @return an &#123;@code Integer&#125; instance representing &#123;@code i&#125;.  * @since  1.5  */public static Integer valueOf(int i) &#123;  if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)      return IntegerCache.cache[i + (-IntegerCache.low)];  return new Integer(i);&#125;\n\nInteger i1 = 40; Java 在编译的时候会直接将代码封装成 Integer i1 = Integer.valueOf(40); ，从而使用常量池中的对象。\nInteger i1 = new Integer(40); 这种情况下会创建新的对象。\nInteger i1 = 40;Integer i2 = new Integer(40);System.out.println(i1==i2);//输出false\n\n再看一个例子：\nInteger i1 = 40;Integer i2 = 40;Integer i3 = 0;Integer i4 = new Integer(40);Integer i5 = new Integer(40);Integer i6 = new Integer(0);System.out.println(&quot;i1 = i2   &quot; + (i1 == i2));System.out.println(&quot;i1 = i2+i3   &quot; + (i1 == i2 + i3));System.out.println(&quot;i1 = i4   &quot; + (i1 == i4));System.out.println(&quot;i4 = i5   &quot; + (i4 == i5));System.out.println(&quot;i4 = i5+i6   &quot; + (i4 == i5 + i6));   System.out.println(&quot;40 = i5+i6   &quot; + (40 == i5 + i6));\n\n输出结果：\ni1 = i2   truei1 = i2+i3   truei1 = i4   falsei4 = i5   falsei4 = i5+i6   true40 = i5+i6   true\n\n解释：\n语句i4 &#x3D;&#x3D; i5 + i6，因为+这个操作符不适用于Integer对象，首先i5和i6进行自动拆箱操作，进行数值相加，即i4 &#x3D;&#x3D; 40。然后Integer对象无法与数值进行直接比较，所以i4自动拆箱转为int值40，最终这条语句转为40 &#x3D;&#x3D; 40进行数值比较。\n引用\n《深入理解Java虚拟机：JVM高级特性与最佳实践（第二版》\n《实战java虚拟机》\nhttps://www.cnblogs.com/CZDblog/p/5589379.html\nhttps://www.cnblogs.com/java-zhao/p/5180492.html\nhttps://blog.csdn.net/qq_26222859/article/details/73135660\nhttps://blog.csdn.net/cugwuhan2014/article/details/78038254\n\n","categories":["后端开发"],"tags":["JVM"]},{"title":"几种常用排序算法的Java实现","url":"/2019/05/04/2019-05-04-%E5%87%A0%E7%A7%8D%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84Java%E5%AE%9E%E7%8E%B0/","content":"\n本文中用到的图片来自 如果天空不死\n\n前言对数据排序是一种很基本的需求，各种编程语言都提供了相应的实现，就 Java 语言本身来说，当然也有着相应的类库可以调用，比如说 java.util.Arrays#sort(int[]) ，网上关于排序算法的讲解也很多，我这里也不想多说，仅仅是对各种算法的思想用最简短的方式进行阐述，并提供相应的实现代码。\n正文各种排序算法的时间复杂度、空间复杂度、以及稳定性是面试时经常问到的点，这里也列出一张表方便查询。\n\n\n\n排序方法\n平均情况\n最好情况\n最坏情况\n辅助空间\n稳定性\n\n\n\n冒泡排序\n$O(n^2)$\n$O(n)$\n$O(n^2)$\n$O(1)$\n稳定\n\n\n选择排序\n$O(n^2)$\n$O(n^2)$\n$O(n^2)$\n$O(1)$\n不稳定\n\n\n插入排序\n$O(n^2)$\n$O(n)$\n$O(n^2)$\n$O(1)$\n稳定\n\n\n堆排序\n$O(nlogn)$\n$O(nlogn)$\n$O(nlogn)$\n$O(1)$\n不稳定\n\n\n归并排序\n$O(nlogn)$\n$O(nlogn)$\n$O(nlogn)$\n$O(n)$\n稳定\n\n\n快速排序\n$O(nlogn)$\n$O(nlogn)$\n$O(n^2)$\n$O(logn)$ ~ $O(n)$\n不稳定\n\n\n\n\n下边对表中的六种排序算法的基本原理进行说明，并附上源代码，注意如果不做特殊说明，所有的例子都是将数据按照从小到大进行排序。\n冒泡排序冒泡排序是非常简单的排序算法，他的基本思想是依次交换相邻的数据，使得未排序的元素中的最大值排到最后，经过 n - 1 轮排序后，数列将呈现有序态，当然考虑性能，如果在某一轮交换中，没有出现两个元素交换的情况，这时就说明数据已经是排好序的，即可提前退出循环得到排序的结果。下图是冒泡排序的过程：\n\n可以看到第一趟排序后，最大的元素已经在数列最后了，第二趟对剩下的元素进行同样的交换操作，完成后，第二大的元素排在倒数第二位。依次类推，进行 n - 1 趟排序操作后，数列就是从小到大排列了。\npublic class BubbleSort &#123;    /*     * 冒泡排序     */    public static void bubbleSort1(int[] a) &#123;        int len = a.length;        for (int i = 0; i &lt; len - 1; i++) &#123;            for (int j = 0; j &lt; len - 1 - i; j++) &#123;                // 若不满足递增顺序，交换相邻数据                if (a[j] &gt; a[j + 1]) &#123;                    int t = a[j + 1];                    a[j + 1] = a[j];                    a[j] = t;                &#125;            &#125;        &#125;    &#125;    /*     * 冒泡排序(改进版)     */    private static void bubbleSort2(int[] a) &#123;        int len = a.length; // 标记        boolean flag = false;        for (int i = 0; i &lt; len - 1; i++) &#123;            for (int j = 0; j &lt; len - 1 - i; j++) &#123;                // 若不满足递增顺序，交换相邻数据                if (a[j] &gt; a[j + 1]) &#123;                    int t = a[j + 1];                    a[j + 1] = a[j];                    a[j] = t;                    flag = true;                &#125;            &#125;            if (!flag) break;            flag = false;        &#125;    &#125;    public static void main(String[] args) &#123;        int i;        int[] a = &#123;20, 40, 30, 10, 60, 50&#125;;        System.out.print(&quot;before sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);        bubbleSort2(a);        System.out.print(&quot;after  sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);    &#125;&#125;\n\n选择排序选择排序的思想其实跟冒泡排序有点相似，只是冒泡排序中数据的交换相对频繁，而选择排序只是在确定交换位置后才会进行交换，先看看基本的实现过程：\n\n可以看到整个排序的过程也会进行 n - 1 趟，假设当前是第 i 趟，那么选择排序就是从 i 及之后的所有元素中找到最小的那个元素的位置记为 j，然后将位置 i 和 j 的元素进行交换。这样本趟排序就结束了，接下来进行下一趟的排序操作，执行 n - 1 趟完成后，就得到最终结果。\npublic class SelectSort &#123;    /*     * 选择排序     */    private static void selectSort(int[] a) &#123;        int len = a.length;        int min = Integer.MAX_VALUE;        int pos = 0;        for (int i = 0; i &lt;len - 1; i++) &#123;            for (int j = i; j &lt; len; j++) &#123;                if (a[j] &lt; min) &#123;                    min = a[j];                    pos = j;                &#125;            &#125;            int t = a[pos];            a[pos] = a[i];            a[i] = t;            min = Integer.MAX_VALUE;            pos = i;        &#125;    &#125;    public static void main(String[] args) &#123;        int i;        int[] a = &#123; 20, 40, 30, 10, 60, 50 &#125;;        System.out.print(&quot;before sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);        selectSort(a);        System.out.print(&quot;after  sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);    &#125;&#125;\n\n插入排序插入排序跟选择排序非常相似，他们的区别是：\n\n选择排序 从当前及后续所有的元素中选中最小的那个元素和当前位置的元素进行交换。\n插入排序 将当前位置的元素插入到当前位置之前的所有元素中的一个合适位置。\n\n\n可以看到整个数据分为两个区，当前元素之前的为有序区，后边的为无序区，插入排序就是将当前元素插入到有序区中，如果元素比较多，那么对有序区进行二分查找来确定插入位置，将会极大的提高排序效率。\npublic class InsertSort &#123;    /*     * 直接插入排序     */    private static void insertSort(int[] a) &#123;        int len = a.length;        for (int i = 1; i &lt; len; i++) &#123;            for (int j = i; j &gt; 0; j--) &#123;                // 将 a[j] 放到前面的一个合适的位置                if (a[j] &lt; a[j - 1]) &#123;                    int t = a[j];                    a[j] = a[j - 1];                    a[j - 1] = t;                &#125; else break;            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        int i;        int[] a = &#123;20, 40, 30, 10, 60, 50&#125;;        System.out.print(&quot;before sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);        insertSort(a);        System.out.print(&quot;after  sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);    &#125;&#125;\n\n堆排序堆排序是一种比较复杂的排序方式，它利用了一种叫做二叉堆的数据结构（还有其它类型的堆结构，如果想要深入了解，请参看这篇博文），所以在介绍堆排序之前我们需要先简单了解下二叉堆这种数据结构。\n二叉堆基本概念及性质二叉堆是完全二元树或者是近似完全二元树，按照数据的排列方式可以分为两种：最大堆和最小堆。\n\n最大堆：父结点的键值总是大于或等于任何一个子节点的键值；\n最小堆：父结点的键值总是小于或等于任何一个子节点的键值。\n\n二叉堆一般都通过”数组”来实现，因为二叉堆是个树结构，所以二叉堆有个根节点，根据根节点位于数组的0索引位置还是1索引位置,当前节点的左子节点、右子节点、父节点分为如下两种情况。\n\n\n\n根节点位置\n左子节点\n右子节点\n父节点\n\n\n\n根节点位于索引0\n$2 * i + 1$\n$2 * i + 2$\n$floor((i - 1) &#x2F; 2)$\n\n\n根节点位于索引1\n$2 * i$\n$2 * i + 1$\n$floor(i\\ &#x2F;\\ 2)$\n\n\n根据上面所述，我们就可以得到一个基本的二叉堆结构。因为最小堆和最大堆（最大堆和最小堆只是二叉堆的两种形式，其中最大堆是父节点大于子节点的二叉堆，反之就是最小堆），仅仅只是父子元素大小的区别，这里拿最大堆进行说明。\n\n根节点位于索引0的最大堆\n\n\n根节点位于索引1的最大堆\n\n结合图片中的注释，可以很容易理解最大堆的特性。下面说明一下如何构建一个最大堆。\n最大堆添加元素最大堆的添加操作很容易理解，因为最大堆有着它自己的结构特点，所以在添加元素后需要根据结构特点进行调整，以此来维持最大堆的结构。\n\n最大堆添加元素\n\n根据图解，可以看到最大堆添加元素后的调整操作就是将元素尽可能的往上移，因为最大堆的父节点总是大于子节点的。\n最大堆删除元素最大堆的删除操作思想跟插入一样，但是在调整的过程中考虑的情况有两种，这点和添加元素后的调整操作不一样。原因是添加元素后进行上调是直接和邻近父节点进行对比，邻近父节点只有一个，所以对比一次就行，而删除元素后，数组中就会形成一个空缺，所以用数组的最后一个元素进行填补，这样，填补的元素所处节点的子节点可能会比填补元素大，这样就需要分别和两个子节点元素进行大小对比，以下是删除元素后调整的详细过程。\n\n最大堆删除元素\n\n当从最大堆中删除数据时：先删除该数据，然后用最大堆中最后一个的元素插入这个空位；接着，把这个“空位”尽量往上挪，直到剩余的数据变成一个最大堆。\n利用最大堆进行排序说完了最大堆的性质和添加删除元素操作，接下来就是利用最大堆进行堆排序，核心就是两点：\n\n将所有的元素构建成最大堆。\n将根节点的元素和数组最后的一个元素进行交换，然后对最后一个元素之前的所有元素进行最大堆的重构（类似于删除元素后的调整过程，只是边界条件在变化）。\n\n\n利用最大堆排序数据的过程\n\n因为这个排序过程的右边界一直在变，所以调整的条件较为苛刻，具体的细节请看下边代码中的注释。\npublic class HeapSort &#123;    private static int[] heapSort(int[] a) &#123;        int[] maxHeap = arrToMaxHeap(a);        return sortHeap(maxHeap);    &#125;    /**     * 根据最大堆，对数据进行排序     *     * @param maxHeap 最大堆     * @return 排序结果     */    private static int[] sortHeap(int[] maxHeap) &#123;        int len = maxHeap.length;        for (int i = 0; i &lt; len - 1; i++) &#123;            int tail = len - 1 - i;            // 将未排序序列的首尾元素进行对调            int t = maxHeap[0];            maxHeap[0] = maxHeap[tail];            maxHeap[tail] = t;            // 重构最大堆            int p = 0;            int s;            // 调整首节点，因为上述对调操作后，0 - tail 区间中的数据已经不满足最大堆性质了，需要进行调换来重构最大堆            // 首先需要判断当前节点是否有孩子节点，上界为 ceil，ceil 及以后的序列是已经排好序的。            // 如果当前节点的两个孩子节点其中之一大于当前节点，则进行其中较大的那个节点进行交换，然后将当前节点设置为目标叶子节点。            // 重复上述过程            while ((s = 2 * p + 1) &lt; tail &amp;&amp; (maxHeap[p] &lt; maxHeap[s] || maxHeap[p] &lt; maxHeap[s + 1])) &#123;                // 如果右节点大于左节点，并且右节点没有超过上界 tail 则当前节点和右节点交换                if (maxHeap[s] &lt; maxHeap[s + 1] &amp;&amp; s + 1 &lt; tail) &#123;                    t = maxHeap[p];                    maxHeap[p] = maxHeap[s + 1];                    maxHeap[s + 1] = t;                    p = s + 1;                    continue;                &#125;                // 到这里说明不能跟右孩子交换，则判断是否左孩子满足交换条件                else if (maxHeap[p] &lt; maxHeap[s]) &#123;                    t = maxHeap[p];                    maxHeap[p] = maxHeap[s];                    maxHeap[s] = t;                    p = s;                    continue;                &#125;                break;            &#125;        &#125;        return maxHeap;    &#125;    /**     * 将数组转换为最大堆     *     * @param a 原数组     * @return 得到的最大堆     */    private static int[] arrToMaxHeap(int[] a) &#123;        int len = a.length;        int[] maxHeap = new int[len];        for (int i = 0; i &lt; len; i++) &#123;            maxHeap[i] = a[i];            int s = i;            int p;            // 对加入的数据按规则进行调整            while ((p = (int) Math.floor((s - 1) * 1.0 / 2)) &gt;= 0 &amp;&amp; maxHeap[s] &gt; maxHeap[p]) &#123;                int t = maxHeap[s];                maxHeap[s] = maxHeap[p];                maxHeap[p] = t;                s = p;            &#125;        &#125;        return maxHeap;    &#125;    public static void main(String[] args) &#123;        int i;        int[] a = &#123;30, 40, 60, 10, 20, 50, 70, 25, 33, 12, 90, 100, 87, 59, 39, 101&#125;;        System.out.print(&quot;before sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);        a = heapSort(a);        System.out.print(&quot;after  sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);    &#125;&#125;\n\n归并排序归并排序的核心是将两个有序数列合并为一个有序数列，其基本思路是将所有的元素看成独立的部分，然后两两合并得到一个较大元素，然后再将较大的元素两两合并得到一个更大的部分，依次类推，直到最后只有一个元素，这就是最终排序好的结果，理解这个该过程后，就可以很容易想到利用用递归的思想进行编程。\n\n归并排序基本过程\n\n这里的元素是偶数个，如果元素是基数个，过程也基本类似，只需要记得，递归的终止条件就是两个：\n\n待合并的元素个数为 1，那么就直接返回这个元素。\n待合并的元素个数为 2，那么就将这两个元素排序后直接返回。\n\n关于这两点，请看代码实现。\npublic class MergeSort &#123;    /**     * 递归调用归并排序函数     * @param a 原数组     * @param l 左边界     * @param r 右边界     * @return l 到 r 区间归并排序的结果，返回的是一个新数组     */    private static int[] mergeSort(int[] a, int l, int r) &#123;        int len = r - l + 1;        // 终止条件        if (len == 1) return new int[]&#123;a[l]&#125;;        if (len == 2) return a[l] &gt; a[r] ? new int[]&#123;a[r], a[l]&#125; : new int[]&#123;a[l], a[r]&#125;;        // 否则递归调用归并函数        int[] pre = mergeSort(a, l, l + len / 2 - 1);        int[] post = mergeSort(a, l + len / 2, r);        // 合并排序的结果        return merge(pre, post);    &#125;    // 两个排序数组的合并    private static int[] merge(int[] pre, int[] post) &#123;        int prl = pre.length, pol = post.length;        int poi = 0, pri = 0;        int[] res = new int[prl + pol];        for (int i = 0; i &lt; prl + pol; i++) &#123;//            此处限制条件比较多//            1. 保证 pre 数组的下标 pri 不会越界//            2. post 数组的值已经全部进入 res 数组//            3. pre 数组当前值小于 post 数组的当前值            if (pri != prl &amp;&amp; (poi == pol || pre[pri] &lt; post[poi])) res[i] = pre[pri++];            else res[i] = post[poi++];        &#125;        return res;    &#125;    public static void main(String[] args) &#123;        int i;        int[] a = &#123;30, 40, 60, 10, 20, 50, 70, 25, 33, 12, 90, 100, 87, 59, 39, 101&#125;;        System.out.print(&quot;before sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);//        mergeSortUp2Down(a, 0, a.length - 1);        // 归并排序(从上往下)        a = mergeSort(a, 0, a.length - 1);                    // 归并排序(从下往上)        System.out.print(&quot;after  sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);    &#125;&#125;\n\n快速排序快速排序采用的是分治的策略，大致就是先让数据做到宏观有序，然后缩小范围，在小的范围内再让数据做到宏观有序，这样逐级逼近，直到最后全部有序。基本的流程如下：\n\n从区间范围内的数据中任意取一个数作为参考点。\n将区间内的剩余数据和参考点进行比对，大于参考点的数据往前挪，小于参考点的数据往后移，然后用参考点将前挪和后移的这两部分数据用参考点隔开。\n递归的对前挪和后移的这两部分数据进行上述操作\n\n详细的过程参考下图：\n\n快速排序的基本过程\n\n这里的过程很清晰了，唯一要注意的就是队规的结束条件是区间长度小于 2，详细的请看下边代码实现。\npublic class FastSort &#123;    /*     * 快速排序     */    private static void quickSort(int[] a, int l, int r) &#123;        int ll = l;        int rr = r;        // 参考点        int mid = a[l];        // 将整个数组分成大于和小于 mid 的两个部分，其中 mid 可以任取 l 到 r 区间中的一个值        while (l &lt; r) &#123;            while (a[r] &gt;= mid &amp;&amp; r &gt; l) r--;            if (r &gt; l) a[l] = a[r];            while (a[l] &lt;= mid &amp;&amp; r &gt; l) l++;            if (r &gt; l) a[r] = a[l];        &#125;        a[l] = mid;        // 终止条件判断        if (ll &lt; l - 1) quickSort(a,ll,l - 1);        if (l + 1 &lt; rr) quickSort(a,l + 1,rr);    &#125;    public static void main(String[] args) &#123;        int i;        int[] a = &#123;30, 40, 60, 10, 20, 50, 70, 25, 33, 12, 90, 100, 87, 59, 39, 101&#125;;        System.out.print(&quot;before sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);        quickSort(a, 0, a.length - 1);        System.out.print(&quot;after  sort:&quot;);        for (i = 0; i &lt; a.length; i++)            System.out.printf(&quot;%d &quot;, a[i]);        System.out.print(&quot;\\n&quot;);    &#125;&#125;\n\n结语本文介绍了六种常用的排序算法的思想，并给出了相应的代码实现，因为写这个文章的主要目的是方便自己以后进行回顾，所以内容省略了很多细节的部分，这是建立在我已经了解过那些细节的基础之上，如果你是一名初学者，可能在看这篇文章时会有些模糊不清，那么建议你还是看看本文开头引用中所提到的那位大神的博客，这里也十分感谢大佬的配图。\n","categories":["常用算法"],"tags":["数据结构","常用算法"]},{"title":"让自己的博客使用https协议","url":"/2019/05/07/2019-05-07-%E8%AE%A9%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8https%E5%8D%8F%E8%AE%AE/","content":"前言在构建好自己的博客系统后，就是进行博客的上线了，考虑到国内访问 GitHub 速度较慢，我这里的选择的阿里云的服务器，同时还申请了一个域名。静态资源服务器选择的是 nginx，为什么选择 nginx 呢？emmm…. 只是因为我就知道这个，整个的发布过程还算容易，只是中间有个小细节需要注意，如果你想要你的博客支持 https 协议那么在你的博客页面中，任何的资源请求都必须是 https 的， 否则在浏览器的地址栏前边就会提示不安全的页面。另外由于在 markdown 插入图片是一个非常麻烦的事情，所以在文章中提到了一种通过七牛云做图床，然后快速给 markdown 插入图片的方法。\n添加 https 支持为 nginx 添加 http_ssl_module你能看到这篇文章，相信你已经完成了自己的博客上线了，并且是采用的自己的服务器和域名，因为通 GitHub Page 来部署自己的博客的话，默认就是支持 https 协议的。我的 nginx 是通过源码包安装的，通常在未指定其他参数的情况下，安装的 nginx 是不带 ssl（https 的实现就是基于此）模块的，如果不确定的话，你也可以通过执行 /path/to/nginx/nginx -V 指令进行确认，如果输出结果有 --with-http_ssl_module 相关内容则代码你的 nginx 是支持 https 协议的，否则你需要为已安装的 nginx 添加 http_ssl_module，方法很简单，只需要下载相应版本的 nginx 的源码包，解压后进入源码包，再依次执行下边两条指令即可：\n# 添加 http_ssl_module 模块./configure --with-http_ssl_module# 重新编译，注意不是 make install（会覆盖现在的配置）make\n\n重新执行以下 /path/to/nginx/nginx -V 确认模块添加成功。\n为 nginx 添加 https 证书我的域名也是在阿里云购买的，同时可以在阿里云购买免费的认证证书，按照相应的步骤操作就行了，申请证书完成后就等待申请通过吧，通常都很快，通过后就能把你申请的证书下载下来了，解压后有两个文件，一个是证书文件，另外一个是钥匙串。你需要做的就是将这两个文件上传到你的 nginx 服务器中，随便一个位置就好，后边的 nginx 配置中需要引用这两个文件。\n执行 vim /path/to/nginx.conf/nginx.conf 编辑 nginx 配置文件，修改 HTTPS Server 节点内容如下：\n# HTTPS serverserver &#123;    listen       443 ssl;    server_name  www.aprilyolies.top;   # 自己的域名    charset utf-8;    ssl_certificate      /usr/local/nginx/cert/https.pem; # 自己的证书文件完整路径    ssl_certificate_key  /usr/local/nginx/cert/https.key; # 自己的钥匙串文件完整路径    ssl_session_cache    shared:SSL:1m;    ssl_session_timeout  5m;    ssl_ciphers  HIGH:!aNULL:!MD5;    ssl_prefer_server_ciphers  on;    location / &#123;        root   /home/eva/blog/aprilyolies;  # 博客的完整路径        index  index.html index.htm;    &#125;&#125;\n\n修改完成后执行 nginx -s reload 重启 nginx 服务即可，通过浏览器访问一下你的博客吧，是不是那个熟悉的 https 标志回来了？\n设置重定向规则这里还有个问题，就是访问时必须要指定是 https 协议，否则还是走的 http 协议，这对于电脑小白来说或许是个安全隐患。所以在这里，我们还得为 nginx 加一点配置：\nserver &#123;    listen       80 default_server;    listen       [::]:80 default_server;    server_name  www.aprilyolies.top;    return 301 https://$server_name$request_uri;    #charset koi8-r;    #access_log  logs/host.access.log  main;    location / &#123;        root   /home/eva/blog/aprilyolies;        # root   html;        index  index.html index.htm;    &#125;&#125;\n\n没错，就是在 HTTP Server 节点下加上 return 301 https://$server_name$request_uri; 这样一句，意思就是通过 http 协议进行的请求都重定向到 https 协议之上。这样你再通过浏览器访问时，就一定是使用 https 协议了。 \n再提醒一句：如果你想要你的博客支持 https 协议那么在你的博客页面中，任何的资源请求都必须是 https 的。\n轻松方便的为 markdown 添加图片如果你现在文章的图片还是选择直接保存到自己的服务器，或者说是不反感现在插入图片的那一系列繁琐的过程，那么下边的内容可能就适合你了，但我还是强烈建议你将剩下的内容看完，因为你会爱上这种操作方式的。\n环境说明：我这里使用的是 macOS Mojave 10.14.4 操作系统 + Alfred3 ，如果你使用的是 windows 操作系统，请移步 Windows 版本 markdown 一键贴图工具，另外 mac 用户自行安装 Alfred3 ，并需要支持 PowerPack（就是需要付（Pò）费（jiě）啦）。\n申请七牛云对象存储空间请自行前往七牛云官网注册并进行实名认证，然后你就能得到免费的 10GB 存储空间了，过程很简单，按照提示操作就行。\n添加 CDN 加速域名先介绍一下 CDN（Content Delivery Network），简单来说，CDN 就是一个缓存服务器端资源的特殊网络，这种网络尽可能的避免影响网络传输速率的节点，同时还有负责负载均衡调度的控制中心，以此来保证网络中的资源尽快的到达用户手中。就像遍布全国的零售店，如果没有这些零售店，那么你买任何东西就得去商品的原产地（这个过程有一个专业名词叫“回源”），这样的速度就很慢，而为了提高商品到达你手中的速度，遍布全国的零售店就构成了一个类似的 CDN。\n因为要添加域名，所以首先你需要先得到一个域名，或许你会问我现在不是有一个域名吗，就用这一个可以吗？答案是要看你现在的这个域名是否已经被解析过了，如果没有被解析，那么直接使用就行。那如果解析过了呢？也是有办法的，你可以选择创建一个二级域名，形式如同 xxx.domain.com，如果还是不明白，那就以我的域名举例子。不过在那之前需要先说一下域名解析的两种记录方式：\n\nA 记录：将域名直接映射到一个 IP 地址，由这个 IP 代表的服务器提供服务。\n\nCNAME 记录：将域名映射到另外一个域名，再由这个域名所代表的服务器提供服务。\n\n\n再回到正文，首先我在阿里云备案了一个叫做 www.aprilyolies.top 的域名，不妨称它为一级域名吧，我将它解析为了一条 A 记录，对应的 IP 就是我的服务器的 IP。然后我在这个一级域名下新建一个二级域名，因为主要是用来存放图片，所以取名 image.aprilyolies.top，这就是一个二级域名，注意！！不要带 www 前缀！！不要带 www 前缀！！不要带 www 前缀！！ 重要的事情说三遍。\n说到这里，可能你都晕了，那就总结一下吧，在你申请过七牛云的对象存储服务后，想更进一步的往里边存储文件，那么就需要添加一个域名，当然你也可以使用它提供的那个测试域名，但是有效期只有30天，到期自动失效，所以你需要获取一个新的域名，就是上文中所说的二级域名，然后在七牛云对象存储空间的控制面板点击自定义域名：\n\n\n进入到创建域名界面后，你需要设置几个参数，加速域名，就是二级域名，你自己根据现在的一级域名想一个二级域名即可（如果你现在有多余的一级域名，那也是可以用的哈）。通信协议，一定要选 https 否则你博客的 https 协议就会出问题了，这里会要求你提供证书，就选择七牛云免费为你提供的证书就好，自己有的话也可以自行上传证书。\n这样七牛云这边的配置就 ok 了，创建完成后会返回一个 CNAME 值，这里我将它理解为对应七牛云自家的 CDN 中的一个域名，然后你设置的这个二级域名，就是返回的这个 CNAME 对应域名的别名，剩下你需要做的，就是将这个二级域名映射到这个 CNAME 上， 在你购买域名的平台上进行操作就行了，这里以阿里云为例：\n\n\n\n这样添加 CDN 加速域名就完成了，怎么样？是不是很简单？但是写这么多，只是想让自己更好的理解其中一些相关概念的意思。添加后就需要等待七牛云那边 CNAME 过程完成了，只有提示完成后，才表示真的添加成功。\n安装一键贴图插件先说一下这个插件的原理，其实就是一系列脚本的集合，它借助 Alfred3 这个软件的 workflow 功能来执行这样的脚本集合，可以自定义启动的快捷键。这种脚本使用 osascript 语言编写的，我也不会，幸好有大佬已经将这样的脚本写好并发布到 GitHub 了，这是下载地址，但是其中内容有点问题，我自己改了一下，后边再说。然后因为要上传图片，所以还要借助七牛云官方的开发工具 qshell，也附上下载地址。\n导入 workflow 并修改部分内容导入很简单，将第一个下载链接的内容解压，双击 Qiniu.alfredworkflow 并选择相应分类就好了（提前安装好 Alfred3 带 PowerPack 的版本），然后就会出现一个新的 workflow，其实就是一个工作流，定义了你上传图片时那一系列的繁琐步骤。\n\n\n设置相关的环境变量，点击 Qiniu 右上角第二个按钮，出现如下对话框，根据实际情况填写好保存即可。access_key 和 secret_key 请在你自己的七牛云账户中心中查询，bucket 就是一图中所标注出来的名字，bucketDomain 就是你的二级域名，不要带 www 前缀！！不要带 www 前缀！！不要带 www 前缀！！ 重要的事情再说三遍。\n\n\n修改脚本内容，注意内容中的中文注释，只需要修改其中三行即可。\n-- config startproperty bucket : (system attribute &quot;bucket&quot;)property bucketDomain : (system attribute &quot;bucketDomain&quot;)property AccessKey : (system attribute &quot;AccessKey&quot;)property SecretKey : (system attribute &quot;SecretKey&quot;)-- config end-- md5(date) as file nameset fileName to do shell script &quot;date \\&quot;+%Y%m%d%H%M%S\\&quot; | md5&quot;-- see if clipboard is a fileset filePath to &quot;&quot;try\tset clipPath to the clipboard as «class furl»\tset filePath to clipPath as alias\t-- like &quot;/Users/jverson/Pictures/igarss/IMG_20140720_221838.jpg&quot;\tset filePath to quoted form of POSIX path of filePath\tset filePath to second item of my theSplit(filePath, &quot;&#x27;&quot;)\tset tempArray to my theSplit(filePath, &quot;.&quot;)\t-- like &quot;jpg&quot; or &quot;png&quot; or &quot;gif&quot; or &quot;mp4&quot;\tset fileType to last item of tempArrayend tryif filePath is not &quot;&quot; then\tset fileName to fileName &amp; &quot;.&quot; &amp; fileType\tset markdownUrl to my upload(fileName, filePath, fileType)\treturn markdownUrl --endend if-- see if clipboard is image dataset jpegDATA to &quot;&quot;try\tset jpegDATA to the clipboard as JPEG pictureend tryif jpegDATA is not &quot;&quot; then\tset tempPath to &quot;/tmp/&quot;\tset fileName to fileName &amp; &quot;.jpg&quot;\tset filePath to tempPath &amp; fileName\tset theFile to open for access filePath with write permission\twrite jpegDATA to theFile\tclose access theFile\tset markdownUrl to my upload(fileName, filePath, &quot;jpg&quot;)    -- delete temp file    do shell script &quot;rm &quot; &amp; filePath\treturn markdownUrlend ifbeep 1display dialog ¬\t&quot;No file or image data found on the clipboard.&quot; with icon ¬\tnote buttons &#123;&quot;Whatever&quot;&#125; default button 1return-- string split function-- ref: http://erikslab.com/2007/08/31/applescript-how-to-split-a-string/on theSplit(theString, theDelimiter)\t-- save delimiters to restore old settings\tset oldDelimiters to AppleScript&#x27;s text item delimiters\t-- set delimiters to delimiter to be used\tset AppleScript&#x27;s text item delimiters to theDelimiter\t-- create the array\tset theArray to every text item of theString\t-- restore the old setting\tset AppleScript&#x27;s text item delimiters to oldDelimiters\t-- return the result\treturn theArrayend theSplit-- upload image to qiniuon upload(fileName, filePath, fileType)    -- compress image todo..    -- qiniu account set    // 设置账户信息，原脚本缺少一个用户名参数，导致执行失败，为了简化操作，这里请按如下设置。    set account_commond to &quot;/usr/local/bin/qshell account &quot;    do shell script account_commond    -- upload to qiniu    -- 这里可以设置图片在七牛云的存储路径，默认是在根目录，我这里设置的是在 “static/images/common/” 目录下，可以根据你自己的需求修改。\tset upload_command to &quot;/usr/local/bin/qshell fput &quot; &amp; bucket &amp; &quot; static/images/common/&quot; &amp; fileName &amp; &quot; &quot; &amp; filePath\tdo shell script upload_command    -- strcat url    set resourceUrl to bucketDomain &amp; fileName    if (fileType is &quot;png&quot;) or (fileType is &quot;jpg&quot;) or (fileType is &quot;gif&quot;) or (fileType is &quot;bmp&quot;) or (fileType is &quot;jpeg&quot;) then        -- 设置按下快捷键后，输出内容的格式。修改之前返回的内容格式为 ![](被上传的图片链接)，但是这种语法不能很好的控制图片的大小和位置，所以我修改为了如下内容，方便控制图片大小和位置，根据自己的需求进行修改即可。\t    set markdownUrl to &quot;&lt;div style=\\&quot;text-align:center;\\&quot;&gt;&lt;img src=\\&quot;&quot; &amp; resourceUrl &amp; &quot;\\&quot; width=600 /&gt;&lt;/div&gt;&quot; \t    return markdownUrl    else        return resourceUrl    end ifend upload-- ref:https://discussions.apple.com/thread/2379870?start=0&amp;tstart=0\n\n配置 qshell 执行环境很简单，将第二个下载链接下载的压缩包解开，然后将其中对应 mac 版本的 qshell_darwin_x64 重命名为 qshell 丢到 /usr/local/bin 路径下，并增加执行权限。\n执行 qshell account -- access_key secret_key username 添加一个用户。\n测试一键上传图片功能请保证你的剪切板中有一张图片，可以选择复制一张图片，或者通过截图的方式做到。然后请在任何可以输入文本的地方按下 workflow 中设置的快捷键。是不是出现了符合 markdown 语法的图片引用了呢？然后再去七牛云空间看看，是不是剪切板中的那张图片已经被上传了呢？如果都没问题那就表示设置成功了哈，慢慢享用吧。\n","categories":["网络安全"],"tags":["Hexo","Https","CDN"]},{"title":"PropertyDescriptor类的使用及其执行过程的分析","url":"/2019/05/11/2019-05-11-PropertyDescriptor%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%85%B6%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E7%9A%84%E5%88%86%E6%9E%90/","content":"前言PropertyDescriptor 是位于 java.beans 包下的一个类，其注释对其的解释为： PropertyDescriptor 描述了 Java Bean 的一个属性，我们可以通过一对 getter 和 setter 方法对其进行访问。\n我对其产生兴趣是因为在看 Spring 源码的过程中，发现 Spring 会通过 org.springframework.beans.BeanWrapperImpl 对其管理的 bean 进行包装，然后调用它的 org.springframework.beans.PropertyAccessor#setPropertyValues(org.springframework.beans.PropertyValues) 方法对属性进行填充，其中参数 PropertyValues 就包含 PropertyDescriptor 属性。在对属性进行填充时，实际上是先获取 PropertyValues 对象的 WriteMethod，然后调用其 invoke 方法，最终通过反射的方式完成属性设置。\n举个栗子如果是要通过 Spring 对 bean 的管理来重现上边的过程比较的麻烦，所以这里手写一个小栗子来模拟这个过程。这里只有两个类，User 为用户类，我们这里就是要对它的属性进行访问，另外一个就是 App 类，所有的逻辑都在其中实现，代码很简单，我们主要是为了观察 setter 方法被执行的过程。\n\nUser 类\n\npublic class User &#123;    private String id;    private String userName;    public User(String id, String userName) &#123;        this.id = id;        this.userName = userName;    &#125;    public String getId() &#123;        return id;    &#125;    public void setId(String id) &#123;        this.id = id;    &#125;    public String getUserName() &#123;        return userName;    &#125;    public void setUserName(String userName) &#123;        this.userName = userName;    &#125;    @Override    public String toString() &#123;        return &quot;User&#123;&quot; +                &quot;id=&#x27;&quot; + id + &#x27;\\&#x27;&#x27; +                &quot;, userName=&#x27;&quot; + userName + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n\nApp 类\n\nimport java.beans.PropertyDescriptor;import java.lang.reflect.Method;public class App &#123;    public static void main(String[] args) throws Exception &#123;        User user = new User(&quot;12&quot;, &quot;eva&quot;);        Class&lt;? extends User&gt; clazz = user.getClass();        PropertyDescriptor pd = new PropertyDescriptor(&quot;userName&quot;, User.class);        Method m = pd.getWriteMethod();        m.invoke(user,&quot;tim&quot;);        System.out.println(user);    &#125;&#125;\n\n执行结果如下：\nUser&#123;id=&#x27;12&#x27;, userName=&#x27;tim&#x27;&#125; \n\n其实代码逻辑很简单，我们仅仅关心 user 实例的 userName 字段被修改的过程，可以看到我们的 PropertyDescriptor 对象是通过其构造函数得到的，并且传入了字段信息为 “userName”，所以我们获取到的 PropertyDescriptor 就是 “userName” 这个字段所代表的 Java Bean 的属性， Method m = pd.getWriteMethod(); 就是获取的这个字段的 setter 方法。然后我们调用 invoke 方法，这里有两个参数：此方法所在的实例和此方法的参数。因为获取到的是一个 Method 对象，它有一个特殊的字段我们要注意 java.lang.reflect.Method#methodAccessor，这里我把它的源码贴出来：\npackage sun.reflect;import java.lang.reflect.InvocationTargetException;/** This interface provides the declaration for    java.lang.reflect.Method.invoke(). Each Method object is    configured with a (possibly dynamically-generated) class which    implements this interface.*/public interface MethodAccessor &#123;    /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */    public Object invoke(Object obj, Object[] args)        throws IllegalArgumentException, InvocationTargetException;&#125;\n\n可以看到这个这个接口的唯一一个方法的签名和 Method 类的的 invoke 方法的签名是一模一样的，而且注释中也说了每一个 Method 对象都会包含一个实现了这个接口的对象。通过查看 Method 类的 invoke 方法，可以发现它最终也就是调用了 MethodAccessor 实现类的 invoke 方法。\npublic Object invoke(Object obj, Object... args)        throws IllegalAccessException, IllegalArgumentException,           InvocationTargetException&#123;    if (!override) &#123;        if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123;            Class&lt;?&gt; caller = Reflection.getCallerClass();            checkAccess(caller, clazz, obj, modifiers);        &#125;    &#125;    MethodAccessor ma = methodAccessor;             // read volatile    if (ma == null) &#123;        ma = acquireMethodAccessor();    &#125;    return ma.invoke(obj, args);&#125;\n\nMethodAccessor 的实现类有两个 sun.reflect.DelegatingMethodAccessorImpl 和 sun.reflect.NativeMethodAccessorImpl，通过 idea 的调试功能，可以看到 Method 包含的是 DelegatingMethodAccessorImpl 这个实现类，我们继续查看它对 invoke 方法的实现，很简单，就是直接调用了它所包含的 MethodAccessor 实现类的 invoke 方法，注意这里 MethodAccessor 的实现类变成了 NativeMethodAccessorImpl，好了那就直接看看 NativeMethodAccessorImpl 的 invoke 方法实现吧： \npublic Object invoke(Object obj, Object[] args)        throws IllegalArgumentException, InvocationTargetException&#123;    // We can&#x27;t inflate methods belonging to vm-anonymous classes because    // that kind of class can&#x27;t be referred to by name, hence can&#x27;t be    // found from the generated bytecode.    if (++numInvocations &gt; ReflectionFactory.inflationThreshold()            &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123;        MethodAccessorImpl acc = (MethodAccessorImpl)            new MethodAccessorGenerator().                generateMethod(method.getDeclaringClass(),                                method.getName(),                                method.getParameterTypes(),                                method.getReturnType(),                                method.getExceptionTypes(),                                method.getModifiers());        parent.setDelegate(acc);    &#125;    return invoke0(method, obj, args);&#125;void setParent(DelegatingMethodAccessorImpl parent) &#123;    this.parent = parent;&#125;private static native Object invoke0(Method m, Object obj, Object[] args);\n\n可以看到在 invoke 方法中，是最后调用了 invoke0 方法，而且在 java 中有个特点，就是如果一个方法是以数字 0 结尾，那么通常这个方法就是一个本地方法，这里也不例外，最后 invoke0 就是一个本地方法。本地方法对我们就是一个黑盒，但是我们可以通过其传入的参数猜测一下他的作用。\n一共三个参数, 分别是 method obj 和 orgs，通过 idea 的 debug 直视化功能，我们可以很直观的看到三个参数的值分别为 public void User.setUserName(java.lang.String)，User&#123;id=&#39;12&#39;, userName=&#39;eva&#39;&#125;，tim ，这不正好就是我们期望调用的方法、参数和对象吗？好了，提前在目标方法中打上断点，再直接下一步，可以看到程序停在了 User 类的 setUsername 方法上了，这样方法的调用过程就分析完毕。\n总结之前在看 Aop 的实现原理时，发现动态代理的过程也会执行上述的代码，但是当时并没有看懂各种类之间是什么关系，这次通过一个比较简单的例子重新走了一个这个过程，大致理清了下通过反射调用的过程。但是对于 Aop 的增强方法的链式调用过程还是很模糊，有时间了再去看看 Aop 实现的过程。\n","categories":["后台开发"],"tags":["Spring","JDK"]},{"title":"Spring中常用Aware结尾接口及使用","url":"/2019/05/11/2019-05-11-Spring%E4%B8%AD%E5%B8%B8%E7%94%A8Aware%E7%BB%93%E5%B0%BE%E6%8E%A5%E5%8F%A3%E5%8F%8A%E4%BD%BF%E7%94%A8/","content":"\n部分内容参考 Spring整理系列(06)——spring中Aware结尾接口\n\n前言在 Spring 中，有一个特殊的约定，就是被 Spring 容器管理的 bean，如果实现了 Spring 提供的以 Aware 结尾的接口，那么在对 bean 进行实例化的过程中，容器会调用相应的接口方法，通过这个特性，我们可以获取容器或者 bean 相关的一些属性。比较常用的就有 BeanFactoryAware、BeanNameAware、ApplicationContextAware、ResourceLoaderAware、ServletContextAware 等等。\n使用方法这里以 BeanNameAware、ApplicationContextAware 为例，演示相关接口的使用方法。相关的代码来自 Dubbo 框架的 com.alibaba.dubbo.config.spring.ServiceBean。\npublic class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware &#123;\tprivate static final long serialVersionUID = 213195494150089726L;\tprivate transient ApplicationContext applicationContext;    private transient String beanName;\tpublic void setApplicationContext(ApplicationContext applicationContext) &#123;\t\tthis.applicationContext = applicationContext;\t\tSpringExtensionFactory.addApplicationContext(applicationContext);\t\tif (applicationContext != null) &#123;\t\t    SPRING_CONTEXT = applicationContext;\t\t    try &#123;\t            Method method = applicationContext.getClass().getMethod(&quot;addApplicationListener&quot;, new Class&lt;?&gt;[]&#123;ApplicationListener.class&#125;); // 兼容Spring2.0.1\t            method.invoke(applicationContext, new Object[] &#123;this&#125;);\t            supportedApplicationListener = true;\t        &#125; catch (Throwable t) &#123;                if (applicationContext instanceof AbstractApplicationContext) &#123;    \t            try &#123;    \t                Method method = AbstractApplicationContext.class.getDeclaredMethod(&quot;addListener&quot;, new Class&lt;?&gt;[]&#123;ApplicationListener.class&#125;); // 兼容Spring2.0.1                        if (! method.isAccessible()) &#123;                            method.setAccessible(true);                        &#125;    \t                method.invoke(applicationContext, new Object[] &#123;this&#125;);                        supportedApplicationListener = true;    \t            &#125; catch (Throwable t2) &#123;    \t            &#125;\t            &#125;\t        &#125;\t\t&#125;\t&#125;    public void setBeanName(String name) &#123;        this.beanName = name;    &#125;&#125;\n\n代码中只保留了与 Aware 接口相关的内容，可以看到 ServiceBean 实现了 BeanNameAware、ApplicationContextAware 接口，对应的方法为 com.alibaba.dubbo.config.spring.ServiceBean#setBeanName 和 com.alibaba.dubbo.config.spring.ServiceBean#setApplicationContext，这两个方法将会被容器调用，带来的结果就是 ServiceBean 可以直接获取到容器上下文环境 ApplicationContext 和当前 bean 在容器中的表示的 BeanName。\n类似的我们也可以自己实现这两个接口，并根据自己的需求来做出相应的函数实现，具体的代码如下：\n//实现BeanNameAware接口，并重写setBeanName()方法，让Bean获取自己在BeanFactory配置中的名字（根据情况是id或者name）//实现ApplicationContextAware接口，并重写setApplicationContext()方法public class MyApplicationContext implements BeanNameAware,ApplicationContextAware&#123;    private String beanName;    //注入的beanName即为MyApplicationContext在BeanFactory配置中的名字（根据情况是id或者name）    @Override    public void setBeanName(String beanName) &#123;        this.beanName = beanName;        System.out.println(&quot;MyApplicationContext beanName:&quot;+beanName);    &#125;    @Override    public void setApplicationContext(ApplicationContext context)            throws BeansException &#123;        //通过重写的接口方法，获取spring容器实例context，进而获取容器中相关bean资源        System.out.println(context.getBean(this.beanName).hashCode());    &#125;&#125;\n\n然后在 Spring 配置文件中加上如下 bean 节点，那么容器中所管理的 MyApplicationContext 在实例化过程中将会执行这两个方法。\n&lt;bean name =&quot;myContext&quot; class=&quot;com.jsun.test.springDemo.aware.MyApplicationContext&quot;&gt;&lt;/bean&gt;\n\n总结这里只是以 BeanNameAware、ApplicationContextAware 接口进行了说明，其他的 Aware 结尾的接口的使用方法类似，表示获取到某种属性的能力。不仅如此，Spring 中的其他很多的接口的设计也是采用了这种思想，比如 ServiceBean 实现的 DisposableBean,ApplicationListener 接口。这是一种很优秀的设计思想，Spring 容器在其初始化的特殊时刻将会统一调用实现了对应接口的实例的对应方法。\n","categories":["后台开发"],"tags":["Spring"]},{"title":"Dubbo基于ExtensionLoader实现的SPI拓展","url":"/2019/05/12/2019-05-12-Dubbo%E7%9A%84SPI%E6%8B%93%E5%B1%95/","content":"\n本文内容转载自 从ExtensionLoader看Dubbo插件化\n\n前言最近在看 Dubbo 的源码，因为 Dubbo 集成了 Spring 框架，根据 Dubbo 的 XML 配置方式（当然也可以是通过注解的方式），不难想到应该从 Dubbo 对应的 NamespaceHandler 作为分析的出发点。\n因为 DubboNamespaceHandler 继承了 NamespaceHandlerSupport 抽象类，所以在 DubboNamespaceHandler 中需要实现 init() 方法的逻辑，主要就是向 Spring 容器中注册相关标签的解析器，这样在遇上对应标签后，将会调用匹配的解析器来生成对应的 bean，相关的代码如下：\npublic class DubboNamespaceHandler extends NamespaceHandlerSupport &#123;\tstatic &#123;\t\tVersion.checkDuplicate(DubboNamespaceHandler.class);\t&#125;\tpublic void init() &#123;\t    registerBeanDefinitionParser(&quot;application&quot;, new DubboBeanDefinitionParser(ApplicationConfig.class, true));        registerBeanDefinitionParser(&quot;module&quot;, new DubboBeanDefinitionParser(ModuleConfig.class, true));        registerBeanDefinitionParser(&quot;registry&quot;, new DubboBeanDefinitionParser(RegistryConfig.class, true));        registerBeanDefinitionParser(&quot;monitor&quot;, new DubboBeanDefinitionParser(MonitorConfig.class, true));        registerBeanDefinitionParser(&quot;provider&quot;, new DubboBeanDefinitionParser(ProviderConfig.class, true));        registerBeanDefinitionParser(&quot;consumer&quot;, new DubboBeanDefinitionParser(ConsumerConfig.class, true));        registerBeanDefinitionParser(&quot;protocol&quot;, new DubboBeanDefinitionParser(ProtocolConfig.class, true));        registerBeanDefinitionParser(&quot;service&quot;, new DubboBeanDefinitionParser(ServiceBean.class, true));        registerBeanDefinitionParser(&quot;reference&quot;, new DubboBeanDefinitionParser(ReferenceBean.class, false));        registerBeanDefinitionParser(&quot;annotation&quot;, new DubboBeanDefinitionParser(AnnotationBean.class, true));    &#125;&#125;\n\n这里我最关注的就是 service 标签所对应的 ServiceBean，它实现了众多的 Spring 功能性接口，Spring 容器会在特殊的时刻调用相应的方法，而 dubbo 的服务发布，就是在 com.alibaba.dubbo.config.spring.ServiceBean#onApplicationEvent 方法中完成的，具体的过程比较复杂，其中涉及到了一个 ExtensionLoader 类，实现的功能比较多，使得自己源码分析的过程比较晕，遂去 google 了一下这个类的作用，确实找到了一篇比较好的文章，所以这里将其转载下来，方便以后回顾查看。\nSPI 与 Dubbo了解 SPI 的人知道，它只是提供一种协议，并没有提供相关插件化实施的接口，不像 OSGI 那样有一成套实施插件化 API。它只是规定在 META-INF 目录下提供接口的实现描述文件，框架本身定义接口、规范，第三方只需要将自己的实现在 META-INF 下描述清楚，那么框架就会自动加载你的实现，至于怎么加载，JDK 并没有提供相关 API，而是框架设计者需要考虑和实现的,并且在 META-INF 目录下面对规则的描述，也是需要框架设计者来规定。比如 Dubbo 的规则是在 META-INF&#x2F;dubbo、META-INF&#x2F;dubbo&#x2F;internal 或者 META-INF&#x2F;services 下面以需要实现的接口的全限定名去创建一个文件，并且在文件中以键值对的方式来规定实现类和别名的关系。下图便是 Dubbo 的 META-INF 目录的详细规则。 \n\n\n这里简单的介绍一下 Dubbo 的插件实现方式和规则，以及提到 SPI 是一种插件化的规范，并没有提供实施的 API，是需要框架自己去实现的。Dubbo 对这一块的实现全部都集中在类 ExtensionLoader 中，那么接下来将围绕这个类来介绍 Dubbo 插件化的实现，在介绍 Dubbo 插件化实施之前，需要知道 Dubbo 框架是以 URL 为总线的模式，即运行过程中所有的状态数据信息都可以通过 URL 来获取，比如当前系统采用什么序列化，采用什么通信，采用什么负载均衡等信息，都是通过 URL 的参数来呈现的，所以在框架运行过程中，运行到某个阶段需要相应的数据，都可以通过对应的 Key 从URL的参数列表中获取。\nExtensionLoader 的 activate 模块ExtensionLoader 是一个单例工厂类，它对外暴露 getExtensionLoader 静态方法返回一个ExtensionLoader 实体，这个方法的入参是一个 Class 类型，这个方法的意思是返回某个接口的 ExtensionLoader。那么对于某一个接口，只会有一个 ExtensionLoader 实体。ExtensionLoader 实体对外暴露了下图中的一些接口来获取扩展实现。\n\n\n上图的方法归为几类，分别是 activate extension、adaptive extension、default extension、get extension by name 以及 supported extension。activate extension 都需要传入 url 参数，这里涉及到 Activate 注解，这个注解主要用处是标注在插件接口实现类上，用来配置该扩展实现类激活条件。在 Dubbo 框架里面的 Filter 接口的各种实现类都通过 Activate 标注，用来描述该 Filter 什么时候生效。比如 MonitorFilter 通过 Activate 标注用来告诉 Dubbo 框架这个 Filter 是在服务提供端和消费端会生效的；而 TimeoutFilter 则是只在服务提供端生效，消费端是不会调用该 Filter； ValidationFilter 要激活的条件除了在消费端和服务提供端激活，它还配置了 value，这个表述另一个激活条件，上面介绍要获取 activate extension 都需要传入URL对象，那么这个 value 配置的值则表述URL必须有指定的参数才可以激活这个扩展。例如 ValidationFilter 则表示URL中必须包含参数 validation(Constants.VALIDATION_KEY 常量的值就是 validation)，否则消费端和服务端都不会激活这个扩展实现，仔细的同学还会发现在 ValidationFilter 中的 Activate 注解还有一个参数 order，这是表示一种排序规则。因为一个接口的实现有多种，返回的结果是一个列表，如果不指定排序规则，那么可能列表的排序不可控，为了达到排序可控，添加了 order 属性用来控制排序，其中 order 的值越大，那么该扩展实现排序就越靠前。除了通过 order 来控制排序，还有 before 和 after 来配置当前扩展的位置，before 和 after 配置的值是扩展的别名。下边是简化的接口信息：\n@Activate(group = &#123;Constants.PROVIDER, Constants.CONSUMER&#125;)public class MonitorFilter implements Filter &#123;……&#125;@Activate(group = Constants.PROVIDER)public class TimeoutFilter implements Filter &#123;……&#125;@Activate(group = &#123; Constants.CONSUMER, Constants.PROVIDER &#125;, value = Constants.VALIDATION_KEY, order = 10000)public class ValidationFilter implements Filter &#123;……&#125;\n\n上面基本对 activate 介绍的差不多了，在 Dubbo 框架中对这个用的最多的就是 Filter 的各种实现，因为 Dubbo 的调用会经过一个过滤器链。哪些 Filter 实现类被包含在调用链中，是通过各种Filter实现类的 Activate 注解来控制的。包括上面说的排序，也可以理解为过滤器链中各个 Filter 的前后顺序。这里的顺序需要注意一个地方，即排序均是对框架本身实现的扩展进行排序，用户自定义的扩展默认是追加在列表后面。说到这里具体例子：\n&lt;dubbo:reference id=”fooRef” interface=”com.foo.Foo” filter=”A,B,C”/&gt;\n\n假设上面是一个有效的消费端服务引用，其中配置了一个 filter 属性，并且通过逗号隔开配置了三个过滤器 A,B,C（A,B,C 均为 Filter 实现的别名），那么对于接口 Foo 调用的过滤器链是怎么样的呢？首先 Dubbo 会加载默认的过滤器（一般消费端有三个 ConsumerContextFilter,MonitorFilter,FutureFilter），并且对这些默认的过滤器实现进行排序（ActivateComparator 实现排序逻辑），这写默认过滤器实现会在过滤器链的前面，后面紧接着的才是 A，B，C 三个自定义过滤器。\nExtensionLoader 的 adaptive 模块上面介绍了 activate extension,下面介绍 ExtensionLoader 另一个重要模块 adaptive extension。Dubbo 框架提供的各种接口均有很多种类的实现，在引用具体实现的时候不可能通过硬编码制定引用哪个实现，这样整个框架的灵活性严重降低。所以为了能够适配一个接口的各种实现，便有了 adaptive extension 这一说。对一个接口实现的适配器 Dubbo 提供两种途径，第一种途径是手动对某个接口实现对应的适配器，第二种是 Dubbo 框架动态生成适配器类。先对第一种途径进行介绍，这种途径也最好理解，对于这种途径 Dubbo 也提供了一个注解 Adaptive，他用来标注在接口的某个实现上，表示这个实现并不是提供具体业务支持，而是作为该接口的适配器。比如 ExtensionFactory 的实现类 AdaptiveExtensionFactory 就是实现适配的功能，这个类被Adaptive进行了标注，那么在调用 ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension() 的时候将会返回 AdaptiveExtensionFactory 实体，用来适配 ExtensionFactory 接口的 SPIExtensionFactory 和 SpringExtensionFactory 两种实现，在 AdaptiveExtensionFactory 将会根据运行时的状态来确定具体调用 ExtensionFactory 的哪个实现。\n而第二种相对于第一种来说就隐晦一点，是 ExtensionLoader 通过分析接口配置的 adaptive 规则动态生成 adaptive 类并且加载到 ClassLoader 中，从而来实现动态适配。配置 adaptive 的规则也是通过 Adaptive 注解来设置，该注解有一个 value 属性，通过设置这个属性便可以设置该接口的 Adaptive 的规则，上面说过服务调用的所有数据均可以从 URL 获取（Dubbo 的 URL 总线模式），那么需要 Dubbo 帮我们动态生成 adaptive 的扩展接口的方法入参必须包含 URL，这样才能根据运行状态动态选择具体实现。这里列举一下 Transporter 接口中配置 adaptive 规则。\n@SPI(&quot;netty&quot;)public interface Transporter &#123;    /**     * Bind a server.     *      * @see com.alibaba.dubbo.remoting.Transporters#bind(URL, Receiver, ChannelHandler)     * @param url server url     * @param handler     * @return server     * @throws RemotingException      */    @Adaptive(&#123;Constants.SERVER_KEY, Constants.TRANSPORTER_KEY&#125;)    Server bind(URL url, ChannelHandler handler) throws RemotingException;    /**     * Connect to a server.     *      * @see com.alibaba.dubbo.remoting.Transporters#connect(URL, Receiver, ChannelListener)     * @param url server url     * @param handler     * @return client     * @throws RemotingException      */    @Adaptive(&#123;Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY&#125;)    Client connect(URL url, ChannelHandler handler) throws RemotingException;&#125;\n\nTransporter 接口提供了两个方法，一个是 connect（用来创建客户端连接），另一个是 bind（用来绑定服务端端口提供服务），并且这两个方法上面均通过 Adaptive 注解配置了 value 属性，bind 配置的是 server 和 transporter，connect 配置的是 client 和 transporter。那么配置这些值有什么用呢？下面看看 ExtensionLoader 根据这些生成了什么样的 adaptive 代码。\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;public class Transporter$Adpative implements com.alibaba.dubbo.remoting.Transporter &#123;    public com.alibaba.dubbo.remoting.Client connect(            com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1)            throws com.alibaba.dubbo.remoting.RemotingException &#123;        if (arg0 == null)            throw new IllegalArgumentException(&quot;url == null&quot;);        com.alibaba.dubbo.common.URL url = arg0;        String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;));        if (extName == null)            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([client, transporter])&quot;);        com.alibaba.dubbo.remoting.Transporter extension = (com.alibaba.dubbo.remoting.Transporter) ExtensionLoader.getExtensionLoader                (com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName);        return extension.connect(arg0, arg1);    &#125;    public com.alibaba.dubbo.remoting.Server bind(            com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1)            throws com.alibaba.dubbo.remoting.RemotingException &#123;        if (arg0 == null)            throw new IllegalArgumentException(&quot;url == null&quot;);        com.alibaba.dubbo.common.URL url = arg0;        String extName = url.getParameter(&quot;server&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;));        if (extName == null)            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([server, transporter])&quot;);        com.alibaba.dubbo.remoting.Transporter extension = (com.alibaba.dubbo.remoting.Transporter) ExtensionLoader.getExtensionLoader                (com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName);        return extension.bind(arg0, arg1);    &#125;&#125;\n\n上面是 ExtensionLoader 自动生成的 Transporter$Adpative 类，并且实现了 Transporter 接口，下面我们分别看看在它 connect 和 bind 中分别做了哪些逻辑。先看看 bind 方法代码段：\npublic com.alibaba.dubbo.remoting.Server bind(        com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1)        throws com.alibaba.dubbo.remoting.RemotingException &#123;    if (arg0 == null)        throw new IllegalArgumentException(&quot;url == null&quot;);    com.alibaba.dubbo.common.URL url = arg0;    String extName = url.getParameter(&quot;server&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;));    if (extName == null)        throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([server, transporter])&quot;);    com.alibaba.dubbo.remoting.Transporter extension = (com.alibaba.dubbo.remoting.Transporter) ExtensionLoader.getExtensionLoader            (com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName);    return extension.bind(arg0, arg1);&#125;\n\n可以看到bind方法先对 url 参数(arg0)进行了非空判断，然后便是调用 url.getParameter 方法，首先是获取 server 参数，然后再获取 transporter 参数，最后如果两个参数均没有，extName便是netty。获取完参数之后，紧接着对 extName 进行非空判断，接下来便是获取 Transporter 的 ExtensionLoader，最后获取别名为 extName 的 Transporter 实现，并调用对应的 bind 来进行绑定服务端口操作。connect 也是类似，只是它首先是从 url 中获取 client 参数，再获取 transporter 参数，同样的如果最后两个参数都没有，那么 extName 也是 netty，最终也是依据 extName 获取对已的接口扩展实现，调用 connect 方法。\n到这里或许你已经明白了 ExtensionLoader 是怎么动态生成 adaptive,上面从 url 中获取 server， client 还是 transporter 参数均是在 Transporter 接口的方法通过 Adaptive 注解配置的 value 属性所决定。其中 netty 是通过注解 SPI 制定当前接口的一种默认实现。这便是 Dubbo 通过 ExtensionLoader 动态生成 adaptive 类来动态适配接口的所有实现。\n上面对 activate 和 adaptive 进行了详细的介绍，这两部分对应 ExtensionLoader 的实现分别是方法 getActivateExtension(URL url, String[] values, String group) 和createAdaptiveExtensionClassCode()，如果感兴趣，可以去查看 ExtensionLoader 源码。接下来对get extension by name 和 default extension 介绍一下，get extension by name 这个没什么好介绍的，就是通过接口实现的别名来获取某一个具体的服务。而 default extension 需要做一下详细介绍，Dubbo 的 SPI 规范除了上面说的在制定文件夹下面描述服务的实现信息之外，在被实现的接口必须标注 SPI 注解，用来告诉 Dubbo 这个接口是通过 SPI 来进行扩展实现的，否则 ExtensionLoader 则不会对这个接口创建 ExtensionLoader 实体，并且调用 ExtensionLoader.getExtensionLoader 方法会出现 IllegalArgumentException 异常。那说这些和默认扩展实现有什么关系呢？在接口上标注 SPI 注解的时候可以配置一个 value 属性用来描述这个接口的默认实现别名，例如上面 Transporter 的 @SPI(“netty”)就是指定 Transporter 默认实现是 NettyTransporter，因为 NettyTransporter 的别名是 netty。这里再对服务别名补充有点，别名是站在某一个接口的维度来区分不同实现的，所以一个接口的实现不能有相同的别名，否则 Dubbo 框架将启动失败，当然不同接口的各自实现别名可以相同。到此 ExtensionLoader 的实现原则和基本原理介绍完了，接下来我们来看看怎么基于 Dubbo 的 ExtensionLoader 来实施我们自己的插件化。\n测试 ExtensionLoader 的动态加载机制插件化的第一步是抽象一个接口，从定义了插件的规范，那么我们先创建一个 IHelloService 接口，并且标注了 SPI 注解，同时指定默认实现是别名为 default 的扩展实现。\n@SPI(&quot;default&quot;)public interface IHelloService &#123;    @Adaptive    String sayHello(URL url, String msg, ExtentionType type);&#125;\n\n那么接下来就是对这个插件接口提供不同的实现，需要我自己来实现一个适配类。适配类如下：\n@Adaptivepublic class HelloServiceAdaptor implements IHelloService &#123;    @Override    public String sayHello(URL url, String msg, ExtentionType type) &#123;        ExtensionLoader extensionLoader = ExtensionLoader.getExtensionLoader(IHelloService.class);        IHelloService extension = (IHelloService) extensionLoader.getDefaultExtension();        switch (type) &#123;            case DEFAULT:                extension = (IHelloService) extensionLoader.getExtension(&quot;default&quot;);                break;            case OTHER:                extension = (IHelloService) extensionLoader.getExtension(&quot;other&quot;);                break;        &#125;        return extension.sayHello(url, msg, type);    &#125;&#125;\n\n相应类 ExtentionType 枚举类：\npublic enum ExtentionType &#123;    DEFAULT,    OTHER&#125;\n\n可见在 AdaptiveExtension 中将会根据 ExtensionType 分发扩展的具体实现，并触发 sayHello 方法。然后再对 IHelloService 接口提供了两种实现：\npublic class DefaultHelloImpl implements IHelloService &#123;    @Override    public String sayHello(URL url, String msg, ExtentionType type) &#123;        return &quot;default say &quot; + msg;    &#125;&#125;\n\n\npublic class OtherHelloImpl implements IHelloService &#123;    @Override    public String sayHello(URL url, String msg, ExtentionType type) &#123;        return &quot;other say &quot; + msg;    &#125;&#125;\n\n并且在 META-INF&#x2F;dubbo 下面创建了文件 com.bieber.dubbo.extension.IHelloService 其中内容如下（注意要将 META-INF 目录置于 resources 资源路径下）：\ndefault=com.aprilyolies.extension.DefaultHelloImplother=com.aprilyolies.extension.OtherHelloImpladaptive=com.aprilyolies.extension.HelloServiceAdaptor\n\n最后是一个启动类：\npublic class App &#123;    public static void main(String[] args) &#123;        ExtensionLoader extensionLoader = ExtensionLoader.getExtensionLoader(IHelloService.class);        IHelloService extension = (IHelloService) extensionLoader.getAdaptiveExtension();        System.out.println(extension.sayHello(new URL(&quot;dubbo&quot;, &quot;127.0.0.1&quot;, 1234), &quot;hello&quot;, ExtentionType.OTHER));    &#125;&#125;\n\n总结关于 Dubbo 插件化的内容介绍完了，其实可以把 ExtensionLoader 当作是 Spring 的 IOC 容器，只不过 IOC 容器里面做的事情是帮我们初始化和管理 bean，我们可以根据我们需要的 bean 类型或者 bean 的 id 来获取对应的 bean 实体，Dubbo 里面 ExtensionLoader 类的作用比较相似，只不过它管理的是插件，同样我们可以根据具体插件实现别名和插件接口来获取我们想要的插件实现。另一个不同点是 Spring 是通过 XML 的方式告诉 Spring 我的 bean 的实现类全路径，而 Dubbo 则是通过 SPI 的方式告诉 ExtensionLoader 具体实现类信息。如果你理解了这个，那么你就理解 ExtensionLoader 了。\n","categories":["后台开发"],"tags":["Dubbo"]},{"title":"Spring如何实现自定义名称空间的解析","url":"/2019/05/13/2019-05-13-Spring%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4%E7%9A%84%E8%A7%A3%E6%9E%90/","content":"\n本文的例子参考 spring拓展之定义自己的namespace\n\n前言今年的春招已经接近尾声了，因为自己没有实际的项目经验，所以找实习的情况很不理想，心里当然是很不甘心的，所以就开始盘算着要动手做出点实际的东西出来，这样今年的秋招才会有底气。先想到的就是自己开发出一个类似于 dubbo 的 rpc 框架，能够实现基本的功能就好。\n为了实现这个小目标，最开始当然是先看看 dubbo 的源码来了解下它的实现原理，因为 dubbo 是依赖于 spring 的 ioc 功能来实现服务的发布和调用的，所以最开始就得先解决 dubbo 自定义标签的解析问题，本文就是关于一个最简单的自定义标签解析的实现。\n实现自定义标签的解析为了实现自定义标签的解析，我们需要定义：\n\nxsd 文件：这个文件用于对自定标签的命名空间规则进行约束。\n\nspring.handlers 文件：用于指定自定义标签的命名空间的处理器。\n\nspring.schemas 文件：指定相应命名空间的 xsd 约束文件的位置。\n\n\n这三个文件需要放在 classpath 根目录的 META-INF 文件夹目录之下，在定义好这三个文件后，就可以测试自定义的标签的解析了。这么说比较抽象，还是举个栗子进行说明。\n定义一个 xsd 文件定义一个 xsd 文件来对自定义命名空间的标签进行约束，因为 xsd 文件的编写规则我们不是很清楚，所以要想实现更加复杂的约束，就需要深入的去学习 xml 和 xsd 规则，这里给个学习地址。\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;xsd:schema xmlns=&quot;https://www.aprilyolies.top/schema/beehive&quot;            xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;            targetNamespace=&quot;https://www.aprilyolies.top/schema/beehive&quot;&gt;    &lt;xsd:import namespace=&quot;http://www.w3.org/XML/1998/namespace&quot;/&gt;    &lt;xsd:import namespace=&quot;http://www.springframework.org/schema/beans&quot;/&gt;    &lt;xsd:import namespace=&quot;http://www.springframework.org/schema/tool&quot;/&gt;    &lt;xsd:annotation&gt;        &lt;xsd:documentation&gt;&lt;![CDATA[ Namespace support for the beehive test. ]]&gt;&lt;/xsd:documentation&gt;    &lt;/xsd:annotation&gt;    &lt;xsd:complexType name=&quot;mybeanType&quot;&gt;        &lt;xsd:attribute name=&quot;id&quot; type=&quot;xsd:ID&quot;&gt;            &lt;xsd:annotation&gt;                &lt;xsd:documentation&gt;&lt;![CDATA[ The unique identifier for a bean. ]]&gt;&lt;/xsd:documentation&gt;            &lt;/xsd:annotation&gt;        &lt;/xsd:attribute&gt;        &lt;xsd:attribute name=&quot;name&quot; type=&quot;xsd:string&quot; use=&quot;required&quot;&gt;            &lt;xsd:annotation&gt;                &lt;xsd:documentation&gt;&lt;![CDATA[ The mybean name. ]]&gt;&lt;/xsd:documentation&gt;            &lt;/xsd:annotation&gt;        &lt;/xsd:attribute&gt;        &lt;xsd:attribute name=&quot;class&quot; type=&quot;xsd:string&quot; use=&quot;required&quot;&gt;            &lt;xsd:annotation&gt;                &lt;xsd:documentation&gt;&lt;![CDATA[ The version. ]]&gt;&lt;/xsd:documentation&gt;            &lt;/xsd:annotation&gt;        &lt;/xsd:attribute&gt;    &lt;/xsd:complexType&gt;    &lt;xsd:element name=&quot;mybean&quot; type=&quot;mybeanType&quot;&gt;        &lt;xsd:annotation&gt;            &lt;xsd:documentation&gt;&lt;![CDATA[ The mybean config ]]&gt;&lt;/xsd:documentation&gt;        &lt;/xsd:annotation&gt;    &lt;/xsd:element&gt;&lt;/xsd:schema&gt;\n\nspring.handlers 文件spring.handlers 文件用于指定自定义命名空间的处理器类。\nhttps\\://www.aprilyolies.top/schema/beehive=com.aprilyolies.beehive.BeehiveNamespaceHandler\n\nspring.schemas 文件spring.schemas 文件用于指定相应命名空间约束文件的位置。\nhttps\\://www.aprilyolies.top/schema/beehive.xsd=META-INF/beehive.xsd\n\n上述的三个文件的存放位置十分讲究，请参看下图：\n\n\n测试自定义命名空间编写 spring 的配置文件这是启动 spring ioc 容器的配置文件，熟悉 spring 使用的小伙伴都不会陌生。注意这里的 beehive 就是我们自定义的命名空间，而 mybean 就是我们自定义的标签。\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:beehive=&quot;https://www.aprilyolies.top/schema/beehive&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd        https://www.aprilyolies.top/schema/beehive https://www.aprilyolies.top/schema/beehive.xsd&quot;&gt;    &lt;beehive:mybean class=&quot;com.aprilyolies.beehive.People&quot; id=&quot;people&quot; name=&quot;eva&quot;/&gt;&lt;/beans&gt;\n\n自定义命名空间的处理器创建一个用于解析自定义命名空间的类，这个类继承了 NamespaceHandlerSupport 类，我们只需要实现 init 方法的逻辑，来向 spring 容器注册不同标签的解析器，因为我们在 xsd 文件中，只是定义了一个 mybean 标签，所以这里只需要注册一个解析器就行了。\nimport org.springframework.beans.factory.xml.NamespaceHandlerSupport;/** * @Author EvaJohnson * @Date 2019-05-13 * @Email g863821569@gmail.com */public class BeehiveNamespaceHandler extends NamespaceHandlerSupport &#123;    @Override    public void init() &#123;        registerBeanDefinitionParser(&quot;mybean&quot;, new MybeanParser());    &#125;&#125;\n\n编写标签解析器这个解析器就是上文中提到的 mybean 标签解析器，用于将 mybean 标签解析为可以由 spring 容器管理的 bean。\n/** * @Author EvaJohnson * @Date 2019-05-13 * @Email g863821569@gmail.com */public class MybeanParser implements BeanDefinitionParser &#123;    @Override    public BeanDefinition parse(Element element, ParserContext parserContext) &#123;        RootBeanDefinition mbd = new RootBeanDefinition();        mbd.setBeanClassName(element.getAttribute(&quot;class&quot;));        String beanName = element.getAttribute(&quot;id&quot;);        MutablePropertyValues mutablePropertyValues = new MutablePropertyValues();        mutablePropertyValues.addPropertyValue(&quot;name&quot;, element.getAttribute(&quot;name&quot;));        mbd.setPropertyValues(mutablePropertyValues);        parserContext.getRegistry().registerBeanDefinition(beanName, mbd);        return mbd;    &#125;&#125;\n\npojo 类没啥好解释，用于功能测试，省略了 getter 和 setter 方法。\n/** * @Author EvaJohnson * @Date 2019-05-13 * @Email g863821569@gmail.com */public class People &#123;    private String id;    private String name;    private Integer age;&#125;\n\nApp 类执行这个 App 类的 main 方法，如果能正常输出 People 类的 name 属性，则表示自定义的命名空间及标签解析成功了。\n/** * @Author EvaJohnson * @Date 2019-05-13 * @Email g863821569@gmail.com */public class App &#123;    public static void main(String[] args) &#123;        ClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(new String[]&#123;&quot;beehive.xml&quot;&#125;, false);        ac.refresh();        People bean = (People) ac.getBean(&quot;people&quot;, People.class);        System.out.println(bean.getName());    &#125;&#125;\n\n总结本文中举的例子可以说是非常简单的，所以涉及的标签解析过程并不复杂，但是如果是用于生产环境的话，那么标签的定义就会比较复杂，相应的 xsd 文件内容也会比较多。我自己对于 xsd 的编写规则也是一片空白，有时间还是要了解一下相关的知识，毕竟我自己考虑的一个类似于 dubbo 的 rpc 框架也是需要依赖于 spring 的 ioc 容器的，如果这个 xsd 文件不会写，那就没办法开始了对吧。\n","categories":["后台开发"],"tags":["Spring"]},{"title":"Dubbo自定义标签解析过程的源码分析","url":"/2019/05/15/2019-05-15-Dubbo%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%87%E7%AD%BE%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","content":"前言今年找实习的过程不是很顺利，主要是因为没有实际的项目，所以希望在秋招之前能够自己动手做出一点小东西出来，现在有两个想法，一个就是做一个简易的 rpc 框架，使用的方式跟 dubbo 一样，能够整合 spring 容器。另外一个就是分布式的统一 ID 生成器，就类似于美团开源的 leaf 项目。\n相比较之下，rpc 框架应该会比分布式的统一 ID 生成器要难，我选择的是先把这个 rpc 框架给搞定，当然最先要解决的就是整个 spring 的 ioc 容器，也就是说我需要自己解析自定义的标签，之前只是了解过大致的原理，但是细节部分没有过多的考量，所以这里我就想通过 dubbo 的自定义标签的解析过程来加深自己的理解，本文的内容就是我在看源码过程中所加的一些注释，来表示当前代码的含义。我还将这些代码注释提交到了 github 上边，各位需要的小伙伴欢迎自取。\n整体设计Dubbo 的自定义标签全部是由 DubboNamespaceHandler 所注册的 DubboBeanDefinitionParser 解析器来完成解析的。这个跟 Spring 自定义标签的解析的设计还是有点小区别。具体的可以看一下他们各自的代码，这里以 AopNamespace 的解析进行说明。\n\norg.apache.dubbo.config.spring.schema.DubboNamespaceHandler\n\npublic class DubboNamespaceHandler extends NamespaceHandlerSupport &#123;    static &#123;        Version.checkDuplicate(DubboNamespaceHandler.class);    &#125;    @Override    public void init() &#123;        // 注册标签解析器，比如 &lt;dubbo:service /&gt;标签        registerBeanDefinitionParser(&quot;application&quot;, new DubboBeanDefinitionParser(ApplicationConfig.class, true));        registerBeanDefinitionParser(&quot;module&quot;, new DubboBeanDefinitionParser(ModuleConfig.class, true));        registerBeanDefinitionParser(&quot;registry&quot;, new DubboBeanDefinitionParser(RegistryConfig.class, true));        registerBeanDefinitionParser(&quot;config-center&quot;, new DubboBeanDefinitionParser(ConfigCenterBean.class, true));        registerBeanDefinitionParser(&quot;metadata-report&quot;, new DubboBeanDefinitionParser(MetadataReportConfig.class, true));        registerBeanDefinitionParser(&quot;monitor&quot;, new DubboBeanDefinitionParser(MonitorConfig.class, true));        registerBeanDefinitionParser(&quot;metrics&quot;, new DubboBeanDefinitionParser(MetricsConfig.class, true));        registerBeanDefinitionParser(&quot;provider&quot;, new DubboBeanDefinitionParser(ProviderConfig.class, true));        registerBeanDefinitionParser(&quot;consumer&quot;, new DubboBeanDefinitionParser(ConsumerConfig.class, true));        registerBeanDefinitionParser(&quot;protocol&quot;, new DubboBeanDefinitionParser(ProtocolConfig.class, true));        registerBeanDefinitionParser(&quot;service&quot;, new DubboBeanDefinitionParser(ServiceBean.class, true));        registerBeanDefinitionParser(&quot;reference&quot;, new DubboBeanDefinitionParser(ReferenceBean.class, false));        registerBeanDefinitionParser(&quot;annotation&quot;, new AnnotationBeanDefinitionParser());    &#125;&#125;\n\n\norg.springframework.aop.config.AopNamespaceHandler\n\npublic class AopNamespaceHandler extends NamespaceHandlerSupport &#123;\t/**\t * Register the &#123;@link BeanDefinitionParser BeanDefinitionParsers&#125; for the\t * &#x27;&#123;@code config&#125;&#x27;, &#x27;&#123;@code spring-configured&#125;&#x27;, &#x27;&#123;@code aspectj-autoproxy&#125;&#x27;\t * and &#x27;&#123;@code scoped-proxy&#125;&#x27; tags.\t */\t@Override\tpublic void init() &#123;\t\t// In 2.0 XSD as well as in 2.1 XSD.\t\tregisterBeanDefinitionParser(&quot;config&quot;, new ConfigBeanDefinitionParser());\t\tregisterBeanDefinitionParser(&quot;aspectj-autoproxy&quot;, new AspectJAutoProxyBeanDefinitionParser());\t\tregisterBeanDefinitionDecorator(&quot;scoped-proxy&quot;, new ScopedProxyBeanDefinitionDecorator());\t\t// Only in 2.0 XSD: moved to context namespace as of 2.1\t\tregisterBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser());\t&#125;&#125;\n\n看到了吧，所做的事情基本一样，应该就只是 dubbo 进行了统一的封装，用一个统一的 DubboBeanDefinitionParser 通过传入参数的方式来对不同的标签进行解析。\n具体的标签解析过程DubboBeanDefinitionParser 实现了 BeanDefinitionParser 接口，Spring 容器在遇上对应的标签后就会调用这个接口的 org.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parse(org.w3c.dom.Element, org.springframework.beans.factory.xml.ParserContext) 方法。这个方法又调用了 org.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parse(org.w3c.dom.Element, org.springframework.beans.factory.xml.ParserContext, java.lang.Class&lt;?&gt;, boolean) 方法，这个方法就是分析的重点，详细的过程我已经添加了注释，请在代码中查看。\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parse(org.w3c.dom.Element, org.springframework.beans.factory.xml.ParserContext, java.lang.Class&lt;?&gt;, boolean)\n\n@SuppressWarnings(&quot;unchecked&quot;)private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123;    // 用于承载被解析出来的标签所对应的 bean 的信息    RootBeanDefinition beanDefinition = new RootBeanDefinition();    beanDefinition.setBeanClass(beanClass);    beanDefinition.setLazyInit(false);    // 获取 id 属性    String id = element.getAttribute(&quot;id&quot;);    // id 属性为空后者空串    if (StringUtils.isEmpty(id) &amp;&amp; required) &#123;        String generatedBeanName = element.getAttribute(&quot;name&quot;);        if (StringUtils.isEmpty(generatedBeanName)) &#123;            // 如果是调用的引用了 ProtocolConfig.class 的 DubboBeanDefinitionParser，并且没有 id 和 name 属性，就将解析出来的 beanDefinition 的名字叫做 dubbo            if (ProtocolConfig.class.equals(beanClass)) &#123;                generatedBeanName = &quot;dubbo&quot;;            &#125; else &#123;                // 不是 引用了 ProtocolConfig.class 的 DubboBeanDefinitionParser，就将 beanDefinition 命名为 interface 属性的值                generatedBeanName = element.getAttribute(&quot;interface&quot;);            &#125;        &#125;        // 将 beanClass 的全限定名作为 beanDefinition 的名字        if (StringUtils.isEmpty(generatedBeanName)) &#123;            generatedBeanName = beanClass.getName();        &#125;        // id 也用这个 beanDefinition 的名字        id = generatedBeanName;        int counter = 2;        // 如果已经注册过这个 id 的 beanDefinition，就将 id 后边加上一个数字        while (parserContext.getRegistry().containsBeanDefinition(id)) &#123;            id = generatedBeanName + (counter++);        &#125;    &#125;    // 如果 id 不为空，也不为空串    if (id != null &amp;&amp; id.length() &gt; 0) &#123;        // 已注册过此 id 则报错        if (parserContext.getRegistry().containsBeanDefinition(id)) &#123;            throw new IllegalStateException(&quot;Duplicate spring bean id &quot; + id);        &#125;        // 将 id 和 beanDefinition 注册，此 beanDefinition 用于承载被解析的标签所对应的 bean 的信息        parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);        // 为这个 beanDefinition 添加个 id 属性值        beanDefinition.getPropertyValues().addPropertyValue(&quot;id&quot;, id);    &#125;    // 如果是调用的引用了 ProtocolConfig.class 的 DubboBeanDefinitionParser    if (ProtocolConfig.class.equals(beanClass)) &#123;        // 通过 beanDefinition 的 name 获取 beanDefinition        for (String name : parserContext.getRegistry().getBeanDefinitionNames()) &#123;            BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name);            PropertyValue property = definition.getPropertyValues().getPropertyValue(&quot;protocol&quot;);            if (property != null) &#123;                Object value = property.getValue();                // 如果在已经注册的 beanDefinition 中，具有属性 protocol，属性值为 ProtocolConfig 对象，且这个 Protocol 对象的 name 属性和现在注册的                // 这个 beanDefinition 的 id 相等，那么就就将这个 protocol 属性的值修改为当前 beanDefinition 的运行时引用（估计是为了避免循环引用的问题）                if (value instanceof ProtocolConfig &amp;&amp; id.equals(((ProtocolConfig) value).getName())) &#123;                    definition.getPropertyValues().addPropertyValue(&quot;protocol&quot;, new RuntimeBeanReference(id));                &#125;            &#125;        &#125;    &#125; else if (ServiceBean.class.equals(beanClass)) &#123;        // 此处解析 service 标签        String className = element.getAttribute(&quot;class&quot;);        // 如果 service 标签有 class 属性        if (className != null &amp;&amp; className.length() &gt; 0) &#123;            // 此 classDefinition 用于承载 service 标签所对应的 class 属性值所代表的 class 对象            RootBeanDefinition classDefinition = new RootBeanDefinition();            classDefinition.setBeanClass(ReflectUtils.forName(className));            classDefinition.setLazyInit(false);            // 解析当前标签元素的子元素信息，用 classDefinition 承载解析出来的信息            parseProperties(element.getChildNodes(), classDefinition);            // 为 beanDefinition 添加一个 ref 属性,值为 service 标签 class 属性所对应的 classDefinition            beanDefinition.getPropertyValues().addPropertyValue(&quot;ref&quot;, new BeanDefinitionHolder(classDefinition, id + &quot;Impl&quot;));        &#125;    &#125; else if (ProviderConfig.class.equals(beanClass)) &#123;        // 此处解析 provider 标签        parseNested(element, parserContext, ServiceBean.class, true, &quot;service&quot;, &quot;provider&quot;, id, beanDefinition);    &#125; else if (ConsumerConfig.class.equals(beanClass)) &#123;        // 此处解析 consumer 标签        parseNested(element, parserContext, ReferenceBean.class, false, &quot;reference&quot;, &quot;consumer&quot;, id, beanDefinition);    &#125;    // 用于保存 beanClass 的属性    Set&lt;String&gt; props = new HashSet&lt;&gt;();    ManagedMap parameters = null;    // 遍历 beanClass 的所有方法，根据相应的属性为 beanDefinition 进行填充    for (Method setter : beanClass.getMethods()) &#123;        String name = setter.getName();        // 如果是 public 修饰的参数个数为一的 setter 方法        if (name.length() &gt; 3 &amp;&amp; name.startsWith(&quot;set&quot;)                &amp;&amp; Modifier.isPublic(setter.getModifiers())                &amp;&amp; setter.getParameterTypes().length == 1) &#123;            // 唯一的参数类型            Class&lt;?&gt; type = setter.getParameterTypes()[0];            // setter 方法所对应的属性            String beanProperty = name.substring(3, 4).toLowerCase() + name.substring(4);            // 看这个测试用例就知道这个函数的作用了，均能通过测试            // public void testCamelToSplitName() throws Exception &#123;            //     assertEquals(&quot;ab-cd-ef&quot;, StringUtils.camelToSplitName(&quot;abCdEf&quot;, &quot;-&quot;));            //     assertEquals(&quot;ab-cd-ef&quot;, StringUtils.camelToSplitName(&quot;AbCdEf&quot;, &quot;-&quot;));            //     assertEquals(&quot;ab-cd-ef&quot;, StringUtils.camelToSplitName(&quot;ab-cd-ef&quot;, &quot;-&quot;));            //     assertEquals(&quot;abcdef&quot;, StringUtils.camelToSplitName(&quot;abcdef&quot;, &quot;-&quot;));            // &#125;            String property = StringUtils.camelToSplitName(beanProperty, &quot;-&quot;);            props.add(property);            // check the setter/getter whether match            Method getter = null;            try &#123;                // 获取相应的 getter 方法                getter = beanClass.getMethod(&quot;get&quot; + name.substring(3), new Class&lt;?&gt;[0]);            &#125; catch (NoSuchMethodException e) &#123;                try &#123;                    // 没有 getter 方法，就获取 is 方法                    getter = beanClass.getMethod(&quot;is&quot; + name.substring(3), new Class&lt;?&gt;[0]);                &#125; catch (NoSuchMethodException e2) &#123;                    // ignore, there is no need any log here since some class implement the interface: EnvironmentAware,                    // ApplicationAware, etc. They only have setter method, otherwise will cause the error log during application start up.                &#125;            &#125;            // 如果 getter 方法为空，或者非 public 修饰，或者返回值类型不一致，就继续下一个方法            if (getter == null                    || !Modifier.isPublic(getter.getModifiers())                    || !type.equals(getter.getReturnType())) &#123;                continue;            &#125;            // 如果是 parameters 属性            if (&quot;parameters&quot;.equals(property)) &#123;                // 为 beanDefinition 填充 parameters                parameters = parseParameters(element.getChildNodes(), beanDefinition);            &#125; else if (&quot;methods&quot;.equals(property)) &#123;                // 如果是 methods 属性，为 beanDefinition 填充 methods                parseMethods(id, element.getChildNodes(), beanDefinition, parserContext);            &#125; else if (&quot;arguments&quot;.equals(property)) &#123;                // 如果是 arguments 属性，为 beanDefinition 填充 arguments                parseArguments(id, element.getChildNodes(), beanDefinition, parserContext);            &#125; else &#123;                // 非上述三种情况，直接获取对应的属性值                String value = element.getAttribute(property);                if (value != null) &#123;                    value = value.trim();                    // 获取的属性值不为空，不为空串                    if (value.length() &gt; 0) &#123;                        // 如果 getter 方法对应的属性为 registry，且属性值为 N/A                        if (&quot;registry&quot;.equals(property) &amp;&amp; RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) &#123;                            // 直接构建 RegistryConfig 对象，设置 address 为 N/A                            RegistryConfig registryConfig = new RegistryConfig();                            registryConfig.setAddress(RegistryConfig.NO_AVAILABLE);                            // 为 beanDefinition 添加这个 RegistryConfig 属性值，键为 beanProperty（即 getter 方法去掉 get 子串，并且首字母变小写的结果）                            beanDefinition.getPropertyValues().addPropertyValue(beanProperty, registryConfig);                        &#125; else if (&quot;provider&quot;.equals(property) || &quot;registry&quot;.equals(property) || (&quot;protocol&quot;.equals(property) &amp;&amp; ServiceBean.class.equals(beanClass))) &#123;                            // 如果 setter 方法所代表的属性为 provider、registry（相应的值不为 N/A）或者 protocol 并且当前解析的是 service 标签                            /**                             * For &#x27;provider&#x27; &#x27;protocol&#x27; &#x27;registry&#x27;, keep literal value (should be id/name) and set the value to &#x27;registryIds&#x27; &#x27;providerIds&#x27; protocolIds&#x27;                             * The following process should make sure each id refers to the corresponding instance, here&#x27;s how to find the instance for different use cases:                             * 1. Spring, check existing bean by id, see&#123;@link ServiceBean#afterPropertiesSet()&#125;; then try to use id to find configs defined in remote Config Center                             * 2. API, directly use id to find configs defined in remote Config Center; if all config instances are defined locally, please use &#123;@link org.apache.dubbo.config.ServiceConfig#setRegistries(List)&#125;                             */                            // 把这个属性的值填充到 beanDefinition 中，键名后边补一个 Ids                            beanDefinition.getPropertyValues().addPropertyValue(beanProperty + &quot;Ids&quot;, value);                        &#125; else &#123;                            // 非以上两种情况                            Object reference;                            // 若 setter 方法的参数 type 是基本类型，或者是基本类型所对应的包装类型                            if (isPrimitive(type)) &#123;                                /**                                 * async -&gt; false                                 * timeout -&gt; 0                                 * delay -&gt; 0                                 * version -&gt; 0.0.0                                 * stat -&gt; -1                                 * reliable -&gt; false                                 */                                if (&quot;async&quot;.equals(property) &amp;&amp; &quot;false&quot;.equals(value)                                        || &quot;timeout&quot;.equals(property) &amp;&amp; &quot;0&quot;.equals(value)                                        || &quot;delay&quot;.equals(property) &amp;&amp; &quot;0&quot;.equals(value)                                        || &quot;version&quot;.equals(property) &amp;&amp; &quot;0.0.0&quot;.equals(value)                                        || &quot;stat&quot;.equals(property) &amp;&amp; &quot;-1&quot;.equals(value)                                        || &quot;reliable&quot;.equals(property) &amp;&amp; &quot;false&quot;.equals(value)) &#123;                                    // backward compatibility for the default value in old version&#x27;s xsd                                    value = null;                                &#125;                                reference = value;                            &#125; else if (&quot;onreturn&quot;.equals(property)) &#123;                                // 这里 value 已经通过 String value = element.getAttribute(property); 进行获取了，就是 onreturn 的属性值                                int index = value.lastIndexOf(&quot;.&quot;);                                // onreturn 方法的引用                                String returnRef = value.substring(0, index);                                // onreturn 方法的名字                                String returnMethod = value.substring(index + 1);                                reference = new RuntimeBeanReference(returnRef);                                // 将这个 onreturn 方法的名字保存到 beanDefinition 中去                                beanDefinition.getPropertyValues().addPropertyValue(&quot;onreturnMethod&quot;, returnMethod);                            &#125; else if (&quot;onthrow&quot;.equals(property)) &#123;                                // 处理方式同 onreturn 类似                                int index = value.lastIndexOf(&quot;.&quot;);                                String throwRef = value.substring(0, index);                                String throwMethod = value.substring(index + 1);                                reference = new RuntimeBeanReference(throwRef);                                beanDefinition.getPropertyValues().addPropertyValue(&quot;onthrowMethod&quot;, throwMethod);                            &#125; else if (&quot;oninvoke&quot;.equals(property)) &#123;                                // 处理方式同 onreturn 类似                                int index = value.lastIndexOf(&quot;.&quot;);                                String invokeRef = value.substring(0, index);                                String invokeRefMethod = value.substring(index + 1);                                reference = new RuntimeBeanReference(invokeRef);                                beanDefinition.getPropertyValues().addPropertyValue(&quot;oninvokeMethod&quot;, invokeRefMethod);                            &#125; else &#123;                                // 如果 setter 方法对应的属性为 ref，并且 spring 容器中已经注册过这个 ref 所引用的 bean 的 beanDefinition                                if (&quot;ref&quot;.equals(property) &amp;&amp; parserContext.getRegistry().containsBeanDefinition(value)) &#123;                                    // 那就拿到这个 beanDefinition                                    BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value);                                    // 这个 beanDefinition 必须是单例的                                    if (!refBean.isSingleton()) &#123;                                        throw new IllegalStateException(&quot;The exported service ref &quot; + value + &quot; must be singleton! Please set the &quot; + value + &quot; bean scope to singleton, eg: &lt;bean id=\\&quot;&quot; + value + &quot;\\&quot; scope=\\&quot;singleton\\&quot; ...&gt;&quot;);                                    &#125;                                &#125;                                reference = new RuntimeBeanReference(value);                            &#125;                            // 将 beanProperty 和 reference 这个 kv 对添加到 beanDefinition 中去                            beanDefinition.getPropertyValues().addPropertyValue(beanProperty, reference);                        &#125;                    &#125;                &#125;            &#125;        &#125;    &#125;\n\n在上述方法中，又调用了当前类中的其他方法，大部分都是对于子标签的解析，我也进行了注释，可以通过下边的代码进行查看。\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#isPrimitive\n\n/** * 判断 cls 是否是基本类型，或者基本类型对应的包装类型 * * @param cls 待判断的对象 * @return 判断的结果 */private static boolean isPrimitive(Class&lt;?&gt; cls) &#123;    return cls.isPrimitive() || cls == Boolean.class || cls == Byte.class            || cls == Character.class || cls == Short.class || cls == Integer.class            || cls == Long.class || cls == Float.class || cls == Double.class            || cls == String.class || cls == Date.class || cls == Class.class;&#125;\n\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parseNested\n\n/** * 此方法在解析 provider 标签或者 consumer 标签时会使用到 * * @param element        根标签 * @param parserContext  解析上下文环境 * @param beanClass      分别对应 ServiceBean 和 ReferenceBean * @param required       由上层函数传入 * @param tag            分别对应 service 和 reference * @param property       分别对应 provider 和 consumer * @param ref            即当前待解析标签的 id * @param beanDefinition 当前待解析标签对应的 beanDefinition */private static void parseNested(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required, String tag, String property, String ref, BeanDefinition beanDefinition) &#123;    // 获取子标签    NodeList nodeList = element.getChildNodes();    if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123;        boolean first = true;        for (int i = 0; i &lt; nodeList.getLength(); i++) &#123;            Node node = nodeList.item(i);            if (node instanceof Element) &#123;                // 这里就是分别解析如下两种标签的情况，子标签为 service 或者 reference                // &lt;provider&gt;                //         &lt;service&gt;&lt;service/&gt;                // &lt;provider/&gt;                //                // &lt;consumer&gt;                //         &lt;reference&gt;&lt;reference/&gt;                // &lt;consumer/&gt;                if (tag.equals(node.getNodeName())                        || tag.equals(node.getLocalName())) &#123;                    // 第一次解析的时候，考虑下根标签的 default 属性                    if (first) &#123;                        first = false;                        // 根标签没有 default 属性，或者为空串                        String isDefault = element.getAttribute(&quot;default&quot;);                        if (StringUtils.isEmpty(isDefault)) &#123;                            // 将 default 置为 false                            beanDefinition.getPropertyValues().addPropertyValue(&quot;default&quot;, &quot;false&quot;);                        &#125;                    &#125;                    // 真正解析这个子标签，其实就是个递归调用的过程                    BeanDefinition subDefinition = parse((Element) node, parserContext, beanClass, required);                    if (subDefinition != null &amp;&amp; ref != null &amp;&amp; ref.length() &gt; 0) &#123;                        // 为子标签添加一个对父节点标签所对应 bean 的引用，属性名为 provider 或者 consumer（由当前解析的父标签所决定）                        subDefinition.getPropertyValues().addPropertyValue(property, new RuntimeBeanReference(ref));                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parseProperties\n\n/** * 解析子 property 标签 * @param nodeList 子标签 * @param beanDefinition 带解析的标签所对应的 beanDefinition */private static void parseProperties(NodeList nodeList, RootBeanDefinition beanDefinition) &#123;    if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123;        for (int i = 0; i &lt; nodeList.getLength(); i++) &#123;            // node 代表子标签            Node node = nodeList.item(i);            if (node instanceof Element) &#123;                // 为 property 标签                if (&quot;property&quot;.equals(node.getNodeName())                        || &quot;property&quot;.equals(node.getLocalName())) &#123;                    String name = ((Element) node).getAttribute(&quot;name&quot;);                    // 标签的 name 属性不为空或者空串                    if (name != null &amp;&amp; name.length() &gt; 0) &#123;                        String value = ((Element) node).getAttribute(&quot;value&quot;);                        String ref = ((Element) node).getAttribute(&quot;ref&quot;);                        // property 标签的属性值可能为 value 数值型和 ref 引用型                        if (value != null &amp;&amp; value.length() &gt; 0) &#123;                            // 将 解析出来的 property 属性存入 beanDefinition 中                            beanDefinition.getPropertyValues().addPropertyValue(name, value);                        &#125; else if (ref != null &amp;&amp; ref.length() &gt; 0) &#123;                            // 将 解析出来的 property 属性存入 beanDefinition 中                            beanDefinition.getPropertyValues().addPropertyValue(name, new RuntimeBeanReference(ref));                        &#125; else &#123;                            throw new UnsupportedOperationException(&quot;Unsupported &lt;property name=\\&quot;&quot; + name + &quot;\\&quot;&gt; sub tag, Only supported &lt;property name=\\&quot;&quot; + name + &quot;\\&quot; ref=\\&quot;...\\&quot; /&gt; or &lt;property name=\\&quot;&quot; + name + &quot;\\&quot; value=\\&quot;...\\&quot; /&gt;&quot;);                        &#125;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parseParameters\n\n/** * 如果当前解析的标签有完成的 setter getter is 方法，就用调用此方法来解析子 parameter 标签，返回值为解析出来的 kv 对 * * @param nodeList * @param beanDefinition * @return */@SuppressWarnings(&quot;unchecked&quot;)private static ManagedMap parseParameters(NodeList nodeList, RootBeanDefinition beanDefinition) &#123;    if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123;        ManagedMap parameters = null;        for (int i = 0; i &lt; nodeList.getLength(); i++) &#123;            // 获取子标签元素            Node node = nodeList.item(i);            if (node instanceof Element) &#123;                // 如果子标签为 parameter                if (&quot;parameter&quot;.equals(node.getNodeName())                        || &quot;parameter&quot;.equals(node.getLocalName())) &#123;                    if (parameters == null) &#123;                        parameters = new ManagedMap();                    &#125;                    String key = ((Element) node).getAttribute(&quot;key&quot;);                    String value = ((Element) node).getAttribute(&quot;value&quot;);                    // 如果 parameter 标签存在 hide 属性为 true，就在 key 属性值前边加一个&#x27;.&#x27;                    boolean hide = &quot;true&quot;.equals(((Element) node).getAttribute(&quot;hide&quot;));                    if (hide) &#123;                        key = HIDE_KEY_PREFIX + key;                    &#125;                    // 用 parameters 存储解析出来的 parameter 标签的 key 和 value                    parameters.put(key, new TypedStringValue(value, String.class));                &#125;            &#125;        &#125;        return parameters;    &#125;    return null;&#125;\n\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parseMethods\n\n/** * 解析 method 子标签 * * @param id             当前解析的 beanDefinition 的 id * @param nodeList       子标签元素 * @param beanDefinition 当前解析的 beanDefinition * @param parserContext  解析上下文环境 */@SuppressWarnings(&quot;unchecked&quot;)private static void parseMethods(String id, NodeList nodeList, RootBeanDefinition beanDefinition,                                    ParserContext parserContext) &#123;    if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123;        ManagedList methods = null;        for (int i = 0; i &lt; nodeList.getLength(); i++) &#123;            // 获取每一个子标签元素            Node node = nodeList.item(i);            if (node instanceof Element) &#123;                Element element = (Element) node;                // 如果是 method 标签                if (&quot;method&quot;.equals(node.getNodeName()) || &quot;method&quot;.equals(node.getLocalName())) &#123;                    String methodName = element.getAttribute(&quot;name&quot;);                    // method 标签必须要有 name 属性                    if (StringUtils.isEmpty(methodName)) &#123;                        throw new IllegalStateException(&quot;&lt;dubbo:method&gt; name attribute == null&quot;);                    &#125;                    if (methods == null) &#123;                        methods = new ManagedList();                    &#125;                    // 递归调用解析，此时解析的是 method 标签，返回代表 method 标签的 methodBeanDefinition                    BeanDefinition methodBeanDefinition = parse(((Element) node),                            parserContext, MethodConfig.class, false);                    // 方法标签 beanDefinition 的命名方式                    String name = id + &quot;.&quot; + methodName;                    // 用 BeanDefinitionHolder 对象来承载解析出来的 methodBeanDefinition 实例                    BeanDefinitionHolder methodBeanDefinitionHolder = new BeanDefinitionHolder(                            methodBeanDefinition, name);                    // methods 存储当前标签下的所有 method 标签所对应的 methodBeanDefinitionHolder                    methods.add(methodBeanDefinitionHolder);                &#125;            &#125;        &#125;        if (methods != null) &#123;            // 将解析的 methods 结果存放到根节点所代表的 beanDefinition 中去            beanDefinition.getPropertyValues().addPropertyValue(&quot;methods&quot;, methods);        &#125;    &#125;&#125;\n\n\norg.apache.dubbo.config.spring.schema.DubboBeanDefinitionParser#parseArguments\n\n/** * 跟 parseMethods 方法作用基本一致 * * @param id * @param nodeList * @param beanDefinition * @param parserContext */@SuppressWarnings(&quot;unchecked&quot;)private static void parseArguments(String id, NodeList nodeList, RootBeanDefinition beanDefinition,                                    ParserContext parserContext) &#123;    if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123;        ManagedList arguments = null;        for (int i = 0; i &lt; nodeList.getLength(); i++) &#123;            // 获取每个子标签元素            Node node = nodeList.item(i);            if (node instanceof Element) &#123;                Element element = (Element) node;                // 为 argument 标签                if (&quot;argument&quot;.equals(node.getNodeName()) || &quot;argument&quot;.equals(node.getLocalName())) &#123;                    String argumentIndex = element.getAttribute(&quot;index&quot;);                    if (arguments == null) &#123;                        arguments = new ManagedList();                    &#125;                    // 递归调用进行解析，这里解析的是 argument 标签，返回相应的 beanDefinition                    BeanDefinition argumentBeanDefinition = parse(((Element) node),                            parserContext, ArgumentConfig.class, false);                    // argumentBeanDefinition 的命名规则                    String name = id + &quot;.&quot; + argumentIndex;                    // 包装解析出来的 argumentBeanDefinition                    BeanDefinitionHolder argumentBeanDefinitionHolder = new BeanDefinitionHolder(                            argumentBeanDefinition, name);                    arguments.add(argumentBeanDefinitionHolder);                &#125;            &#125;        &#125;        if (arguments != null) &#123;            // 将解析出来的结果封装到当前解析的父标签所对应的 beanDefinition 中去            beanDefinition.getPropertyValues().addPropertyValue(&quot;arguments&quot;, arguments);        &#125;    &#125;&#125;\n\n总结应该来说，整个的标签解析过程还是很好理解的，但是我不太喜欢 dubbo 的这种一体式的标签解析设计，因为各种标签的解析过程都糅杂在一个方法中了，使得方法非常长，阅读起来也不是很清晰，相比较之下，spring 的标签解析就是各司其职，不同的标签对应不同的标签解析器，这样逻辑很清楚，留下个小坑，以后有时间的话，就把这个 dubbo 的标签解析过程整成类似于 spring 的那种方式。\n标签解析过程完成后，就是对不同标签解析出来的 bean 的作用进行分析了。根据自己使用 dubbo 的过程，决定下一个源码分析的类容就是 org.apache.dubbo.config.spring.ServiceBean。\n","categories":["后台开发"],"tags":["Spring","Dubbo"]},{"title":"看Dubbo源码总结出来的那些小技巧","url":"/2019/05/26/2019-05-26-%E7%9C%8BDubbo%E6%BA%90%E7%A0%81%E6%80%BB%E7%BB%93%E5%87%BA%E6%9D%A5%E7%9A%84%E9%82%A3%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7/","content":"前言好久没有更新 Blog 了，一个重要的原因是抽不出时间呐，因为在看 Dubbo 的源码，到今天总算是把服务发布者和服务调用者的部分给看完了，而这篇文章就是在看 Dubbo 源码中学到的一些小技巧，不是很系统，但是很干货，如果自己看过源码就会更加的印象深刻。在看源码的过程中我还根据自己的理解添加了较为详细的注释，因为个人能力问题，不能保证全部正确，但也还是有一定的参考意义，如果你也是在看 Dubbo 源码的话可以参考一下我的代码注释，地址奉上。\n正文Stream 组合方法\norg.apache.dubbo.common.extension.AdaptiveClassCodeGenerator.hasInvocationArgument\n\nprivate boolean hasInvocationArgument(Method method) &#123;    Class&lt;?&gt;[] pts = method.getParameterTypes();    // 查看 method 是否有 org.apache.dubbo.rpc.Invocation 类型的参数    return Arrays.stream(pts).anyMatch(p -&gt; CLASSNAME_INVOCATION.equals(p.getName()));&#125;\n\n在 return Arrays.stream(pts).anyMatch(p -&gt; CLASSNAME_INVOCATION.equals(p.getName())); 这条语句中，借用了 Arrays 工具类的 stream 方法得到 java.util.stream.Stream 实例，利用这个实例就可以进行类似于 scala 语法的一些函数式编程了。这里的 anyMatch 表示任一匹配的方式，如果找到了任意符合条件的 p，就返回 true，否则返回 false。\n\norg.apache.dubbo.common.extension.AdaptiveClassCodeGenerator#generateInvocationArgumentNullCheck\n\nprivate String generateInvocationArgumentNullCheck(Method method) &#123;    Class&lt;?&gt;[] pts = method.getParameterTypes();    return IntStream.range(0, pts.length).filter(i -&gt; CLASSNAME_INVOCATION.equals(pts[i].getName()))            .mapToObj(i -&gt; String.format(CODE_INVOCATION_ARGUMENT_NULL_CHECK, i, i))            .findFirst().orElse(&quot;&quot;);&#125;\n\n在 return IntStream.range(0, pts.length).filter(i -&gt; CLASSNAME_INVOCATION.equals(pts[i].getName())).mapToObj(i -&gt; String.format(CODE_INVOCATION_ARGUMENT_NULL_CHECK, i, i)).findFirst().orElse(&quot;&quot;); 这条代码中，借用了 Arrays 工具类的 stream 方法得到 java.util.stream.Stream 实例，利用这个实例就可以进行类似于 scala 语法的一些函数式编程了。这里的 filter 表示过滤，即找到满足 CLASSNAME_INVOCATION.equals(pts[i].getName()) 的 i，mapToObj 函数表示映射，即将过滤出来的 i 通过映射转换为 String.format(CODE_INVOCATION_ARGUMENT_NULL_CHECK, i, i)，findFirst 表示映射的终止条件，即找到任意 i 即返回，而 orElse 则是没有找到符合条件的 i 的处理方式，直接返回 “”。\n\norg.apache.dubbo.common.extension.AdaptiveClassCodeGenerator#generateReturnAndInvocation\n\nprivate String generateReturnAndInvocation(Method method) &#123;    // 如果方法的返回类型为 void，拼接 return    String returnStatement = method.getReturnType().equals(void.class) ? &quot;&quot; : &quot;return &quot;;    String args = Arrays.stream(method.getParameters()).map(Parameter::getName).collect(Collectors.joining(&quot;, &quot;));    return returnStatement + String.format(&quot;extension.%s(%s);\\n&quot;, method.getName(), args);&#125;\n\n在 String args = Arrays.stream(method.getParameters()).map(Parameter::getName).collect(Collectors.joining(&quot;, &quot;)); 这条代码中，借用了 Arrays 工具类的 stream 方法得到 java.util.stream.Stream 实例，利用这个实例就可以进行类似于 scala 语法的一些函数式编程了。这里的 map 为映射函数，即将 stream 中的每一个元素调用 Parameter::getName 函数进行处理，这里的 Parameter::getName 代表函数引用，最后的 collect 表示将所有的处理结果进行搜集，collect 的参数表示搜集的方式。\n一种获取 ClassLoader 的方式\norg.apache.dubbo.common.utils.ClassUtils#getClassLoader(java.lang.Class&lt;?&gt;)\n\npublic static ClassLoader getClassLoader(Class&lt;?&gt; clazz) &#123;    ClassLoader cl = null;    try &#123;        // 返回 Thread 的 contextClassLoader        cl = Thread.currentThread().getContextClassLoader();    &#125; catch (Throwable ex) &#123;        // Cannot access thread context ClassLoader - falling back to system class loader...    &#125;    if (cl == null) &#123;        // No thread context class loader -&gt; use class loader of this class.        // 返回 class 的类加载器，如果是 bootstrap 类加载器，将会返回 null        cl = clazz.getClassLoader();        if (cl == null) &#123;            // getClassLoader() returning null indicates the bootstrap ClassLoader            try &#123;                cl = ClassLoader.getSystemClassLoader();            &#125; catch (Throwable ex) &#123;                // Cannot access system ClassLoader - oh well, maybe the caller can live with null...            &#125;        &#125;    &#125;    return cl;&#125;\n\n这是一个获取类加载器的方式，有三个优先级，先是获取当前线程的 contextClassLoader，如果没有获取到，尝试获取加载该类 clazz 的类加载器，注意如果加载 clazz 的类加载器是 bootstrap 类加载器，那么返回值为 null，因为这个类加载器是通过 c++ 语言实现，通过 java 进行获取都是为 null。最后便是获取 SystemClassLoader，这里已经可以确定是获取的 bootstrap 类加载器了。\n增强版的 isPrimitives 方法\norg.apache.dubbo.common.utils.ReflectUtils#isPrimitives\n\npublic static boolean isPrimitives(Class&lt;?&gt; cls) &#123;    if (cls.isArray()) &#123;        return isPrimitive(cls.getComponentType());    &#125;    return isPrimitive(cls);&#125;public static boolean isPrimitive(Class&lt;?&gt; cls) &#123;    return cls.isPrimitive() || cls == String.class || cls == Boolean.class || cls == Character.class            || Number.class.isAssignableFrom(cls) || Date.class.isAssignableFrom(cls);&#125;\n\nisPrimitives 一个增强版本的判断 class 是否是原始类型的函数，在 jdk 类库中，直接有一个函数 java.lang.Class#isPrimitive 就可以直接判断一个 class 实例是否是九种原始基本类型中的一种。在 isPrimitives 中增加了对 Array、String、Boolean、Charater、Number、Date 几种类型的判断支持。这里 Array 的判断是通过获取 java.lang.Class#getComponentType 来进行的。\nCurator 框架的使用\norg.apache.dubbo.remoting.zookeeper.curator.CuratorZookeeperClient\n\npublic CuratorZookeeperClient(URL url) &#123;    // 保存 url 地址    super(url);    try &#123;        int timeout = url.getParameter(TIMEOUT_KEY, 5000);        CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()                // 备用地址                .connectString(url.getBackupAddress())                // 重试策略                .retryPolicy(new RetryNTimes(1, 1000))                // 连接超时策略                .connectionTimeoutMs(timeout);        // 获取授权信息        String authority = url.getAuthority();        if (authority != null &amp;&amp; authority.length() &gt; 0) &#123;            builder = builder.authorization(&quot;digest&quot;, authority.getBytes());        &#125;        // 就是根据 builder 获取一个 CuratorFrameworkImpl        client = builder.build();        // 添加一个连接监听器        client.getConnectionStateListenable().addListener(new ConnectionStateListener() &#123;            @Override            // 如果连接状态发生改变，就会执行此方法            public void stateChanged(CuratorFramework client, ConnectionState state) &#123;                if (state == ConnectionState.LOST) &#123;                    // 断开连接                    CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);                &#125; else if (state == ConnectionState.CONNECTED) &#123;                    // 连接成功                    CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);                &#125; else if (state == ConnectionState.RECONNECTED) &#123;                    // 重连                    CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);                &#125;            &#125;        &#125;);        client.start();    &#125; catch (Exception e) &#123;        throw new IllegalStateException(e.getMessage(), e);    &#125;&#125;\n\n这里我们重点关注 client = builder.build(); 这一条语句，返回值 client 其实就是 CuratorFrameworkImpl 实例，CuratorFramework 提供了一套高级的API，简化了 ZooKeeper 的操作，它增加了很多使用ZooKeeper开发的特性，可以处理 ZooKeeper 集群复杂的连接管理和重试机制。这些特性包括：\n1、 自动化的连接管理: 重新建立到 ZooKeeper 的连接和重试机制存在一些潜在的错误 case。 Curator 帮助你处理这些事情，对你来说是透明的。\n2、 简化了原生的ZooKeeper的方法，提供了一个现代的流式接口。\n3、 提供了Recipes实现： 如前面的文章介绍的那样，基于这些Recipes可以创建很多复杂的分布式应用。\nCurator 框架通过 CuratorFrameworkFactory 以工厂模式和 builder 模式创建 CuratorFramework 实例。 CuratorFramework 实例都是线程安全的，你应该在你的应用中共享同一个 CuratorFramework 实例。\n工厂方法 newClient() 提供了一个简单方式创建实例。而 Builder 提供了更多的参数控制。一旦你创建了一个 CuratorFramework 实例，你必须调用它的 start() 启动，在应用退出时调用 close() 方法关闭。上边的代码便是 dubbo 对 实例，CuratorFramework 的一个使用示例。\n一种可用端口的获取方式\norg.apache.dubbo.common.utils.NetUtils#getAvailablePort(int)\n\npublic static int getAvailablePort() &#123;    try (ServerSocket ss = new ServerSocket()) &#123;        // 这种情况就会产生一个随机的端口        ss.bind(null);        return ss.getLocalPort();    &#125; catch (IOException e) &#123;        return getRandomPort();    &#125;&#125;public static int getAvailablePort(int port) &#123;    if (port &lt;= 0) &#123;        // 这里是传入的 default 端口小于等于 0 的情况        return getAvailablePort();    &#125;    for (int i = port; i &lt; MAX_PORT; i++) &#123;        // 从 port 端口逐个向上找可以使用的端口        try (ServerSocket ss = new ServerSocket(i)) &#123;            return i;        &#125; catch (IOException e) &#123;            // continue        &#125;    &#125;    return port;&#125;\n\n这里获取可用端口使用了两种策略，根据传入参数的不同情况分别采用不同策略，首先是传入端口小于等于 0 的情况，通过新建一个 ServerSocket 实例 ServerSocket ss = new ServerSocket()，再将它绑定到一个 null endPoint，这时通过 ss.getLocalPort() 便能获取到一个系统随机指定的端口了。如果传入的端口是大于 0 的，那么采用的策略就是逐次递增端口号，通过 ServerSocket ss = new ServerSocket(i) 来判定当前端口是否可用。\nFuture 和 Map 的组合操作\norg.apache.dubbo.rpc.filter.AccessLogFilter#log\n\nprivate void log(String accessLog, AccessLogData accessLogData) &#123;    // 如果 LOG_ENTRIES 中没有键为 accessLog 的记录，就新建一个记录，以 accessLog 为键存入 LOG_ENTRIES 中    Set&lt;AccessLogData&gt; logSet = LOG_ENTRIES.computeIfAbsent(accessLog, k -&gt; new ConcurrentHashSet&lt;&gt;());    if (logSet.size() &lt; LOG_MAX_BUFFER) &#123;        // accessLog 所对应的 AccessLogData 不应该超过 5000 条        logSet.add(accessLogData);    &#125; else &#123;        //TODO we needs use force writing to file so that buffer gets clear and new log can be written.        logger.warn(&quot;AccessLog buffer is full skipping buffer &quot;);    &#125;&#125;\n\nSet&lt;AccessLogData&gt; logSet = LOG_ENTRIES.computeIfAbsent(accessLog, k -&gt; new ConcurrentHashSet&lt;&gt;()); 这条代码的逻辑很简单，但是它利用了 java 的新特性，通过传入函数参数，简化了操作。computeIfAbsent 这个函数，先判断 map 中是否有 accessLog 这条记录，如果没有就新建一条记录，以 accessLog 为键进行存储，等价的就是一个 if-else 操作。\n\norg.apache.dubbo.rpc.AsyncRpcResult#thenApplyWithContext\n\npublic void thenApplyWithContext(Function&lt;Result, Result&gt; fn) &#123;    this.resultFuture = resultFuture.thenApply(fn.compose(beforeContext).andThen(afterContext));&#125;\n\n这条代码看起来很简单对吧，但是实现的功能却比较复杂，传入的参数是一个 Function 实例，需要注意的是它的 compose 方法，这个方法意思是说构建出一个复合函数，以 fn.compose(beforeContext) 为例，那么它的意思是对于调用者来说，先使用 beforeContext 函数来处理传入的参数（即调用者本身），然后使用 fn 函数对 beforeContext 函数处理的结果进行处理。后边的 andThen 意思基本一致，只不过是先调用 andThen 方法的调用者对参数进行处理，而后再将处理的结果交由 afterContext 函数进行处理。结合上述的例子来看，那么基本的调用顺序就是：resultFuture -&gt; beforeContext &#x3D; result1，result1 -&gt; fn &#x3D; result2，result2 -&gt; afterContext &#x3D; result3，result3 就是最终要返回的结果。\nOptional 的使用\norg.apache.dubbo.config.AbstractInterfaceConfig#startConfigCenter\n\nvoid startConfigCenter() &#123;    // 这里对应 config-center 标签，存储在 ServiceBean 中    if (configCenter == null) &#123;        // java.util.Optional.ifPresent 如果值存在，就调用函数，否则什么都不干        ConfigManager.getInstance().getConfigCenter().ifPresent(cc -&gt; this.configCenter = cc);    &#125;    // 初次调用时，如果没有配置 config-center 标签，则这里是为 null 的    if (this.configCenter != null) &#123;        // TODO there may have duplicate refresh        this.configCenter.refresh();        // 准备运行环境        prepareEnvironment();    &#125;    // 单例获取 ConfigManager，依据具体的配置信息对相应的 config 进行属性的更新    ConfigManager.getInstance().refreshAll();&#125;public Optional&lt;ConfigCenterConfig&gt; getConfigCenter() &#123;    return Optional.ofNullable(configCenter);&#125;\n\n这里关注 ConfigManager.getInstance().getConfigCenter().ifPresent(cc -&gt; this.configCenter = cc); 这条代码，getConfigCenter 方法返回的是一个 Optional 实例，它有一个 ifPresent 方法，参数是一个 @FunctionalInterface 注解标注的函数式接口，这样我们在 ifPresent 只需要传入一个函数进去，返回的 Optional 就能根据它自身的状态来决定是否要应用这个函数，这个过程其实就是简化了我们自己手写 if-else 判断代码的过程。\nVersion 的获取方式\norg.apache.dubbo.common.Version#getVersion(java.lang.Class&lt;?&gt;, java.lang.String)\n\npublic static String getVersion(Class&lt;?&gt; cls, String defaultVersion) &#123;    try &#123;        // find version info from MANIFEST.MF first        // 根据 cls 查找 version 信息，存储在 MANIFEST.MF 文件中        Package pkg = cls.getPackage();        String version = null;        if (pkg != null) &#123;            version = pkg.getImplementationVersion();   // 此为获取 MANIFEST.MF 文件中版本信息的函数，比如 Implementation-Version:            if (!StringUtils.isEmpty(version)) &#123;                return version;            &#125;            version = pkg.getSpecificationVersion();    // 此为获取 MANIFEST.MF 文件中版本信息的函数，比如 Specification-Version            if (!StringUtils.isEmpty(version)) &#123;                return version;            &#125;        &#125;        // guess version fro jar file name if nothing&#x27;s found from MANIFEST.MF        // 没能从 MANIFEST.MF 文件中获取到 version 信息        CodeSource codeSource = cls.getProtectionDomain().getCodeSource();        // 估计是由于某种原因，没能获取到 codeSource，那就使用参数传递的 defaultVersion 信息        if (codeSource == null) &#123;            logger.info(&quot;No codeSource for class &quot; + cls.getName() + &quot; when getVersion, use default version &quot; + defaultVersion);            return defaultVersion;        &#125;        // 那就根据 jar 包推测版本信息        String file = codeSource.getLocation().getFile();        if (!StringUtils.isEmpty(file) &amp;&amp; file.endsWith(&quot;.jar&quot;)) &#123;            version = getFromFile(file);        &#125;        // return default version if no version info is found        return StringUtils.isEmpty(version) ? defaultVersion : version;    &#125; catch (Throwable e) &#123;        // return default version when any exception is thrown        logger.error(&quot;return default version, ignore exception &quot; + e.getMessage(), e);        return defaultVersion;    &#125;&#125;\n\n这是 dubbo 公共包中用于获取版本信息的函数，该函数优先从 cls 所在 package 中的 MANIFEST.MF 文件中获取版本信息，有 Implementation-Version 和 Specification-Version 两种情况，分别对应 getImplementationVersion 和 getSpecificationVersion 函数，如果在 MANIFEST.MF 文件中没有能获取到版本信息，那么该函数就会根据该 cls 所在的 jar 包来获取相应的版本信息，如果还是没有获取到的话，那么就会直接使用函数的默认版本参数值。\n动态代码和字节码的生成\norg.apache.dubbo.common.bytecode.Wrapper#makeWrapper\n\nprivate static Wrapper makeWrapper(Class&lt;?&gt; c) &#123;    // 不能对 9 中基本类型的包装类型构建 Wrapper    if (c.isPrimitive()) &#123;        throw new IllegalArgumentException(&quot;Can not create wrapper for primitive type: &quot; + c);    &#125;    String name = c.getName();    ClassLoader cl = ClassUtils.getClassLoader(c);    // 主要是对三个函数进行拼接    // setPropertyValue    // getPropertyValue    // invokeMethod    // public void setPropertyValue (Object o, String n, Object v)&#123;    StringBuilder c1 = new StringBuilder(&quot;public void setPropertyValue(Object o, String n, Object v)&#123; &quot;);    // public Object getPropertyValue(Object o, String n)&#123;    StringBuilder c2 = new StringBuilder(&quot;public Object getPropertyValue(Object o, String n)&#123; &quot;);    // public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException&#123;    StringBuilder c3 = new StringBuilder(&quot;public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws &quot; + InvocationTargetException.class.getName() + &quot;&#123; &quot;);    // 根据 name 构造出这样的代码    // public void setPropertyValue (Object o, String n, Object v)&#123;    //     org.apache.dubbo.demo.DemoService w;    //     try &#123;    //         w = ((org.apache.dubbo.demo.DemoService) $1);    //     &#125; catch (Throwable e) &#123;    //         throw new IllegalArgumentException(e);    //     &#125;    c1.append(name).append(&quot; w; try&#123; w = ((&quot;).append(name).append(&quot;)$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;&quot;);    // public Object getPropertyValue (Object o, String n)&#123;    //     org.apache.dubbo.demo.DemoService w;    //     try &#123;    //         w = ((org.apache.dubbo.demo.DemoService) $1);    //     &#125; catch (Throwable e) &#123;    //         throw new IllegalArgumentException(e);    //     &#125;    c2.append(name).append(&quot; w; try&#123; w = ((&quot;).append(name).append(&quot;)$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;&quot;);    // public Object invokeMethod (Object o, String n, Class[]p, Object[]v) throws    // java.lang.reflect.InvocationTargetException &#123;    //     org.apache.dubbo.demo.DemoService w;    //     try &#123;    //         w = ((org.apache.dubbo.demo.DemoService) $1);    //     &#125; catch (Throwable e) &#123;    //         throw new IllegalArgumentException(e);    //     &#125;    c3.append(name).append(&quot; w; try&#123; w = ((&quot;).append(name).append(&quot;)$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;&quot;);    // 保存字段的 name 和 type    Map&lt;String, Class&lt;?&gt;&gt; pts = new HashMap&lt;&gt;(); // &lt;property name, property types&gt;    // 保存方法的 desc（签名） 和 instance    // get method desc.    // int do(int arg1) =&gt; &quot;do(I)I&quot;    // void do(String arg1,boolean arg2) =&gt; &quot;do(Ljava/lang/String;Z)V&quot;    Map&lt;String, Method&gt; ms = new LinkedHashMap&lt;&gt;(); // &lt;method desc, Method instance&gt;    // 保存方法名    List&lt;String&gt; mns = new ArrayList&lt;&gt;(); // method names.    // 保存声明方法的类名    List&lt;String&gt; dmns = new ArrayList&lt;&gt;(); // declaring method names.    // get all public field.    for (Field f : c.getFields()) &#123;        String fn = f.getName();        Class&lt;?&gt; ft = f.getType();        // 避开 static 和 transient 修饰的字段        if (Modifier.isStatic(f.getModifiers()) || Modifier.isTransient(f.getModifiers())) &#123;            continue;        &#125;        // 根据 field 进行构建        // public void setPropertyValue (Object o, String n, Object v)&#123;        //     org.apache.dubbo.demo.DemoService w;        //     try &#123;        //         w = ((org.apache.dubbo.demo.DemoService) $1);        //     &#125; catch (Throwable e) &#123;        //         throw new IllegalArgumentException(e);        //     &#125;        //     if( $2.equals(&quot;serviceName&quot;))&#123;        //         w.serviceName=(org.apache.dubbo.demo.DemoService) $3;        //         return;        //     &#125;        c1.append(&quot; if( $2.equals(\\&quot;&quot;).append(fn).append(&quot;\\&quot;) )&#123; w.&quot;).append(fn).append(&quot;=&quot;).append(arg(ft, &quot;$3&quot;)).append(&quot;; return; &#125;&quot;);        // public Object getPropertyValue (Object o, String n)&#123;        //     org.apache.dubbo.demo.DemoService w;        //     try &#123;        //         w = ((org.apache.dubbo.demo.DemoService) $1);        //     &#125; catch (Throwable e) &#123;        //         throw new IllegalArgumentException(e);        //     &#125;        //     if( $2.equals(&quot;serviceName&quot;))&#123;        //         return ($w)w.serviceName;        //     &#125;        c2.append(&quot; if( $2.equals(\\&quot;&quot;).append(fn).append(&quot;\\&quot;) )&#123; return ($w)w.&quot;).append(fn).append(&quot;; &#125;&quot;);        // 保存字段的 name 和 type        pts.put(fn, ft);    &#125;    Method[] methods = c.getMethods();    // get all public method.    // methods 方法不为空，且不全为 Object 声明的方法    boolean hasMethod = hasMethods(methods);    if (hasMethod) &#123;        // 通过 methods 对 c3 进行构造        c3.append(&quot; try&#123;&quot;);        for (Method m : methods) &#123;            //ignore Object&#x27;s method.            if (m.getDeclaringClass() == Object.class) &#123;                continue;            &#125;            // 通过方法名进行构造            String mn = m.getName();            c3.append(&quot; if( \\&quot;&quot;).append(mn).append(&quot;\\&quot;.equals( $2 ) &quot;);            int len = m.getParameterTypes().length;            // 补上方法参数信息            // public Object invokeMethod (Object o, String n, Class[]p, Object[]v) throws java.lang.reflect.InvocationTargetException &#123;            //     org.apache.dubbo.demo.DemoService w;            //     try &#123;            //         w = ((org.apache.dubbo.demo.DemoService) $1);            //     &#125; catch (Throwable e) &#123;            //         throw new IllegalArgumentException(e);            //     &#125;            //     try &#123;            //         if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 1            c3.append(&quot; &amp;&amp; &quot;).append(&quot; $3.length == &quot;).append(len);            boolean override = false;            for (Method m2 : methods) &#123;                // 如果有跟当前方法同名的其它方法，即存在重写（overwrite）                if (m != m2 &amp;&amp; m.getName().equals(m2.getName())) &#123;                    override = true;                    break;                &#125;            &#125;            if (override) &#123;                if (len &gt; 0) &#123;                    for (int l = 0; l &lt; len; l++) &#123;                        // 补上方法参数信息                        // public Object invokeMethod (Object o, String n, Class[]p, Object[]v) throws java.lang.reflect.InvocationTargetException &#123;                        //     org.apache.dubbo.demo.DemoService w;                        //     try &#123;                        //         w = ((org.apache.dubbo.demo.DemoService) $1);                        //     &#125; catch (Throwable e) &#123;                        //         throw new IllegalArgumentException(e);                        //     &#125;                        //     try &#123;                        //         if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 1 &amp;&amp; $3[l].getName().equals(&quot;java.lang.String&quot;))&#123;;                        c3.append(&quot; &amp;&amp; &quot;).append(&quot; $3[&quot;).append(l).append(&quot;].getName().equals(\\&quot;&quot;)                                .append(m.getParameterTypes()[l].getName()).append(&quot;\\&quot;)&quot;);                    &#125;                &#125;            &#125;            // public Object invokeMethod (Object o, String n, Class[]p, Object[]v) throws java.lang.reflect.InvocationTargetException &#123;            //     org.apache.dubbo.demo.DemoService w;            //     try &#123;            //         w = ((org.apache.dubbo.demo.DemoService) $1);            //     &#125; catch (Throwable e) &#123;            //         throw new IllegalArgumentException(e);            //     &#125;            //     try &#123;            //         if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 1) &#123;            c3.append(&quot; ) &#123; &quot;);            // 拼接方法的返回值            if (m.getReturnType() == Void.TYPE) &#123;                c3.append(&quot; w.&quot;).append(mn).append(&#x27;(&#x27;).append(args(m.getParameterTypes(), &quot;$4&quot;)).append(&quot;);&quot;).append(&quot; return null;&quot;);            &#125; else &#123;                c3.append(&quot; return ($w)w.&quot;).append(mn).append(&#x27;(&#x27;).append(args(m.getParameterTypes(), &quot;$4&quot;)).append(&quot;);&quot;);            &#125;            // 拼接完返回值后            // public Object invokeMethod (Object o, String n, Class[]p, Object[]v) throws java.lang.reflect.InvocationTargetException &#123;            //     org.apache.dubbo.demo.DemoService w;            //     try &#123;            //         w = ((org.apache.dubbo.demo.DemoService) $1);            //     &#125; catch (Throwable e) &#123;            //         throw new IllegalArgumentException(e);            //     &#125;            //     try &#123;            //         if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 1) &#123;            //             return ($w) w.sayHello((java.lang.String) $4[0]);            //         &#125;            c3.append(&quot; &#125;&quot;);            // 保存拼接的方法名            mns.add(mn);            if (m.getDeclaringClass() == c) &#123;                // 保存声明方法的类名                dmns.add(mn);            &#125;            // 保存方法的签名和方法实例            // get method desc.            // int do(int arg1) =&gt; &quot;do(I)I&quot;            // void do(String arg1,boolean arg2) =&gt; &quot;do(Ljava/lang/String;Z)V&quot;            ms.put(ReflectUtils.getDesc(m), m);        &#125;        c3.append(&quot; &#125; catch(Throwable e) &#123; &quot;);        c3.append(&quot;     throw new java.lang.reflect.InvocationTargetException(e); &quot;);        c3.append(&quot; &#125;&quot;);    &#125;    // 补全括号即剩余信息    // o 方法调用的目标对象，n 方法名，p 方法的参数类型，v 方法的参数    // public Object invokeMethod (Object o, String n, Class[]p, Object[]v) throws java.lang.reflect.InvocationTargetException &#123;    //     org.apache.dubbo.demo.DemoService w;    //     try &#123;    //         w = ((org.apache.dubbo.demo.DemoService) $1);    //     &#125; catch (Throwable e) &#123;    //         throw new IllegalArgumentException(e);    //     &#125;    //     try &#123;    //         if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 1) &#123;    //             return ($w) w.sayHello((java.lang.String) $4[0]);    //         &#125;    //     &#125; catch (Throwable e) &#123;    //         throw new java.lang.reflect.InvocationTargetException(e);    //     &#125;    //     throw new org.apache.dubbo.common.bytecode.NoSuchMethodException(&quot;Not found method \\&quot;&quot; + $2 + &quot;\\&quot; in class org.apache.dubbo.demo.DemoService.&quot;);    // &#125;    c3.append(&quot; throw new &quot; + NoSuchMethodException.class.getName() + &quot;(\\&quot;Not found method \\\\\\&quot;\\&quot;+$2+\\&quot;\\\\\\&quot; in class &quot; + c.getName() + &quot;.\\&quot;); &#125;&quot;);    // deal with get/set method.    Matcher matcher;    // 这里 ms 保存的是接口中非 Object 类方法的签名和方法实例    for (Map.Entry&lt;String, Method&gt; entry : ms.entrySet()) &#123;        // 方法签名        String md = entry.getKey();        // 方法实例        Method method = entry.getValue();        // 匹配 getter 方法        if ((matcher = ReflectUtils.GETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123;            String pn = propertyName(matcher.group(1));            c2.append(&quot; if( $2.equals(\\&quot;&quot;).append(pn).append(&quot;\\&quot;) )&#123; return ($w)w.&quot;).append(method.getName()).append(&quot;(); &#125;&quot;);            pts.put(pn, method.getReturnType());        &#125; else if ((matcher = ReflectUtils.IS_HAS_CAN_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123;            // 匹配 is、has、can 方法            String pn = propertyName(matcher.group(1));            c2.append(&quot; if( $2.equals(\\&quot;&quot;).append(pn).append(&quot;\\&quot;) )&#123; return ($w)w.&quot;).append(method.getName()).append(&quot;(); &#125;&quot;);            pts.put(pn, method.getReturnType());        &#125; else if ((matcher = ReflectUtils.SETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123;            // 匹配 setter 方法            Class&lt;?&gt; pt = method.getParameterTypes()[0];            String pn = propertyName(matcher.group(1));            c1.append(&quot; if( $2.equals(\\&quot;&quot;).append(pn).append(&quot;\\&quot;) )&#123; w.&quot;).append(method.getName()).append(&quot;(&quot;).append(arg(pt, &quot;$3&quot;)).append(&quot;); return; &#125;&quot;);            pts.put(pn, pt);        &#125;    &#125;    // c1 的拼接结果    // public void setPropertyValue (Object o, String n, Object v)&#123;    //     org.apache.dubbo.demo.DemoService w;    //     try &#123;    //         w = ((org.apache.dubbo.demo.DemoService) $1);    //     &#125; catch (Throwable e) &#123;    //         throw new IllegalArgumentException(e);    //     &#125;    //     throw new org.apache.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \\&quot;&quot; + $2 + &quot;\\&quot; field or setter method in class org.apache.dubbo.demo.DemoService.&quot;);    // &#125;    c1.append(&quot; throw new &quot; + NoSuchPropertyException.class.getName() + &quot;(\\&quot;Not found property \\\\\\&quot;\\&quot;+$2+\\&quot;\\\\\\&quot; field or setter method in class &quot; + c.getName() + &quot;.\\&quot;); &#125;&quot;);    // c2 的拼接结果    //  public Object getPropertyValue (Object o, String n)&#123;    //      org.apache.dubbo.demo.DemoService w;    //      try &#123;    //          w = ((org.apache.dubbo.demo.DemoService) $1);    //      &#125; catch (Throwable e) &#123;    //          throw new IllegalArgumentException(e);    //      &#125;    //      throw new org.apache.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \\&quot;&quot; + $2 + &quot;\\&quot; field or setter method in class org.apache.dubbo.demo.DemoService.&quot;);    //  &#125;    c2.append(&quot; throw new &quot; + NoSuchPropertyException.class.getName() + &quot;(\\&quot;Not found property \\\\\\&quot;\\&quot;+$2+\\&quot;\\\\\\&quot; field or setter method in class &quot; + c.getName() + &quot;.\\&quot;); &#125;&quot;);    // make class    // 对构建的 wrapper 类进行计数    long id = WRAPPER_CLASS_COUNTER.getAndIncrement();    // 根据 classLoader 构建 ClassGenerator    ClassGenerator cc = ClassGenerator.newInstance(cl);    // 补全一些类信息    cc.setClassName((Modifier.isPublic(c.getModifiers()) ? Wrapper.class.getName() : c.getName() + &quot;$sw&quot;) + id);    cc.setSuperClass(Wrapper.class);    cc.addDefaultConstructor();    cc.addField(&quot;public static String[] pns;&quot;); // property name array.    cc.addField(&quot;public static &quot; + Map.class.getName() + &quot; pts;&quot;); // property type map.    cc.addField(&quot;public static String[] mns;&quot;); // all method name array.    cc.addField(&quot;public static String[] dmns;&quot;); // declared method name array.    for (int i = 0, len = ms.size(); i &lt; len; i++) &#123;    // 方法的参数类型数组，有几个函数就会有几个数组        cc.addField(&quot;public static Class[] mts&quot; + i + &quot;;&quot;);    &#125;    cc.addMethod(&quot;public String[] getPropertyNames()&#123; return pns; &#125;&quot;);    cc.addMethod(&quot;public boolean hasProperty(String n)&#123; return pts.containsKey($1); &#125;&quot;);    cc.addMethod(&quot;public Class getPropertyType(String n)&#123; return (Class)pts.get($1); &#125;&quot;);    cc.addMethod(&quot;public String[] getMethodNames()&#123; return mns; &#125;&quot;);    cc.addMethod(&quot;public String[] getDeclaredMethodNames()&#123; return dmns; &#125;&quot;);    cc.addMethod(c1.toString());    cc.addMethod(c2.toString());    cc.addMethod(c3.toString());    try &#123;        // 根据 ClassGenerator 生成真正的 Class 对象        Class&lt;?&gt; wc = cc.toClass();        // setup static field.        // 根据上边获取的信息对 Class 对象的某些属性进行填充        // 字段的 name 和 type        wc.getField(&quot;pts&quot;).set(null, pts);        // pns 集合专门用来保存字段的名字        wc.getField(&quot;pns&quot;).set(null, pts.keySet().toArray(new String[0]));        // mns 集合专门用来保存方法名        wc.getField(&quot;mns&quot;).set(null, mns.toArray(new String[0]));        // dmns 集合专门用来保存方法的声明类        wc.getField(&quot;dmns&quot;).set(null, dmns.toArray(new String[0]));        int ix = 0;        // ms 保存的是方法签名和方法实例        // 遍历方法实例        for (Method m : ms.values()) &#123;            // mts 字段用来保存方法的参数类型            wc.getField(&quot;mts&quot; + ix++).set(null, m.getParameterTypes());        &#125;        // 返回构建的 Wrapper 实例        return (Wrapper) wc.newInstance();    &#125; catch (RuntimeException e) &#123;        throw e;    &#125; catch (Throwable e) &#123;        throw new RuntimeException(e.getMessage(), e);    &#125; finally &#123;        // 对相关资源进行释放        cc.release();        ms.clear();        mns.clear();        dmns.clear();    &#125;&#125;\n\n这是 dubbo 用于根据服务接口生成对应 Wrapper 实例的代码，是一个动态代码生成的例子，过程非常的冗长，但是它所要实现的目的很简单，主要是三个方法 setPropertyValue、getPropertyValue、invokeMethod，当然还有几个和服务接口类相关的字段，比如说 public static String[] pns; 用于存储字段的类型名、public static java.util.Map pts; 用于保存字段的名字和类型对、public static String[] mns; 用于保存方法名、public static String[] dmns; 用于保存方法声明的类名、public static Class[] mts0; 用于保存方法的参数类型，这个数字 0 代表方法的序列。再有就是用于获取这些字段的 getter 方法，内容比较多，在下边的代码框中统一贴出。以上这些都是生成的 Wrapper 实例的代码，属于动态生成的代码，除此之外，代码还根据相应的接口信息，对相关的字段内容进行了统计和填充比如 wc.getField(&quot;pts&quot;).set(null, pts);、 wc.getField(&quot;pns&quot;).set(null, pts.keySet().toArray(new String[0])); 等代码都是将统计的内容添加到将要生成的 Wrapper 类的字段中去。至于是如何通过动态代码生成相应的 Class 类，就要靠 org.apache.dubbo.common.bytecode.ClassGenerator 这个类了，底层的原理暂时没有了解，大致猜测是使用的 Javassit 相关的字节码生成技术，这是属于 java 中比较靠底层的技术了，暂时是没有精力去深入了解了，暂且挖个坑吧。在通过 ClassGenerator 生成了对应的 Class 对象后，就是构建 Wrapper 实例，这个就跟使用普通的 Class 对象一样了，所以这里的技术难点就是在于如何生成动态代码，和如何根据动态代码来生成相应的 Class 对象了。\n一种特殊的静态字段的初始化方式\norg.apache.dubbo.rpc.protocol.injvm.InjvmProtocol#getInjvmProtocol\n\nprivate static InjvmProtocol INSTANCE;public InjvmProtocol() &#123;    INSTANCE = this;&#125;public static InjvmProtocol getInjvmProtocol() &#123;    if (INSTANCE == null) &#123; // 加载的过程会调用对应 class 的 newInstance 方法，就会对 INSTANCE 进行初始化        ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(InjvmProtocol.NAME); // load    &#125;    return INSTANCE;&#125;\n\n这是 dubbo 获取 InjvmProtocol 的方法，获取的方式是先从 INSTANCE 缓存中获取，如果为空的话，就会执行 ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(InjvmProtocol.NAME); 这条语句，然后再返回 INSTANCE，需要注意的是这里好像并么有对 INSTANCE 进行赋值，如果 INSTANCE 为空，那么执行上述代码后 INSTANCE 也一定为空不是吗？但是通过代码调试，可以发现执行完 if 中的代码后 INSTANCE 就已经是被赋值为 InjvmProtocol 了，而就 INSTANCE 本身来说，它只有在 InjvmProtocol 类的构造函数中会有一个写操作，那就是说一定是在上述代码语句中执行了 InjvmProtocol 的构造函数，通过代码跟踪可以发现在如下代码中调用了它的构造方法。\n\norg.apache.dubbo.common.extension.ExtensionLoader#createExtension\n\n@SuppressWarnings(&quot;unchecked&quot;)private T createExtension(String name) &#123;    // 先尝试从 cachedClasses 获取别名为 name 的 class    Class&lt;?&gt; clazz = getExtensionClasses().get(name);    if (clazz == null) &#123;        throw findException(name);    &#125;    try &#123;        // 尝试从 EXTENSION_INSTANCES 获取 Extension 实例        T instance = (T) EXTENSION_INSTANCES.get(clazz);        if (instance == null) &#123;            // 没有获取到，那就直接通过 class 创建即可            EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance());            instance = (T) EXTENSION_INSTANCES.get(clazz);        &#125;        // 根据 setter 方法，为 instance 实例填充 extension 属性        injectExtension(instance);        Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses;        if (CollectionUtils.isNotEmpty(wrapperClasses)) &#123;            for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123;                // 根据 setter 方法，为 wrapper 实例填充 extension 属性                instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));            &#125;        &#125;        return instance;    &#125; catch (Throwable t) &#123;        throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; +                type + &quot;) couldn&#x27;t be instantiated: &quot; + t.getMessage(), t);    &#125;&#125;\n\n注意这里的 Class&lt;?&gt; clazz = getExtensionClasses().get(name); 语句获取的就是 InjvmProtocol 对应的 class 了，然后执行了 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); 语句来完成对 INSTANCE 的初始化。还有一点需要注意的是，InjvmProtocol 和它的构造函数都是属于 public 关键字修饰，也就是说任何代码都可以调用 InjvmProtocol 的构造函数，这样就会使得 INSTANCE 并非单例了，因为每一次 new InjvmProtocol 都会使得 INSTANCE 引用新的实例。\n资源加载的方式\norg.apache.dubbo.common.extension.ExtensionLoader#loadDirectory\n\nprivate void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type) &#123;    // META-INF/dubbo/internal/com.alibaba.dubbo.common.extension.ExtensionFactory    String fileName = dir + type;   // META-INF/dubbo/internal/org.apache.dubbo.configcenter.DynamicConfigurationFactory    try &#123;        Enumeration&lt;java.net.URL&gt; urls;        ClassLoader classLoader = findClassLoader();        if (classLoader != null) &#123;            // 通过 classloader 获取 filename 资源的全部 urls            urls = classLoader.getResources(fileName);        &#125; else &#123;            urls = ClassLoader.getSystemResources(fileName);        &#125;        if (urls != null) &#123;            while (urls.hasMoreElements()) &#123;                // /Users/eva/IdeaProjects/dubbo-with-comment/dubbo-common/target/classes/META-INF/dubbo/internal/org.apache.dubbo.common.extension.ExtensionFactory                // /Users/eva/IdeaProjects/dubbo-with-comment/dubbo-config/dubbo-config-spring/target/classes/META-INF/dubbo/internal/org.apache.dubbo.common.extension.ExtensionFactory                java.net.URL resourceURL = urls.nextElement();                // 将 resourceURL 所对应的文件中的 class 进行加载，然后保存到 extensionClasses                loadResource(extensionClasses, classLoader, resourceURL);            &#125;        &#125;    &#125; catch (Throwable t) &#123;        logger.error(&quot;Exception occurred when loading extension class (interface: &quot; +                type + &quot;, description file: &quot; + fileName + &quot;).&quot;, t);    &#125;&#125;\n\n这是 Dubbo 在进行 ExtensionClass 获取的代码，核心的就是 urls = classLoader.getResources(fileName); 这条代码，它会将资源路径下所有的 fileName 资源作为 Enumeration&lt;java.net.URL&gt; 返回，然后我们就可以针对每一个资源文件进行处理了。\n总结本文的篇幅算是比较长了，总结就尽量短吧，因为内容都是一些零散的技巧性总结，所以看起来不会觉得很系统，其中的一些要点可能还是要通过自己在阅读源码中领会了，看源码确实很枯燥乏味，但是如果不去看一些好的东西，只管自己折腾的话，那么可以说自己写出来的东西就是一坨 Shit。\n","categories":["后台开发"],"tags":["Dubbo"]},{"title":"分布式统一id生成器snowflake介绍","url":"/2019/07/17/2019-07-17-%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%9F%E4%B8%80id%E7%94%9F%E6%88%90%E5%99%A8snowflake%E4%BB%8B%E7%BB%8D/","content":"前言项目地址好久没有写技术博客了，实在是因为自己比较忙，花了将近两个月的时间完成了两个开源小项目，这篇文章要介绍的就是其中一个，我将它的名字叫做 snowflake，是一个分布式的统一 id 生成器，能够生成 segment 和 snowflake 两种类型的 id。另外一个就是一个类似于 dubbo 的 rpc 框架 beehive，在我的 snowflake 项目中提供了内嵌模式的测试程序，它所使用的 rpc 框架就是我自己开发的 beehive，关于 beehive 我准备在我后边的文章中再作介绍，本篇就先详细介绍一下 snowflake 这个 id 生成器。\n基本介绍snowflake 是一款分布式的统一 ID 生成器，提供了两种 id 生成的方式，分段 id 和通过 snowflake 算法计算得到 id。在分段 id 的生成过程中，不同的服务器从数据库获取自己专属的 id 号段，再从该号段中来产生唯一 id，在从数据库中获取号段的过程中，通过数据库的事务机制，保证了不同的 id 服务器获取的号段是不重复的，所以能够保证全局的 id 唯一性。而 snowflake 算法计算 id 的方式稍微复杂，首先它并不是通过 id 隔段的方式来保证 id 的唯一性，而是通过各个 id 服务器的 machine id 来保证不同的服务器之间产生的 id 唯一性，此外，在单台 id 服务器之上，machine id 是唯一且不变的，要想产生唯一 id，就还需要其他的项来进行保证，snowflake 算法采用的是加上时间戳的方式，在本项目的实现中，提供了两种时间颗粒度的选择（秒和毫秒），对于计算机世界而言一秒和一毫秒而言，是很漫长的，在这样的时间颗粒度下很有可能会在同一个最小时间单元内生成多个 id，因为时间戳和 machine id 一致，所以在我们生成的 id 中，还需要一个额外的字段来保证在单位时间粒度中生成的 id 的唯一性，这就是序列号。snowflake 算法生成 id 相关的三个字段如上所述，更加详细的 id 模型请看下表：\n\n\n\n颗粒度\n时间戳\n序列号\nmachine id\n\n\n\n秒\n占用 31 位\n占用 22 位\n占用 10 位\n\n\n毫秒\n占用 41 位\n占用 12 位\n占用 10 位\n\n\n从上表可以看出来两种颗粒度的 id 占用的长度都是 63 位数，刚好可以使用一个长整型数据来进行存储，剩余一位没有使用，方便以后拓展使用。对于秒颗粒度而言，一年 31536000 秒占用 25 位，时间戳剩余 6 位，也就是说这种方式产生的 id 能用 64 年（非精确计算），而序列号占用 22 位，折算后可以知道理论情况下，一秒内单台 id 服务器最多能生成 4194303 个 id。对于毫秒颗粒度而言，一年 31536000000 毫秒占用 35 位，剩余 6 位，同样可以使用 64 年（非精确计算），由于时间戳长度的增加导致序列号的长度被压缩为 12 位，这样理论情况下，单台 id 服务器一毫秒内最多能产生 4096 个 id。\n基本使用内嵌服务发布模式内嵌服务发布模式需要使用到 rpc 框架，在 snowflake 中用于产生 id 的服务接口为 top.aprilyolies.snowflake.idservice.IdService，可以看到它的实现类有两个，SegmentIdService 和 SnowflakeIdService，分别对应两种 id 的生成方式，他们的继承关系如下图：\n\n\n了解这个以后，我们便知道在 rpc 框架中，需要暴露的服务名称就是这个接口的全限定名。在服务端，除了要暴露服务外，还要指定对应的服务实现，这是我是通过 spring 的 FactoryBean 机制来避免直接构建 IdService 实现类，简单来说我们在使用 rpc 框架指定服务实现类时，不是直接使用的 IdService 实现类，而是通过 FactoryBean 来构建对应的 IdService 实现类，这么说可能有点绕，还是直接看示例程序比较合适，项目的工程结构如下：\n\n\n内嵌服务发布的实例程序就在 snowflake-demo 模块之下，再次说明这里我使用的是自己开发的 rpc 框架 beehive，如果你使用的是其他类型的 rpc 框架，方式也基本一致。先看服务发布端的 spring 配置文件：\n\nembed-server.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:beehive=&quot;https://www.aprilyolies.top/schema/beehive&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd https://www.aprilyolies.top/schema/beehive https://www.aprilyolies.top/schema/beehive.xsd&quot;&gt;    &lt;bean class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt;        &lt;property name=&quot;locations&quot; value=&quot;classpath:snowflake.properties&quot;/&gt;    &lt;/bean&gt;    &lt;bean id=&quot;serviceFactory&quot; class=&quot;top.aprilyolies.snowflake.idservice.IdServiceFactory&quot;&gt;        &lt;property name=&quot;machineIdProvider&quot; value=&quot;ZOOKEEPER&quot;/&gt;        &lt;property name=&quot;idType&quot; value=&quot;1&quot;/&gt;        &lt;property name=&quot;zkHost&quot; value=&quot;119.23.247.86&quot;/&gt;        &lt;property name=&quot;dbUrl&quot; value=&quot;jdbc:mysql://localhost:3306/snowflake&quot;/&gt;        &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;        &lt;property name=&quot;password&quot; value=&quot;kuaile1..&quot;/&gt;        &lt;property name=&quot;serviceType&quot; value=&quot;snowflake&quot;/&gt;    &lt;/bean&gt;    &lt;beehive:service id=&quot;idService&quot; service=&quot;top.aprilyolies.snowflake.idservice.IdService&quot;                     ref=&quot;serviceFactory&quot; proxy-factory=&quot;jdk&quot; serializer=&quot;hessian&quot; server-port=&quot;7442&quot;/&gt;    &lt;beehive:registry id=&quot;registry&quot; address=&quot;zookeeper://119.23.247.86:2181&quot;/&gt;&lt;/beans&gt;\n\n这里的 &lt;beehive:service&#x2F;&gt; 标签是 beehive 用于发布服务的，它暴露的服务接口是 top.aprilyolies.snowflake.idservice.IdService 这里和我上边的说明一致。然后就是该服务的实现类指定，可以看到这里是设置的 ref=&quot;serviceFactory&quot;，它所对应的就是那个 IdService 工厂类，因为在构建 IdService 实现类时需要指定部分参数信息，所以这里我们还指定了一系列参数，具体的作用如下：\n根据生成的 id 的类型不同，参数的指定也不一样，如果你是要生成 segment 类型的 id，那么你只需要指定用于获取 id 段信息的数据库信息即可，也就是这三个。\n&lt;property name=&quot;dbUrl&quot; value=&quot;jdbc:mysql://localhost:3306/snowflake&quot;/&gt;&lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;&lt;property name=&quot;password&quot; value=&quot;kuaile1..&quot;/&gt;\n\n需要在对应的数据库中提前创建 id 分段信息表，在项目的 scripts 目录下已提供 SEGMENT_ID_TABLE.sql 文件，内容如下：\nSET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;DROP TABLE IF EXISTS `SEGMENT_ID_TABLE`;CREATE TABLE `SEGMENT_ID_TABLE` (  `business` varchar(40) NOT NULL COMMENT &#x27;业务类型&#x27;,  `begin` bigint(40) NOT NULL COMMENT &#x27;起始ID&#x27;,  `end` bigint(40) NOT NULL COMMENT &#x27;最大ID&#x27;,  PRIMARY KEY (`business`)) ENGINE=InnoDB DEFAULT CHARSET=latin1;BEGIN;INSERT INTO `SEGMENT_ID_TABLE` VALUES (&#x27;order&#x27;, 519349, 524349);INSERT INTO `SEGMENT_ID_TABLE` VALUES (&#x27;payment&#x27;, 51, 5051);COMMIT;SET FOREIGN_KEY_CHECKS = 1;\n\n\n如果你要获取的是 snowflake 算法生成的 id，那么情况稍微复杂一点点，根据 snowflake id 的构成方式，我们可以知道唯一不能直接确定的就是 machine id，它需要借助于外部的条件来保证唯一性。根据 snowflake machine id 的获取方式不同可以将其配置分为三种。\n\n从数据库中获取 machine id&lt;property name=&quot;idType&quot; value=&quot;1&quot;/&gt;&lt;property name=&quot;dbUrl&quot; value=&quot;jdbc:mysql://localhost:3306/snowflake&quot;/&gt;&lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;&lt;property name=&quot;password&quot; value=&quot;kuaile1..&quot;/&gt;&lt;property name=&quot;machineIdProvider&quot; value=&quot;MYSQL&quot;/&gt;\n\n从数据库中获取 machine id 需要提前在对应数据库中创建对应的 machine id 映射表，在项目的 scripts 目录下已提供 SNOWFLAKE-MYSQL-MACHINE-ID.sql 文件，内容如下：\nCREATE DATABASE snowflake;drop table if exists MYSQL_MACHINE_ID_PROVIDER;create table MYSQL_MACHINE_ID_PROVIDER(    ID bigint not null,    IP varchar(64) default null,    primary key (ID),    unique key UK_IP (IP));drop procedure if exists initMysqlMachineIdProvider;DELIMITER //create procedure initMysqlMachineIdProvider()begin    declare count int;    set count = 0;    set autocommit = false;    LOOP_LABLE:        loop            insert into MYSQL_MACHINE_ID_PROVIDER(ID) values (count);            set count = count + 1;            if count &gt;= 1024 then                leave LOOP_LABLE;            end if;        end loop;    commit;    set autocommit = true;end;//DELIMITER ;call initMysqlMachineIdProvider;\n\n\n从 zookeeper 获取 machine id\n&lt;property name=&quot;idType&quot; value=&quot;1&quot;/&gt;&lt;property name=&quot;zkHost&quot; value=&quot;119.23.247.86&quot;/&gt;&lt;property name=&quot;machineIdProvider&quot; value=&quot;ZOOKEEPER&quot;/&gt;\n\n从本地配置文件获取 machine id（不建议，需要在 classpath 下创建 snowflake.properties 配置文件并指定 snowflake.machine.id&#x3D;1023 属性值，它将作为 machine id，在集群环境下，需要保证这个值唯一）\n&lt;property name=&quot;idType&quot; value=&quot;1&quot;/&gt;&lt;property name=&quot;machineIdProvider&quot; value=&quot;PROPERTY&quot;/&gt;\n\n这里的 idType 就是指的 snowflake 算法生成的 id 的颗粒度（即在怎样的单位时长内，生成的 id 是单调有序的），0 代表在一秒内，生成的 id 是单调有序递增的，而 1 则代表在一毫秒的时间内，生成的 id 是单调有序递增的。\n在服务端的配置完成后，剩下的就是直接引用发布的服务了，配置很简单，我这里只是贴出来，不做说明。\n\nembed-client.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:beehive=&quot;https://www.aprilyolies.top/schema/beehive&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd https://www.aprilyolies.top/schema/beehive https://www.aprilyolies.top/schema/beehive.xsd&quot;&gt;    &lt;beehive:registry id=&quot;registry&quot; address=&quot;zookeeper://119.23.247.86:2181&quot;/&gt;    &lt;beehive:reference id=&quot;idService&quot; service=&quot;top.aprilyolies.snowflake.idservice.IdService&quot; load-balance=&quot;poll&quot;                       serializer=&quot;hessian&quot; read-timeout=&quot;1000&quot; retry-times=&quot;2&quot;/&gt;&lt;/beans&gt;\n\n在实例程序中，我已经指定了 IdService 类型为 snowflake，且 machine id 的获取方式为 ZOOKEEPER，所以不需要使用到数据库，而且我指定的 zookeeper 地址为我的阿里云地址，正常情况下，我会开启 zookeeper 服务，这样你直接运行 server 端和 client 端程序就能看到结果。\n独立运行模式独立运行模式采用手动直接构建 IdService 的方式，这种方式更加灵活，我们只需要指定几个和 id service 相关的参数，然后就能通过 IdServiceFactory 类来拿到 IdService 实例，至于怎么使用这个 IdService，完全由你决定，就像我在项目中给出的两个 restful 风格的 id 生成方式，一个是通过 Springboot 构建的 web 应用来进行访问，另外一个就是通过 Netty 服务器来提供访问支持。参数的配置方式和内嵌服务发布模式完全一致，只不过是一个配置文件是 xml，一个配置文件是 properties。\n就直接那 netty 的实例程序来说明吧，我们根本就是要得到 IdService 的实例，在 IdServiceFactory 类中提供了一个公有静态方法 public static IdService buildIdService(ClassLoader classLoader, String serviceType, String confPath) ，我们可以直接通过该方法来获取 IdService 实例，三个参数需要指定，classloader 类加载器，需要保证这个类加载器能够加载到你的配置文件，serviceType 服务类型，固定为 segment 或者 snowflake，指定其它参数会报错，最后一个就是你的配置文件路径，里边的内容如下：\nsnowflake.machine.id=1023snowflake.machine.id.provider=ZOOKEEPERsnowflake.id.type=0snowflake.zookeeper.host=119.23.247.86snowflake.database.url=jdbc:mysql://localhost:3306/snowflakesnowflake.database.username=rootsnowflake.database.password=kuaile1..\n\n跟上边介绍的一样，里边的配置不是非得全写，根据自己的需求指定几条必须的参数即可。该方法的返回值就是 IdService 实例，就像示例程序的 SnowflakeChannelHandler 返回的那样。\n// SnowflakeIdService 实例private static final IdService snowIdService = IdServiceFactory.buildIdService(SnowflakeChannelHandler.class.getClassLoader(), &quot;snowflake&quot;, &quot;snowflake.properties&quot;);// SegmentIdService 实例private static final IdService segIdService = IdServiceFactory.buildIdService(SnowflakeChannelHandler.class.getClassLoader(), &quot;segment&quot;, &quot;snowflake.properties&quot;);  \n\n测试运行内嵌服务发布模式测试因为测试程序依赖了我开发的 beehive rpc 框架，这个在 maven 中央仓库无法直接下载，需要先手动进行安装该依赖，具体方法就是执行如下指令，这样在你的本地 maven 仓库就会存在该依赖了。\ngit clone https://github.com/AprilYoLies/beehive.gitcd beehivemvn clean install -Dmaven.test.skip=true\n\n然后启动服务端，执行 nowflake-demo&#x2F;embed-server 模块下 top.aprilyolies.snowflake.EmbedServer 类的 main 方法，如果启动成功，那么就表示服务已发布。\n接着启动客户端，执行 snowflake-demo&#x2F;embed-client 模块下 top.aprilyolies.snowflake.EmbedClient 类的 main 方法，如果出现如下结果，就表示服务调用成功。\n14108116920565761141081169708974091410811697928601714108116983480321141081169918689291410811699606323314108117004451841141081170086461451410811701703475314108117021229057\n\n独立运行模式测试独立运行模式提供了两个 Server 端，随便启动一个就行，以 NettyServer 为例，执行 snowflake-server&#x2F;snowflake-netty 模块下 top.aprilyolies.snowflake.SnowflakeServer 类的 main 方法，如果启动成功，就会日志打印请求的路径如下：\n210 [main] INFO top.aprilyolies.snowflake.SnowflakeServer - Snowflake netty server started on port 6707.210 [main] INFO top.aprilyolies.snowflake.SnowflakeServer - Get segment id by http://localhost:6707/snowflake/seg/business-name210 [main] INFO top.aprilyolies.snowflake.SnowflakeServer - Get snowflake id by http://localhost:6707/snowflake/snow\n\n访问两个链接中的任意一条就会得到对应的 id。\nTODO-LIST\n在通过 snowflake 算法生成 id 时，由于需要通过时间戳来生成 id，这就有可能会因为某一个机器的时间发生回拨，导致这台机器产生出重复的 id，有两种解决办法，一个是在每次生成 id 时，都检查一次当前时间戳是否比上一次生成 id 的时间戳小，如果条件成立，就拒绝 id 生成，这种方式的好处是，在服务不重启的情况下也能检查出这种问题，缺陷是获取当前时间戳和时间比对是一个耗时操作，会导致吞吐量下降。另外一种方式是每隔一小段时间向数据库中写入当前机器生成 id 的时间戳，在服务重启时需要先检查当前时间戳是否比上一次生成 id 的时间戳小，如果成立，则拒绝启动服务，这种做法能够避免服务重启时的时间回拨问题，但是如果服务是在运行中，发生时间回拨，这种方式将会产生错误。\n\n在 segment 方式生成 id 的过程中，代码是使用的硬编码方式将 step 值写死，对于不同的应用场景，可能该步进值并不合适，最好是系统能够根据两次获取 id 段的时间差来自动调整步进值，这样能够动态的缓解 id 段服务数据库的压力。\n\n可以再为系统增加一个可视化管理界面，能够直观的看到不同业务的 id 段使用情况，以及 id 段缓存的使用情况。\n\n\n","categories":["后台开发"],"tags":["分布式"]},{"title":"轻量级RPC框架BEEHIVE介绍","url":"/2019/07/18/2019-07-18-%E8%BD%BB%E9%87%8F%E7%BA%A7RPC%E6%A1%86%E6%9E%B6BEEHIVE%E4%BB%8B%E7%BB%8D/","content":"简介项目地址\nbeehive 是一款轻量级的 RPC 框架，通过 spring 容器来管理 bean，做到了对用户代码的零入侵，同时通过 spi 拓展机制，实现了自己的 ioc 容器，使得 beehive 能够很方便的对组件进行拓展。\n功能特性\n实现了 SPI 拓展机制，能够方便的进行组件的自定义和替换\n\n提供了两种代理方式的支持（JDK 原生、Javassist）\n\n底层通信采用 Netty 框架，保证稳定性和高效性\n\n对 Zookeeper 注册中心的支持，能够自动的侦测服务的状态，同步进行更新\n\n完成了对与 fastjson 和 hessian 两种序列化器的支持\n\n整合 spring 容器，对用户代码零入侵，使用方便\n\n在客户端实现了两种负载均衡策略的支持（随机选取，轮询选取）\n\n\n使用方式beehive 加入了对于 spring 容器的支持，使得它在使用过程中可以做到对用户代码的零入侵，使用方式和 dubbo 很类似，在服务端，只需要定义要发布的服务的接口类型，服务的实现类，以及注册中心的地址即可完成启动，其他的一些相关参数可以作为备选项，这里给出一个使用样例。\n\nprovider.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:beehive=&quot;https://www.aprilyolies.top/schema/beehive&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd        https://www.aprilyolies.top/schema/beehive https://www.aprilyolies.top/schema/beehive.xsd&quot;&gt;    &lt;bean id=&quot;demoServiceImpl&quot; class=&quot;top.aprilyolies.service.BeehiveServiceImpl&quot;/&gt;    &lt;bean id=&quot;userServiceImpl&quot; class=&quot;top.aprilyolies.service.UserServiceImpl&quot;/&gt;    &lt;beehive:service id=&quot;demoService&quot; service=&quot;top.aprilyolies.service.BeehiveService&quot;                     ref=&quot;demoServiceImpl&quot; proxy-factory=&quot;jdk&quot; serializer=&quot;hessian&quot; server-port=&quot;7442&quot;/&gt;    &lt;beehive:service id=&quot;userService&quot; service=&quot;top.aprilyolies.service.UserService&quot;                     ref=&quot;userServiceImpl&quot; proxy-factory=&quot;javassist&quot; serializer=&quot;hessian&quot; server-port=&quot;7442&quot;/&gt;    &lt;beehive:registry id=&quot;registry&quot; address=&quot;zookeeper://119.23.247.86:2181&quot;/&gt;&lt;/beans&gt;\n\n这是服务端的 spring 配置文件，其中 id&#x3D;”demoServiceImpl” 和 id&#x3D;”userServiceImpl” 的 bean 就是服务的实现类，而 &lt;beehive:service&#x2F;&gt; 标签中的 service&#x3D;”top.aprilyolies.service.BeehiveService” 就是待发布服务的接口类型，另外一个 &lt;beehive:service&#x2F;&gt; 类似，最后 &lt;beehive:registry&#x2F;&gt; 标签中定义的就是注册中心地址，目前仅支持 zookeeer。\n说完了配置文件，再看看启动程序，很简单，就是一个典型的 spring 容器启动程序如下，不做过多说明。\npublic static void main(String[] args) throws IOException &#123;    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;provider.xml&quot;);    context.start();    System.out.println(&quot;Provider started on thread &quot; + Thread.currentThread().getName() + &quot;..&quot;);    System.in.read();&#125;\n\n启动服务端程序后就是客户端程序了，要做的配置也非常简单，仅仅是通过 beehive 引入服务即可，具体的 rpc 过程对于用户来说是绝对透明的，内容如下：\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:beehive=&quot;https://www.aprilyolies.top/schema/beehive&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd        https://www.aprilyolies.top/schema/beehive https://www.aprilyolies.top/schema/beehive.xsd&quot;&gt;    &lt;beehive:registry id=&quot;registry&quot; address=&quot;zookeeper://119.23.247.86:2181&quot;/&gt;    &lt;beehive:reference id=&quot;demoService&quot; service=&quot;top.aprilyolies.service.BeehiveService&quot; load-balance=&quot;poll&quot;                       serializer=&quot;hessian&quot; read-timeout=&quot;1000&quot; retry-times=&quot;2&quot;/&gt;    &lt;beehive:reference id=&quot;userService&quot; service=&quot;top.aprilyolies.service.UserService&quot; load-balance=&quot;poll&quot;                       serializer=&quot;hessian&quot; read-timeout=&quot;1000&quot; retry-times=&quot;2&quot;/&gt;&lt;/beans&gt;\n\n基本跟服务端的配置相似，注册中心的配置是一样的，只有引用服务的标签变成为 &lt;beehive:reference&#x2F;&gt;，该标签的属性设置也跟服务端的服务发布标签有所不同，关于详细的属性说明请看下文。\n客户端启动程序服务端一样简单，直接启动程序，查看输出结果即可，不做过多说明。\npublic class Consumer &#123;    public static void main(String[] args) throws Exception &#123;        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;consumer.xml&quot;);        context.start();        BeehiveService demoService = context.getBean(&quot;demoService&quot;, BeehiveService.class);        long start = System.currentTimeMillis();        for (int i = 0; i &lt; 50000; i++) &#123;            String hello = demoService.say(&quot;world - &quot; + i);            System.out.println(&quot;result: &quot; + hello);            Thread.sleep(500);        &#125;        System.out.println(System.currentTimeMillis() - start);    &#125;&#125;\n\n参数设置说明&lt;beehive:service&#x2F;&gt; 标签\nid：为 bean 在 spring 容器中的唯一标识符\n\nservice：将要发布的服务，值为你想要发布的服务的全限定名\n\nref：你所发布服务的实现类，它的值为 spring &lt;bean&#x2F;&gt; 标签的 id 值\n\nproxy-factory：服务提供端代理类创建的方式，目前支持 javassist 和 jdk 可选\n\nserializer：序列化器，默认为 fastjson，可选 hessian\n\nserver-port：服务启动的端口号，默认使用 7440，你也可以再启动程序时通过 -Dport&#x3D;端口号 来指定，优先级最高\n\n\n&lt;beehive:reference&#x2F;&gt; 标签\nid：为 bean 在 spring 容器中的唯一标识符\n\nservice：将要发布的服务，值为你想要发布的服务的全限定名\n\nload-balance：负载均衡设置，由客户端实现，目前只支持 random 和 poll 两种方式\n\nproxy-factory：服务提供端代理类创建的方式，目前支持 javassist 和 jdk 可选\n\nserializer：序列化器，默认为 fastjson，可选 hessian\n\nread-timeout：指定 rpc 结果读取超时时间，如果本次结果获取失败，将会重试\n\nretry-times：指定重试次数，即 rpc 结果获取超时重试次数\n\n\n&lt;beehive:registry&#x2F;&gt; 标签\nid：为 bean 在 spring 容器中的唯一标识符\n\naddress：注册中心的地址，目前只支持 zookeeper，格式如 “zookeeper:&#x2F;&#x2F;host:port”\n\n\n样例测试基本测试项目中提供了实例程序（位于 beehive-demo）模块下，通过 git clone 将工程拉取下来后，在根目录下输入如下指令进行安装。\n\nmvn clean install -Dmaven.test.skip&#x3D;true\n\n因为需要用到注册中心，所以实例程序中注册中心的地址是我的阿里云服务器地址，正常情况下我会启动 zookeeper 服务，那么示例程序就会将服务注册到我的阿里云服务器的 zookeeper 上，当然你也可以在本机启动一个 zookeeper，然后修改 spring 配置文件中的注册中心地址。\n启动服务器，如果你没有修改实例程序的配置文件，默认使用我阿里云的 zookeeper，输入如下指令：\n\njava -jar beehive-demo&#x2F;provider&#x2F;target&#x2F;provider-1.0-SNAPSHOT-jar-with-dependencies.jar\n\n启动客户端，没有修改代码的情况下，会从注册中心获取服务信息，输入如下指令：\n\njava -jar beehive-demo&#x2F;consumer&#x2F;target&#x2F;consumer-1.0-SNAPSHOT-jar-with-dependencies.jar\n\n如果过程没有错误的话，在控制台将会打印 rpc 的结果如下：\nresult: Jim say world - 0 from 192.168.1.105, [ server id is No.1]result: Jim say world - 1 from 192.168.1.105, [ server id is No.1]result: Jim say world - 2 from 192.168.1.105, [ server id is No.1]result: Jim say world - 3 from 192.168.1.105, [ server id is No.1]result: Jim say world - 4 from 192.168.1.105, [ server id is No.1]result: Jim say world - 5 from 192.168.1.105, [ server id is No.1]result: Jim say world - 6 from 192.168.1.105, [ server id is No.1]result: Jim say world - 7 from 192.168.1.105, [ server id is No.1]result: Jim say world - 8 from 192.168.1.105, [ server id is No.1]result: Jim say world - 9 from 192.168.1.105, [ server id is No.1]\n\n或者启动多线程的 consumer，输入如下指令：\n\njava -cp beehive-demo&#x2F;consumer&#x2F;target&#x2F;consumer-1.0-SNAPSHOT-jar-with-dependencies.jar top.aprilyolies.consumer.MultiThreadConsumer\n\n我这里是启动了 5 个线程来进行的 rpc 请求，参数附带了当前线程的信息，所以 rpc 的结果也包含了线程信息，结果：\nresult: Jim say MultiThreadConsumer-pool-thread-3 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-3 - 1 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-1 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-4 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-5 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-2 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-3 - 2 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-1 - 1 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-2 - 1 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-5 - 1 from 192.168.1.105, [ server id is No.1]\n\n服务切换的测试示例程序中提供了两个服务端程序，表示两个服务提供者，测试服务切换需要同时启动这两个程序，指令如下：\n\njava -cp beehive-demo&#x2F;provider&#x2F;target&#x2F;provider-1.0-SNAPSHOT-jar-with-dependencies.jar top.aprilyolies.provider.Provider\n\n\njava -cp beehive-demo&#x2F;provider&#x2F;target&#x2F;provider-1.0-SNAPSHOT-jar-with-dependencies.jar top.aprilyolies.provider.AnotherProvider\n\n启动客户端，没有修改代码的情况下，会从注册中心获取服务信息，输入如下指令：\n\njava -jar beehive-demo&#x2F;consumer&#x2F;target&#x2F;consumer-1.0-SNAPSHOT-jar-with-dependencies.jar\n\n因为测试程序中默认使用的是轮询负载均衡机制，所以客户端会从所有的服务提供者中逐个调用，得到的结果如下，根据最后的 serverid 就能够分辨出来当前是请求的哪个服务提供者。\nresult: Jim say world - 0 from 192.168.1.105, [ server id is No.1]result: Jim say world - 1 from 192.168.1.105, [ server id is No.2]result: Jim say world - 2 from 192.168.1.105, [ server id is No.1]result: Jim say world - 3 from 192.168.1.105, [ server id is No.2]result: Jim say world - 4 from 192.168.1.105, [ server id is No.1]result: Jim say world - 5 from 192.168.1.105, [ server id is No.2]result: Jim say world - 6 from 192.168.1.105, [ server id is No.1]result: Jim say world - 7 from 192.168.1.105, [ server id is No.2]result: Jim say world - 8 from 192.168.1.105, [ server id is No.1]result: Jim say world - 9 from 192.168.1.105, [ server id is No.2]\n\n或者启动多线程的 consumer，输入如下指令：\n\njava -cp beehive-demo&#x2F;consumer&#x2F;target&#x2F;consumer-1.0-SNAPSHOT-jar-with-dependencies.jar top.aprilyolies.consumer.MultiThreadConsumer\n\nresult: Jim say MultiThreadConsumer-pool-thread-2 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-2 - 1 from 192.168.1.105, [ server id is No.2]result: Jim say MultiThreadConsumer-pool-thread-4 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-1 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-5 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-3 - 0 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-2 - 2 from 192.168.1.105, [ server id is No.1]result: Jim say MultiThreadConsumer-pool-thread-3 - 1 from 192.168.1.105, [ server id is No.2]result: Jim say MultiThreadConsumer-pool-thread-5 - 1 from 192.168.1.105, [ server id is No.2]result: Jim say MultiThreadConsumer-pool-thread-1 - 1 from 192.168.1.105, [ server id is No.2]result: Jim say MultiThreadConsumer-pool-thread-4 - 1 from 192.168.1.105, [ server id is No.2]\n\n可以看到多线程的环境下，rpc 的调用逻辑和单线程是保持一致的。\n实例程序默认是使用的轮询负载均衡机制，如果过程没错的话，那么你将会看到客户端会交替的从两个 provider 进行 rpc 调用。\n尝试关掉其中一个 provider，客户端会侦测到这个变化，随即将这个下线的 provider 剔除，仅仅从剩下的 provider 中进行 rpc 调用。\n再尝试重启这个 provider，客户端也会侦测到这个变化，随即将这个 provider 加入到可调用的 providers 列表中，进而进行 rpc 调用。\n底层实现原理标签解析beehive 实现了自己的标签解析器，spring 容器能够对这些标签对应的 bean 的创建及初始化进行管理，beehive 自定义的标签只有 &lt;beehive:registry&#x2F;&gt;、&lt;beehive:service&#x2F;&gt;、&lt;beehive:reference&#x2F;&gt; 三个，分别对应注册中心、服务发布、服务调用三个逻辑，相应的 BeanDefinitionParser 是由 top.aprilyolies.beehive.spring.namespace.BeehiveNamespaceHandler 完成注册的，它的代码内容如下，就是为每个 beehive 对应的标签注册了一个 BeanDefinitionParser，用于解析 spring 配置文件中的 beehive 标签。\npublic class BeehiveNamespaceHandler extends NamespaceHandlerSupport &#123;    @Override    public void init() &#123;        // beehive:registry 标签解析器        registerBeanDefinitionParser(&quot;registry&quot;, new RegistryBeanDefinitionParser());        // beehive:service 标签解析器        registerBeanDefinitionParser(&quot;service&quot;, new ServiceBeanDefinitionParser());        // beehive:reference 标签解析器        registerBeanDefinitionParser(&quot;reference&quot;, new ReferenceBeanDefinitionParser());    &#125;&#125;\n\n因为三个 BeanDefinitionParser 的基本逻辑一样，我这里仅以 ServiceBeanDefinitionParser 进行大致说明，先贴出 ServiceBeanDefinitionParser 的源代码：\npublic class ServiceBeanDefinitionParser extends AbstractBeanDefinitionParser &#123;    @Override    public BeanDefinition parse(Element element, ParserContext parserContext) &#123;        // 构建 RootBeanDefinition，用于承载解析出来的信息        RootBeanDefinition beanDefinition = new RootBeanDefinition();        // 指定解析的 bean 的类型        beanDefinition.setBeanClass(ServiceProvider.class);        // 不使用懒加载        beanDefinition.setLazyInit(false);        String id = element.getAttribute(&quot;id&quot;);        String service = element.getAttribute(&quot;service&quot;);        beanDefinition.getPropertyValues().addPropertyValue(&quot;service&quot;, service);        // 如果没有指定 id 属性        if (StringUtils.isEmpty(id)) &#123;            String name = element.getAttribute(&quot;name&quot;);            beanDefinition.getPropertyValues().addPropertyValue(&quot;name&quot;, name);            // 尝试使用 name 来确定 id 信息            if (!isExisted(parserContext, name)) &#123;                id = name;            &#125; else &#123;                // name 不行的话，那么就使用 service 来确定 id 信息                String beanName = getBeanName(service);                id = beanName;                int count = 1;                while (isExisted(parserContext, id)) &#123;                    id = beanName + count;                &#125;            &#125;        &#125;        if (!StringUtils.isEmpty(id)) &#123;            // 相同 id 只能存在一个            if (isExisted(parserContext, id)) &#123;                throw new IllegalStateException(String.format(&quot;Bean of id %s has existed&quot;, id));            &#125;            beanDefinition.getPropertyValues().addPropertyValue(&quot;id&quot;, id);            // 进行注册信息，这一步一定不能落下            parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);        &#125;        // 解析 protocol 属性        parseAttribute(element, beanDefinition, &quot;protocol&quot;, &quot;beehive&quot;);        // 解析 proxy 属性        parseAttribute(element, beanDefinition, &quot;proxy-factory&quot;, &quot;javassist&quot;);        // 解析 serializer 属性        parseAttribute(element, beanDefinition, &quot;serializer&quot;, &quot;fastjson&quot;);        // 解析 serializer 属性        parseAttribute(element, beanDefinition, &quot;server-port&quot;, &quot;7440&quot;);        String ref = element.getAttribute(&quot;ref&quot;);        // 如果 setter 方法对应的属性为 ref，并且 spring 容器中已经注册过这个 ref 所引用的 bean 的 beanDefinition        if (parserContext.getRegistry().containsBeanDefinition(ref)) &#123;            // 那就拿到这个 beanDefinition            BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(ref);            // 这个 beanDefinition 必须是单例的            if (!refBean.isSingleton()) &#123;                throw new IllegalStateException(&quot;The exported service ref &quot; + ref + &quot; must be singleton! Please set the &quot; + ref + &quot; bean scope to singleton, eg: &lt;bean id=\\&quot;&quot; + ref + &quot;\\&quot; scope=\\&quot;singleton\\&quot; ...&gt;&quot;);            &#125;        &#125;        RuntimeBeanReference reference = new RuntimeBeanReference(ref);        beanDefinition.getPropertyValues().addPropertyValue(&quot;ref&quot;, reference);        return beanDefinition;    &#125;&#125;\n\n这个类实现了 org.springframework.beans.factory.xml.BeanDefinitionParser 接口，他只有一个 BeanDefinition parse(Element element, ParserContext parserContext); 方法，参数 element 就是 spring 配置文件中 beehive 对应的那个标签元素，参数 parserContext 就是一个标签解析的上下文环境，可以从中获取到已经解析的标签的信息。在 parse 方法中我们就需要实现自己的标签解析逻辑，主要就是创建了一个 RootBeanDefinition 实例，然后将其和正在解析的标签所对应的类进行绑定，也就是 beanDefinition.setBeanClass(ServiceProvider.class); 这个方法，接下来就是将标签中解析出来的属性逐个的添加到刚刚创建的 RootBeanDefinition 实例中，这样 RootBeanDefinition 就包含了类信息及相关的参数信息，最后就是将 RootBeanDefinition 实例返回，交由 spring 容器进行管理，这包括 bean 是否是单例，不同的初始化阶段的声明周期方法的调用，字段的自动装配等等。\n服务端启动服务端启动主要是完成了三件事，打开数据通信服务器、创建服务接口服务端代理，向注册中心发布服务，执行的先后顺序如下图：\n\n\n服务端启动核心逻辑\n\n\n在完成标签的解析后，标签对应的 bean 就会交由 spring 容器管理，根据 bean 的实现接口的类型，spring 容器会在不同的阶段完成 bean 对应接口方法的调用，服务端的启动就是如此。先看看服务发布标签对应 bean（ServiceProvider）的实现接口 public class ServiceProvider extends ServiceConfigBean implements ApplicationListener&lt;ContextRefreshedEvent&gt;, InitializingBean, ApplicationContextAware，对于 ApplicationListener 接口的实现类，spring 容器在初始化完成后进行该接口对应方法的调用，InitializingBean 接口则是在进行 bean 的初始化时进行调用，而 ApplicationContextAware 是一个感知接口，就是该接口的实现类能够拿到 spring 上下文环境，在 beehive 中，则是利用该接口拿到了 spring 上下文环境，通过它注册了一个关闭钩子函数，用于关闭通信端程序。具体如下：\n@Overridepublic void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;    this.applicationContext = applicationContext;    // 注册关闭监听器    // 如果 context 是 ConfigurableApplicationContext 接口的实例    if (applicationContext instanceof ConfigurableApplicationContext) &#123;        // spring 框架的方法，向 jvm 注册一个关闭钩子函数，在 jvm 关闭时会调用这个钩子函数来关闭 applicationContext        ((ConfigurableApplicationContext) applicationContext).registerShutdownHook();    &#125;    // 注册关闭监听器    addApplicationListener(new ShutdownHookListener());&#125;/**    * beehive 的关闭监听器，它会监听 context 关闭事件，同时关闭相关的组件    */public class ShutdownHookListener implements ApplicationListener &#123;    @Override    public void onApplicationEvent(ApplicationEvent event) &#123;        // 此监听器只会监听 context 关闭事件        if (event instanceof ContextClosedEvent) &#123;            BeehiveShutdownHook.closeAll();        &#125;    &#125;&#125;// 关闭注册的 Registrypublic static void closeAll() &#123;    for (Registry registry : registries) &#123;        registry.close();    &#125;    for (EndPoint endPoint : endPoints) &#123;        endPoint.close();    &#125;&#125;\n\n而实现 InitializingBean 接口主要是为了注入 registry 对应的 bean 如下：\n/**    * 用于为当前 bean 填充一些必要属性    *    * @throws Exception    */@Overridepublic void afterPropertiesSet() throws Exception &#123;    checkRegistry();&#125;/**    * 检查当前 bean 的 registry 属性是否为空，否则从 spring 容器中获取对应的值进行填充    */private void checkRegistry() &#123;    RegistryConfigBean registry = getRegistry();    if (registry == null) &#123;        if (applicationContext != null) &#123;            Map&lt;String, RegistryConfigBean&gt; registryMap = BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext,                    RegistryConfigBean.class, false, false);            if (registryMap.size() &gt; 0) &#123;                // 如果 spring 容器中有多个 registry bean，那么优先获取第一个                Collection&lt;RegistryConfigBean&gt; registries = registryMap.values();                for (RegistryConfigBean reg : registries) &#123;                    setRegistry(reg);                    break;                &#125;            &#125;        &#125;    &#125;&#125;\n\n服务端启动的主要逻辑是在 ApplicationListener 接口对应的方法中完成的，该方法中直接是调用了 exportService(); 方法，该方法中主要是两个部分，准备 registryUrls 和进行真正的服务注册，准备 registryUrls 就只是一个信息拼凑的过程，逻辑简单，只是过程比较繁琐，感兴趣的话可以自行去看源码，最终的拼凑结果我通过 debug 的方式显示出来了，请看下图。\n@Overridepublic void onApplicationEvent(ContextRefreshedEvent event) &#123;    exportService();&#125;public void exportService() &#123;    if (!published) &#123;        synchronized (publishMonitor) &#123;            if (!published) &#123;                if (logger.isDebugEnabled()) &#123;                    logger.debug(&quot;Export service via thread &quot; + Thread.currentThread().getName());                &#125;                // 将当前实例以 provider_model 的形式保存到 BeehiveContext 中                BeehiveContext.unsafePut(UrlConstants.PROVIDER_MODEL, this);                // 根据 registry 属性构建 registry urls                List&lt;URL&gt; registryUrls = getRegistryUrl(getRegistry());                // 将当前实例中的属性填充到 url 的参数中                fillParameters(registryUrls, this);                // 检查 registry url 是否包含必要的属性                checkRegistryUrls(registryUrls);                // 进行真正的服务注册                registryService(registryUrls);            &#125;            published = true;        &#125;    &#125;&#125;\n\n\n\nregistryUrls的内容\n\n这里重点关注第二部分进行真正的服务注册方法 registryService(registryUrls);，它根本是调用的 AbstractRegistry#registry 方法，在该方法中主要就是完成了服务端启动的三个核心逻辑，从其方法名就可以知道了。\n@Overridepublic void registry(URL url) &#123;    if (url == null)        throw new IllegalArgumentException(&quot;Can&#x27;t publish a service for null url&quot;);    try &#123;        openServer(url);        createInvoker(url);        doPublish(url);    &#125; catch (Exception e) &#123;        logger.error(&quot;publish service failed&quot;, e.getCause());    &#125;&#125;\n\n先看 openServer(url); 方法，它会根据 url 确定当前终端是服务端还是客户端，因为我们现在是分析的服务端启动，所以走的是上边那条逻辑。\n@Overrideprotected void openServer(URL url) &#123;    String protocol = url.getOriginUrl().getParameterElseDefault(UrlConstants.SERVICE_PROTOCOL, UrlConstants.DEFAULT_SERVICE_PROTOCOL);    URL serviceUrl = URL.copyFromUrl(url.getOriginUrl());    serviceUrl.setOriginUrl(url.getOriginUrl());    serviceUrl.setProtocol(protocol);    if (url.isProvider()) &#123;        protocolSelector.publish(serviceUrl);    &#125; else if (!url.isProvider()) &#123;        protocolSelector.subscribe(serviceUrl);    &#125;&#125;\n\n该方法的实现是这样的，优先从缓存中获取 server 实例，如果没有的话就新建一个 server 实例并进行缓存，server 实例的创建是在 NettyTransporter#bind 方法中完成的，可以看到这里创建的是一个 NettyServer，也就是说 beehive 的底层是采用的 netty 作为通信框架的。\n@Overridepublic Server bind(URL url) &#123;    String serverKey = buildServerKey(url);    Server server = serverCache.get(serverKey);    if (server == null) &#123;        synchronized (serverCache) &#123;            if (serverCache.get(serverKey) == null) &#123;                server = new NettyServer(url);                AbstractConfig.BeehiveShutdownHook.addEndPoint(server);                serverCache.putIfAbsent(serverKey, server);            &#125;        &#125;    &#125;    return server;&#125;\n\n知道 openServer(url); 的实现后，再看 createInvoker(url); 方法，它就是一个创建服务接口代理类的过程，考虑到拓展性，所以 beehive 的处理过程还将创建出来的代理进行了封装，最终返回的是一个 Invoker 链，我们先看看根本的代理类的创建过程，它的实现是在 AbstractProxyFactory#createInvoker 方法中，里边有两个逻辑，创建原生的代理类，和将代理类封装成为 Invoker 实现类，这样做是为了方便后边的 Invoker 链的构建。beehive 提供了两种代理类生成的方式，这里只是为了说明代理的逻辑，所以选择稍微简单的 jdk 原生代理的方式进行说明，而 javassist 方式生成代理的过程可以自行参考源码理解。\njdk 原生代理类生成的入口方法为 JdkProxyFactory#createProxy，我们是服务端代理类生成，走上一个分支，可以看到它根本是调用的 ProviderProxy.getJdkProxy(target, clazz, Proxy.class); 方法，其中 target 就是我们在 spring 配置文件中指定的服务接口的实现类，class 是服务接口对应的 class，而 Proxy.class 则是返回的接口类型，也就是说我们生成的代理类是实现了两个接口的，服务接口和 Proxy 接口，且返回的表现形式是 Proxy。\n@Overrideprotected Proxy createProxy(Class&lt;?&gt; clazz, URL url) &#123;    if (url.isProvider()) &#123;        // 根据 url 信息获取 invoke target 实例        ServiceConfigBean serviceConfigBean = BeehiveContext.unsafeGet(UrlConstants.PROVIDER_MODEL, ServiceConfigBean.class);        Object target = serviceConfigBean.getRef();        return ProviderProxy.getJdkProxy(target, clazz, Proxy.class);    &#125; else &#123;        Invoker invoker = getInvoker(url);        return ConsumerProxy.getJdkProxy(new InvokerInvocationHandler(invoker, url), clazz, Proxy.class);    &#125;&#125;\n\n知道这一点后，我们再直接看 jdk 代理类的构建细节，也就是如下代码所示的那样，可以看到代理的逻辑是由 ProviderInvocationHandler 指定的，它持有了我们在 spring 配置文件中指定的服务接口的实现类，当代理类需要执行某个方法时，真正调用的其实是服务接口实现类的方法。\n/**    * 创建 jdk 代理类    *    * @param classes    * @return    */public static Proxy getJdkProxy(Object target, Class&lt;?&gt;... classes) &#123;    if (classes.length &lt; 1) &#123;        throw new IllegalStateException(&quot;Can&#x27;t create jdk proxy for none of interface has specified&quot;);    &#125;    ClassLoader classLoader = classes[0].getClassLoader();    ProviderInvocationHandler handler = new ProviderInvocationHandler(target);    return (Proxy) java.lang.reflect.Proxy.newProxyInstance(classLoader, classes, handler);&#125;/**    * provider 的 jdk invocation handler    */private static class ProviderInvocationHandler implements InvocationHandler &#123;    private final Object target;    public ProviderInvocationHandler(Object target) &#123;        this.target = target;    &#125;    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        return method.invoke(target, args);    &#125;&#125;\n\n返回的 jdk 代理是是被封装成了 ProxyWrapperInvoker，beehive 接下来就是根据该 invoker 构建 invoker 链，至于 invoker 链的其他节点，则是通过 spi 拓展机制来指定的，但是关于 invoker 逻辑功能，我暂时是做的空实现，所以采用的是硬编码的方式，如果以后有新的需求了，就会考虑将其实现改为适配 spi 拓展，关乎 invoker 链，这里采用的是责任链模式，具体的构建过程如下：\n/**    * 通过 filter 构建 invoker 链，最后一个 invoker 就是我们创建的 ProxyWrapperInvoker，它封装了我们真正的调用逻辑    *    * @param invoker 原始的 invoker    * @return 通过 filter 构建出来的 invoker 链    */public static Invoker buildInvokerChain(Invoker&lt;?&gt; invoker) &#123;    // TODO 这里的 filter 获取应该通过 ExtensionLoader    List&lt;Filter&gt; filters = new ArrayList&lt;&gt;();    filters.add(new AccessLogFilter());    filters.add(new MonitorFilter());    Invoker ptr = invoker;    if (filters.size() &gt; 0) &#123;        for (Filter filter : filters) &#123;            final Invoker next = ptr;            Invoker pre = new AbstractInvoker() &#123;                @Override                protected Object doInvoke(InvokeInfo info) &#123;                    return filter.doFilter(next, info);                &#125;            &#125;;            ptr = pre;        &#125;    &#125;    //noinspection unchecked    return ptr;&#125;\n\n可以看到封装我们代理类的 ProxyWrapperInvoker 节点位于 invoker 链的末尾，而最终返回的是 invoker 链的头结点，这样在进行逻辑调用时，就会先执行拓展逻辑，最后再执行我们的代理逻辑。\n最后一个就是 doPublish(url); 方法，它做的事情很简单，就是向注册中心也就是 zookeeper 中写入当前发布的服务的相关信息，这里的 zookeeper 客户端使用的 curator 框架，具体的过程很简单，这里只给出写入服务信息后的结果。\n\n\nzookeeper 中写入的服务信息\n\n执行到这里，服务端的启动计算完成了，这个启动过程主要就是做了三件事情，启动数据交互的服务终端，创建逻辑调用的代理类，将其封装为 Invoker 链，之后就是向注册中心发布服务，接下来继续读客户端的启动进行说明。\n客户端启动在了解过服务端的启动之后，再看客户端的启动流程就会很简单，跟客户端一样，它主要也是实现了三个逻辑，在这三个逻辑中，就只有代理类的创建比较复杂，而在数据交互的终端创建和消费者信息注册方面，过程基本一致，所以这里主要就是对代理类的创建方式进行说明。\n\n\n客户端启动核心逻辑\n\n首先还是看和服务调用相关的标签 &lt;beehive:reference&#x2F;&gt; 对应的 bean（ServiceConsumer）所实现的接口，相比于服务端，客户端实现的接口就只有一个 FactoryBean，它指定了三个方法，根据 spring 的实现规则，知道在获取实现 FactoryBean 接口的 bean 时，它实际返回的是 getObject() 方法返回的实例。根据这个特性，所以 beehive 客户端的服务接口代理类就是通过该方法返回的，我们重点关注这个方法。\npublic interface FactoryBean&lt;T&gt; &#123;\tT getObject() throws Exception;\tClass&lt;?&gt; getObjectType();\tboolean isSingleton();&#125;\n\ngetObject() 方法和服务端的 ServiceProvider#onApplicationEvent 方法很相似，分为准备 registryUrls 信息和订阅 registryUrl 两部分（客户端的订阅和服务端的发布相对应），准备 registryUrls 信息的过程就是个简单但是比较繁琐的过程，可以自行看源码了解，而订阅 registryUrl 的逻辑根本就是调用的 AbstractRegistry#registry 方法，它跟服务端调用的是同样的方法。\n@Overridepublic void registry(URL url) &#123;    if (url == null)        throw new IllegalArgumentException(&quot;Can&#x27;t publish a service for null url&quot;);    try &#123;        openServer(url);        createInvoker(url);        doPublish(url);    &#125; catch (Exception e) &#123;        logger.error(&quot;publish service failed&quot;, e.getCause());    &#125;&#125;\n\n所以客户端启动做的三个核心逻辑和服务端是一样的，只是具体的实现不一样，先看 openServer(url);，它根本是调用的 NettyTransporter#connect 方法，可以看到这里我们创建的是 NettyClient，这和服务端的 NettyServer 对应。\n@Overridepublic Client connect(URL url) &#123;    NettyClient nettyClient = new NettyClient(url);    AbstractConfig.BeehiveShutdownHook.addEndPoint(nettyClient);    return nettyClient;&#125;\n\n再看 createInvoker(url); 方法的实现，我们这里启动客户端，所以走的是 else 分支，首先代码是从 zookeeper 注册中心中获取已经发布的服务信息，也就是服务端所发布的服务信息。接着调用 ZookeeperRegistry#addProviderRefreshListener 方法，其实就是通过 curator 框架向 zookeeper 注册了一个监听器，它会监听服务上下线的信息，以此来达到更新 provider 列表的目的，关键的代码如下，添加的 listener 为 ProviderRefreshListener，可以看到它监听 CHILD_ADDED、CHILD_REMOVED、CHILD_UPDATED 三种事件，所作出的动作是 BeehiveContext.unsafePut(PROVIDERS, providerUrls); 更新 provider 列表。\n/**    * 为 consumer 添加一个监听器，用于监测 provider 更新消息    *    * @param providerPath    */private void addProviderRefreshListener(String providerPath) &#123;    try &#123;        PathChildrenCache pathCache = new PathChildrenCache(zkClient, providerPath, true);        pathCache.start();        pathCache.getListenable().addListener(new ProviderRefreshListener(pathCache));    &#125; catch (Exception e) &#123;        logger.error(&quot;Add provider refresh listener failed, the target path was &quot; + providerPath + &quot;, the curator client was &quot; + zkClient);        e.printStackTrace();    &#125;&#125;/**    * 该 listener 用于刷新 provider 信息    */private class ProviderRefreshListener implements PathChildrenCacheListener &#123;    private final PathChildrenCache pathCache;    public ProviderRefreshListener(PathChildrenCache pathCache) &#123;        this.pathCache = pathCache;    &#125;    @Override    public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception &#123;        PathChildrenCacheEvent.Type eventType = event.getType();        // 如果 child 信息发生变化，进行更新        switch (eventType) &#123;            case CHILD_ADDED:            case CHILD_REMOVED:            case CHILD_UPDATED: &#123;                List&lt;ChildData&gt; currentData = pathCache.getCurrentData();                List&lt;String&gt; providerUrls = new ArrayList&lt;&gt;(currentData.size());                for (ChildData data : currentData) &#123;                    providerUrls.add(data.getPath());                &#125;                // 这里是保存到 concurrent hash map 中，能够保证可见性                BeehiveContext.unsafePut(PROVIDERS, providerUrls);            &#125;        &#125;    &#125;&#125;\n\n接着就是创建服务接口的客户端代理，这里以 jdk 的客户端代理进行说明，还记得在服务端创建 jdk 代理时有获取一个代理 target 实例吗？它就是服务接口的实现类，完成了具体提服务逻辑。但现在我们是在创建客户端的代理，那么这里的代理 target 实例是什么呢？其实可以先试想一下，我们客户端在调用接口方法时，代理类应该完成啥样的逻辑呢？\nbeehive 这里的实现其实就是将被调用的接口方法和参数相关信息发送到服务端，服务端再根据收到的方法及参数信息完成真正的服务接口实现类的逻辑调用，最终再将处理的结果返回给客户端代理，最终代理将结果返回给方法调用者，完成这个发送方法及参数信息给服务端的类就是这里应该拿到的 target 实例，通过 debug，可以知道这个实例其实就是 FailoverClusterInvoker。它里边的实现逻辑不是这里应该关注的点，我们只需要知道，客户端的服务接口代理根本是调用的 FailoverClusterInvoker 实例的方法。知道这个后，jdk 代理类的创建就跟服务端一样了，具体到代码就是下边这一段，getInvoker(url) 拿到的是 FailoverClusterInvoker，它将被作为 target 而创建服务端接口代理类。\n\ntop.aprilyolies.beehive.proxy.JdkProxyFactory#createProxy\n\nInvoker invoker = getInvoker(url);return ConsumerProxy.getJdkProxy(new InvokerInvocationHandler(invoker, url), clazz, Proxy.class);\n\n完成客户端服务接口代理类创建的说明，就只剩下 doPublish(url);，跟服务端一样就是向注册中心写入自身的信息，使用的是 curator 框架，过程很简单，不做细说，只给出写入的结果。\n\n\nzookeeper 中写入的消费者信息\n\n客户端 RPC 请求流程当完成客户端和服务端的启动后，客户端就可以进行 rpc 请求了，还记的上文指出的 FailoverClusterInvoker 实例吗？它是客户端代理类真正逻辑的起点。从类名可以知道它是一个 Invoker 类，自然是实现了 Invoker 接口，这样我们关注的也就是该接口对应的 Invoker#invoke 方法，它的实现是在父类 AbstractInvoker 之中，该方法又是调用了 AbstractInvoker#doInvoke 方法，子类负责实现该方法的逻辑，这里是典型的模板方法设计模式。\n我先把 FailoverClusterInvoker#doInvoke 方法贴出来，第一个 if 判断实现看看缓存中是否有 invokers 信息，如果没有就会执行 listInvokers 方法来列出可用的 invokers。\n\ntop.aprilyolies.beehive.invoker.FailoverClusterInvoker#doInvoke\n\n@Overrideprotected Object doInvoke(InvokeInfo info) &#123;    try &#123;        if (this.invokers == null || registry == null) &#123;            synchronized (this) &#123;                if (invokers == null || registry == null) &#123;                    invokers = listInvokers();                    Registry registry = BeehiveContext.unsafeGet(REGISTRIES, Registry.class);                    addInvokersRefreshListener(this.registry);                    this.registry = registry;                &#125;            &#125;        &#125;        if (needUpdateInvokers) &#123;            updateInvokers();        &#125;        int reInvokeCount = retryCountThreadLocal.get();        LoadBalance loadBalance = loadBalanceThreadLocal.get();        if (loadBalance == null) &#123;            loadBalance = createLoadBalance(url);            loadBalanceThreadLocal.set(loadBalance);        &#125;        // 选择合适的 invoker        Invoker&lt;T&gt; invoker = selectInvoker(loadBalance, invokers);        if (invoker != null) &#123;            Invoker chain = buildInvokerChain(invoker);            Object result = chain.invoke(info);            if (result == null) &#123;                // 辅助刷新 invokers                needUpdateInvokers = true;                // 返回结果为空进行重试                if (reInvokeCount++ &lt; MAX_REINVOKE_TIMES) &#123;                    retryCountThreadLocal.set(reInvokeCount);                    return doInvoke(info);                &#125; else &#123;                    // 重试达到上限，直接返回 null 结果                    throw new IllegalStateException(&quot;Do invoke &quot; + MAX_REINVOKE_TIMES + &quot; times, but the result was still null&quot;);                &#125;            &#125; else return result;        &#125; else &#123;            throw new IllegalStateException(&quot;There is none of service provider could be use, please check your &quot; +                    &quot;registry center that if there is any service has published.&quot;);        &#125;    &#125; finally &#123;        retryCountThreadLocal.set(0);    &#125;&#125;\n\n如下就是列出可用 invokers 信息的方法，首先是拿到注册中心上发布的服务信息的集合，在服务端启动时，会首先获取一次该集合并缓存到 BeehiveContext 中，如果后续发生了服务信息的更新即服务的上下线等，客户端启动时注册的监听器会侦测该变化，并刷新服务信息集合。接着就是过滤这些服务信息，因为即便是相同的服务，可能会由于发布服务时使用的编解码方式与客户端使用的编解码方式不一致导致服务不能直接访问，这样该服务也就应该被过滤掉。过滤的条件可以更加细化，如果你有好的建议也可以提交 PR，我看到后会进行处理。完成服务信息的过滤后接着就是获取当前服务对应的通信终端，最后将获取的服务信息和通信终端构建为 RemoteInvoker 返回。\n\ntop.aprilyolies.beehive.invoker.FailoverClusterInvoker#listInvokers\n\nprivate synchronized List&lt;Invoker&lt;T&gt;&gt; listInvokers() &#123;    //noinspection unchecked    Map&lt;String, List&lt;String&gt;&gt; providersMap = BeehiveContext.unsafeGet(UrlConstants.PROVIDERS, Map.class);    List&lt;String&gt; providers = providersMap.get(url.getParameter(UrlConstants.SERVICE));    providers = filterProviders(providers);    this.providers = providers;    Client client = BeehiveContext.unsafeGet(UrlConstants.CONSUMERS_TRANSPORT, Client.class);    assert providers != null;    return createRemoteInvoker(providers, client);&#125;\n\nFailoverClusterInvoker#doInvoke 的第二个 if 条件是判断是否服务发生了更新，如果发生了更新就需要刷新 invokers 列表，刷新的过程和列出 invokers 列表的逻辑相似，只是这其中涉及到一个集合操作，即剔除下线的服务，新增上线的服务，感兴趣的话可以自己看源代码。\n接下来的代码就是从列出的 invokers 列表中选择一个 invoker 构建 invoker 链，然后进行 invoke 调用，选择 invoker 的过程我将其描述为一个负载均衡的过程，默认提供了两种负载均衡策略，随机选取和轮询选取，具体的由 PollLoadBalance 和 RandomLoadBalance 两个类来负责实现，代码也很简单，贴出来自行阅读即可。\npublic class RandomLoadBalance extends AbstractLoadBalance &#123;    private static final Random random = new Random(System.currentTimeMillis());    @Override    public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers) &#123;        try &#123;            if (invokers == null || invokers.size() == 0) &#123;                return null;            &#125;            int idx = Math.abs(random.nextInt() % invokers.size());            if (logger.isDebugEnabled()) &#123;                logger.debug(&quot;There are &quot; + invokers.size() + &quot; invokers, RandomLoadBalance choose the invoker with&quot; +                        &quot;index of &quot; + idx);            &#125;            return invokers.get(idx);        &#125; catch (Exception e) &#123;            logger.error(&quot;Got invoker failed, this may caused by some new provider was added, and the beehive&quot; +                    &quot; was refresh the invokers list&quot;);            return null;        &#125;    &#125;&#125;public class PollLoadBalance extends AbstractLoadBalance &#123;    private int idx = 0;    @Override    public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers) &#123;        int size = invokers.size();        if (idx &gt;= size) &#123;            idx = 0;        &#125;        return invokers.get(idx++);    &#125;&#125;\n\nFailoverClusterInvoker#selectInvoker 方法就是通过上述的两个负载均衡器选择一个合适的 invoker 的方法，拿到这个 invoker 后就是构建 invoker 链，这个过程和服务端启动的 invoker 链构建过程一样，这里不再赘述。接着就是调用 invoker 链的 invoke 方法，根据之前的分析我们知道 invoker 链的尾节点就是我们通过负载均衡器选择出来的那个 invoker，也就是我们在 FailoverClusterInvoker#listInvokers 方法中列出的众多 invokers 中的一个，他们都是 RemoteInvoker 实例，所以我们接下来分析该 invoker 的 invoke 方法。\n同样的 RemoteInvoker 是继承自 AbstractInvoker 父类，我们关注的是 doInvoke 方法的实现。这里还是先把代码贴出来，考虑到篇幅问题，我这里剃掉了部分空指针判断条件和失败重试代码，只留下了核心代码。简化后的代码可以很清楚的看到核心逻辑就三个，连接服务端，发送 rpc 请求信息，获取响应结果。连接服务端和发送 rpc 请求和 netty 的使用有关，如果不熟悉 netty 需要先自行了解 netty 的使用，本文这里不细述。而这里获取响应的结果是采用的异步的方式。\n@Overrideprotected Object doInvoke(InvokeInfo info) &#123;    try &#123;        // 获取当前线程的 channelMap        Map&lt;String, Channel&gt; channelMap = addressChannel.get();        Channel ch = channelMap.get(channelKey);        if (ch == null || !ch.isOpen() || !ch.isActive()) &#123;            // 连接服务器            ch = connectServer();        &#125;        // 构建 request 消息        Request request = buildRequest(info);        // 发送消息        ch.writeAndFlush(request);        // 获取异步的响应结果        Object result = getResponse(request);        String retryTimes = this.url.getParameter(UrlConstants.RETRY_TIMES);        int times = RETRY_TIMES;        if (!StringUtils.isEmpty(retryTimes)) &#123;            try &#123;                times = Integer.parseInt(retryTimes);            &#125; catch (NumberFormatException e) &#123;            &#125;        &#125;        return result;    &#125; catch (Exception e) &#123;        return null;    &#125;&#125;\n\n获取 rpc 结果的入口方法是 RemoteInvoker#getResponse,这里需要明确的一点是每一个 rpc 请求都有它所唯一对应的 id 来标志，rpc 请求结果的异步获取利用了这个特性。进行当前 rpc 请求的线程将本次请求的 id 和一个 RpcResult 形成映射缓存到 BeehiveContext，然后当前线程调用该 RpcResult 的 get 方法来获取结果。\n/**    * 从 BeehiveContext 中获取异步的响应结果    *    * @param request    * @return    */private Object getResponse(Request request) &#123;    // 拿到请求的 id，用于异步获取响应内容    String sid = String.valueOf(request.getId());    // 存根请求结果    BeehiveContext.unsafePut(sid, new RpcResult());    // 异步获取相应结果    Object res = null;    try &#123;        String timeout = this.url.getParameter(UrlConstants.READ_TIMEOUT);        if (StringUtils.isEmpty(timeout)) &#123;            res = BeehiveContext.unsafeGet(sid, RpcResult.class).get();        &#125; else &#123;            try &#123;                int time = Integer.parseInt(timeout);                res = BeehiveContext.unsafeGet(sid, RpcResult.class).get(time);            &#125; catch (NumberFormatException e) &#123;                logger.warn(&quot;The timeout parameter &quot; + timeout + &quot; is wrong, use the default timeout 2000ms&quot;);                res = BeehiveContext.unsafeGet(sid, RpcResult.class).get();            &#125;        &#125;    &#125; catch (Throwable t) &#123;        // empty    &#125;    // 移除缓存    BeehiveContext.unsafeRemove(sid);    return res;&#125;\n\n下边列出了 RpcResult 的 get 方法，可以看到这里使用了 Condition 来完成线程之间的通信。如果 rpc 请求过程的完成标志 finished 为 false，进行 get 方法的当前线程会进行限时阻塞。如果在阻塞的过程中 rpc 过程完成，当前被阻塞的线程会被唤醒继续之前的逻辑。如果发生超时，那么之前的代码会根据情况进行请求的重试。\n/**    * 带延时的获取相应的结果    *    * @param timeout 延时时长    * @return 相应的结果    */public Object get(int timeout) &#123;    if (finished) &#123;        return this.msg;    &#125; else &#123;        try &#123;            lock.lock();            if (!finished) &#123;                finishCondition.await(timeout, TimeUnit.MILLISECONDS);                if (!finished) &#123;                    throw new RuntimeException(&quot;Get result was timeout&quot;);                &#125; else &#123;                    return this.msg;                &#125;            &#125;            return this.msg;        &#125; catch (InterruptedException e) &#123;            logger.error(&quot;Get result was interrupted&quot;);            throw new RuntimeException(&quot;Get result was interrupted&quot;);        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;\n\n异步获取 rpc 请求的结果的方式就是这样，这里有个疑问是谁来负责唤醒当前的阻塞线程呢？这个就需要牵涉到 netty 的 channel handler 对于 rpc 结果的处理了，这里我们只需要知道如果 rpc 结果在有限时长内完成，那么当前线程会顺利的返回 rpc 的结果，如果超时就会进行重试，而负责唤醒当前阻塞线程的其它线程是跟 netty 有关的。\nnetty 通信客户端上边说到了进行 rpc 请求的线程在通过 netty 发送 rpc 信息后，调用 get 方法会阻塞在 rpc 结果的获取方法上，这部分即对 rpc 信息的发送编码过程进行说明，这里需要先明确 rpc 的信息是由 Request 实例承载的，我这里通过 debug 的方式给出一个 Request 实例的样例。可以看到其中就两个字段，消息的类型和 RPCINFO，里边包括了请求的方法名、参数的类型、参数的值以及服务的全限定名，通过这几项值就可以唯一确定服务的具体实现了。\n\n\nRequest 内部数据实例\n\n上文只是说了 NettyClient 的构建，但是具体的内容没有说明，其实关于 netty 客户端的创建，我们需要关心的就是 ChannelInitializer 对于 NioSocketChannel 的初始化过程，具体的代码如下：\nbootstrap.handler(new ChannelInitializer() &#123;    @Override    protected void initChannel(Channel ch) throws Exception &#123;        ch.pipeline()//.addLast(&quot;logging&quot;,new LoggingHandler(LogLevel.INFO))//for debug        .addLast(&quot;decoder&quot;, new NettyDecoderHandler(getUrl()))   // 指定 decoder -&gt; InternalDecoder        .addLast(&quot;encoder&quot;, new NettyEncoderHandler(getUrl()))   // 指定 encoder -&gt; InternalEncoder        // 该处理器用于向服务器发送心跳消息        .addLast(&quot;client-idle-handler&quot;, new IdleStateHandler(HEARTBEAT_INTERVAL, 0, 0, TimeUnit.MILLISECONDS))        .addLast(&quot;heartbeat-handler&quot;, new HeartbeatHandler())   // 该处理器主要是对心跳消息进行处理        .addLast(&quot;handler&quot;, new ClientFinalChannelHandler(getUrl()));    // 最后的 handler，就是核心的逻辑处理器    &#125;&#125;);\n\n这里的 IdleStateHandler 和 HeartbeatHandler 是和心跳消息相关联的，感兴趣可以自行阅读，对于我们的 Request 实例的发送和响应的接收而言，只跟 另外三个 ChannelHandler 相关，因为我们现在是发送 Request 包，直接定位到 NettyEncoderHandler#encode 方法如下，至于为什么会调用该方法，这就和 netty 的 channel pipeline 上的 channel handler context 与 channel handler 有关了，如果对 netty 的源码不熟，就会很难理解，如果有时间我后边会写一些关于 netty 源码的文章。好了，我们这里是 Request，走 requestEncode(ctx, msg, out); 分支。\n@Overrideprotected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception &#123;    serializer = extensionSelector.serializer(url, out);    if (msg instanceof Request) &#123;        requestEncode(ctx, msg, out);    &#125; else if (msg instanceof Response) &#123;        responseEncode(ctx, msg, out);    &#125;&#125;\n\n具体的代码如下，其实每一步我在注释中已经写得很详细了，我这里只要给出数据包的模型就能够很容易理解编码的过程，唯一要注意的是我们这里的 Request 是 RpcRequest，所以在进行数据包体的编码时，是从 Request 中获取到 data 即 RpcInfo 进行编码。\n\n\n\n魔幻数字（0 - 1）\n标志位（2）\n保留位（3）\n序列号（4 - 11）\n数据包体长度（12 - 15）\n\n\n\n占用 2 字节\n占用 1 字节\n占用 1 字节\n占用 8 字节\n占用 4 字节\n\n\nprivate void requestEncode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws IOException &#123;    Request request = (Request) msg;    if (logger.isDebugEnabled()) &#123;        logger.debug(&quot;Encode request message of &quot; + request);    &#125;    // 构建请求头    byte[] header = new byte[HEADER_LENGTH];    // 填充魔幻数字    ByteUtils.fillShort(MAGIC, header, 0);    // 填充请求头的标志字节    header[2] = (byte) (REQUEST_FLAG | extensionSelector.getSerializerId(url));    // 填充请求 id    ByteUtils.fillLong(request.getId(), header, 4);    // 这是 header 的起始位置    int headerIndex = out.writerIndex();    // 将 writer 指针定位到 body 写入的起始位置    int bodyIndex = headerIndex + HEADER_LENGTH;    out.writerIndex(bodyIndex);    // 对于 rpc 请求的编码和事件消息的编码是不一样的    if (request.isEvent()) &#123;        header[2] = (byte) (header[2] | EVENT_FLAG);        encodeEventRequest(request.getData());    &#125; else &#123;        encodeRpcRequest(request.getData());    &#125;    serializer.flushBuffer();    int len = out.writerIndex() - bodyIndex;    // 填充 header 的长度信息    ByteUtils.fillInt(len, header, 12);    // 将位置定位到 header 起始位置    out.writerIndex(headerIndex);    // 写入头信息    out.writeBytes(header);    // 将指针定位到全部数据写入后应该在的位置    out.writerIndex(bodyIndex + len);&#125;/**    * 将 rpc 相关的信息写入，不采用直接写入 object 的方式是为了最大的降低数据传输的量    *    * @param msg    * @throws IOException    */private void encodeRpcRequest(Object msg) throws IOException &#123;    RpcInfo info = (RpcInfo) msg;    // 请求的服务的名字    serializer.writeUTF(info.getServiceName());    // 请求的方法名    serializer.writeUTF(info.getMethodName());    // 请求的方法参数类型（用签名的方式表示）    serializer.writeUTF(ReflectUtils.getDesc(info.getPts()));    // 方法调用的参数值    Object[] pvs = info.getPvs();    if (pvs != null) &#123;        for (Object pv : pvs) &#123;            serializer.writeObject(pv);        &#125;    &#125;&#125;\n\n将编码后的结果发送给服务端后，服务端会进行解码，然后根据解码的结果完成对应的服务接口实现类方法的调用，这个稍后进行说明，方法调用的结果，服务端也是通过 netty 发送回来，同样的数据包也是经过编码的，客户端需要对其进行解码，才能得到具体的结果，这个过程是在 NettyDecoderHandler#decode 方法中完成的，至于为什么是在这个方法，那么又需要涉及到 netty 的源码实现了。在该方法中，核心就是调用 NettyDecoderHandler#prepareDecode 方法，如果能够理解编码的过程，那么解码就是一个逆向过程，结合我在代码中的注释应该就能理解，这里也不再赘述.需要注意的是 NettyDecoderHandler#prepareDecode 方法解码出来的结果会在 NettyDecoderHandler#decode 中添加到 List&lt;Object&gt; out 集合中，然后在父类中会逐个的将里边的元素取出并交由下一个 ChannelHandler 处理，这里也就是我们在创建 NettyClient 时指定的 ClientFinalChannelHandler。\n@Overrideprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123;    while (in.isReadable()) &#123;        int readerIndex = in.readerIndex();        serializer = extensionSelector.deserializer(url, in);        int pre = count;        Object result = prepareDecode(ctx, in, out);        if (result == EMPTY_RESULT) &#123;            in.readerIndex(readerIndex);            count = pre;            break;        &#125; else &#123;            int len = count - pre;            in.readerIndex(readerIndex + len);            out.add(result);        &#125;    &#125;&#125;private Object prepareDecode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123;    int readable = in.readableBytes();    byte[] header = new byte[Math.min(readable, HEADER_LENGTH)];    in.readBytes(header);    // 如果魔幻头不一致，那么就需要重新定位到新的魔幻头    if ((readable &gt; 0 &amp;&amp; header[0] != MAGIC_LOW) || (readable &gt; 1 &amp;&amp; header[1] != MAGIC_HIGH)) &#123;        int length = header.length;        if (header.length &lt; readable) &#123; // 这里说明够头部的长度            // 这里就说明，除了 header 的字节部分，还有真正的数据部分            header = ByteUtils.copyOf(header, readable);            // 这样就是将全部数据读到了 header 中，前 16 个为 header 部分，后边的为剩余数据            in.readBytes(header, length, readable - length);    // 全部的数据都到了 header 中        &#125;        for (int i = 1; i &lt; header.length - 1; i++) &#123;            if (header[i] == MAGIC_LOW &amp;&amp; header[i + 1] == MAGIC_HIGH) &#123;    // 这里是重新确定魔幻头的位置                // 这里就说明又检测到了一个数据包，那么就将第一个数据包的内容放到 header 中                in.readerIndex(in.readerIndex() - header.length + i);   // 将 readerIndex 重新定位到新的魔幻头位置                readable = in.readableBytes();                header = new byte[Math.min(readable, HEADER_LENGTH)];                in.readBytes(header);                break;            &#125;        &#125;        // 一次只解析一个数据包    &#125;    // check length.    if (readable &lt; HEADER_LENGTH) &#123; // 接收到的数据还不足以解析出一个完整的数据包        return EMPTY_RESULT;    &#125;    // get data length. 根据 header 获取 len 信息    int len = ByteUtils.readInt(header, 12);    // 总长度为 header + 数据长度（header 后四位进行记录）    int tt = len + HEADER_LENGTH;    if (readable &lt; tt) &#123;    // 也就是说目前接受到的数据还不够 header + 包长度得到的总长度        return EMPTY_RESULT;    &#125;    count += tt;    // limit input stream.通过 ChannelBufferInputStream 对 buffer 进行封装，记录了内容读取的上下界    // ChannelBufferInputStream -&gt; NettyBackedCahnnelBuffer -&gt; Netty 原生 buf    return doDecode(header); // 解码除开 header 以外的信息&#125;private Object doDecode(byte[] header) &#123;    byte flag = header[2], proto = (byte) (flag &amp; SERIALIZER_MASK);    // get request id.    long id = ByteUtils.readLong(header, 4);    // 如果标志位是不是 request，那就说明是收到的 response    if ((flag &amp; REQUEST_FLAG) == 0) &#123;        // decode response.        Response res = new Response(id);        // get status.        byte status = header[3];        res.setStatus(status);        // 判断当前相应是否为事件响应        try &#123;            try &#123;                if ((flag &amp; EVENT_FLAG) == 0) &#123;                    res.setType(MessageType.RESPONSE);                    Object msg = serializer.readObject();                    res.setData(msg);                &#125; else &#123;                    res.setType(MessageType.HEARTBEAT_RESPONSE);                    Object msg = serializer.readObject();                    res.setData(msg);                &#125;            &#125; catch (Exception e) &#123;                logger.error(&quot;Decode message error, please check provider and consumer use the same serializer&quot;);            &#125;        &#125; catch (Throwable e) &#123;            e.printStackTrace();        &#125;        return res;    &#125; &#125;\n\n清除 netty 原理的话就会知道在 ClientFinalChannelHandler 中接收上个 ChannelHandler 的处理结果的方法是 ClientFinalChannelHandler#channelRead，这个方法很简单，就只是向线程池中提交了一个 EventHandleThread 任务，它持有了解码出来的结果，那么接下来就是看这个 Task 对我们的解码结果做了什么处理。直接查看它的 run 方法。可以知道它就是直接调用 handleMsg();方法。因为我们收到的是服务端的 Response 数据包，所以只关注该方法的 else if (msg instanceof Response) 分支。\n/**    * 处理接收到的消息，此处的处理怎么看都不够优雅    *    * @throws IllegalAccessException    * @throws InstantiationException    */private void handleMsg() throws IllegalAccessException, InstantiationException &#123;    // 这里是对于非事件 request 的处理方式    else if (msg instanceof Response) &#123;        Response response = (Response) msg;        if (logger.isDebugEnabled()) &#123;            logger.debug(&quot;Received response message of &quot; + response);        &#125;        byte status = response.getStatus();        // 只对相应状态为 ok 的 response 进行处理        if (Response.OK == status) &#123;            Object data = response.getData();            RpcResult result = getRpcResult(response);            if (result != null) &#123;                // 完成相应结果的填充                result.fillData(data);            &#125;        &#125;    &#125;&#125;\n\n可以看到所做的事情就是从 Response 中拿到响应的数据，然后将其填充到 RpcResult 中，特别注意，这个 RpcResult 是和 rpc Request 的 id 对应的，所以填充的结果也是针对对应的 RpcResult，而在 RpcResult#fillData 方法中，就是完成了结果的填充，并唤醒了阻塞在当前 rpc 请求对应的线程，这样 rpc 请求的结果就被服务接口客户端代理返回给接口的方法调用者。\nnetty 通信服务端在服务端的启动中，我们也只是说了创建了 NettyServer，但是具体的细节没有进行说明，现在就完成这一部分的解释。和客户端一样，我们需要关注的是 ChannelInitializer 对于 NioSocketChannel 的初始化，方法如下：\n .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;    @Override    protected void initChannel(NioSocketChannel ch) throws Exception &#123;        // 从 url 中获取 idleTimeout 时长，如果 url 参数中没有指定，那么就直接使用三倍的 heartBeat 时长        ch.pipeline()//.addLast(&quot;logging&quot;,new LoggingHandler(LogLevel.INFO))//for debug                .addLast(&quot;decoder&quot;, new NettyDecoderHandler(getUrl()))   // InternalDecoder                .addLast(&quot;encoder&quot;, new NettyEncoderHandler(getUrl()))   // InternalEncoder                // 用于检测 channel 空闲状态，条件成立时关闭对应的 channel，相对的客户端的 Idle 处理器则用于发送心跳消息                .addLast(&quot;server-idle-handler&quot;, new IdleStateHandler(0, 0, IDLE_TIMEOUT, MILLISECONDS))                .addLast(&quot;heartbeat-handler&quot;, new HeartbeatHandler())                .addLast(&quot;final-handler&quot;, new ServerFinalChannelHandler(getUrl()));    &#125;&#125;);\n\n上文已经说过了前四个 ChannelHandler 的作用及使用了，服务端对于他们的使用基本一致，所以也不再赘述，最后一个 ChannelHandler 和 NettyClient 的最后一个 ChannelHandler 的作用基本一致，都是向线程池中提交了一个 EventHandleThread，里边的方法是一样的，只是因为处理的是来自客户端的 Request 包，所以走的是 EventHandleThread#handleMsg 方法的 if (msg instanceof Request) 分支。\n// 这里是对于非事件 request 的处理方式if (msg instanceof Request) &#123;    Request request = (Request) msg;    if (logger.isDebugEnabled()) &#123;        logger.debug(&quot;Received request message of &quot; + request);    &#125;    if (!request.isEvent()) &#123;        // 根据 request 相关的内容构建 response        Response response = buildResponse(request);        Object data = request.getData();        // 如果 request 携带的数据为 RpcInfo，那么就根据其进行相应的 invoker 调用        if (data instanceof RpcInfo) &#123;            Object result = doInvoke((RpcInfo) data);            // 将 invoke 的结果填充到 response 中            response.setData(result);            // 将响应结果写回            ctx.writeAndFlush(response);        &#125;    &#125;&#125;/**    * 根据 RpcInfo 进行逻辑调用，获取调用的结果    *    * @param data    * @return    * @throws InstantiationException    * @throws IllegalAccessException    */private Object doInvoke(RpcInfo data) throws InstantiationException, IllegalAccessException &#123;    RpcInfo info = data;    // 尝试从 BeehiveContext 中获取 invoker 实例    Invoker invoker = BeehiveContext.unsafeGet(info.getServiceName(), Invoker.class);    // 根据 url 信息获取 invoke target 实例    ServiceConfigBean serviceConfigBean = BeehiveContext.unsafeGet(UrlConstants.PROVIDER_MODEL, ServiceConfigBean.class);    Object target = serviceConfigBean.getRef();    // 进行真正的 invoke 操作    return invoker.invoke(info.createInvokeInfo(target));    &#125;\n\n在该分支中，首先是构建了一个 Response 实例，这个实例的 id 是和 Request 一致的，这样客户端收到该 Response 数据包后才知道对应哪个 RpcResult 实例。接下来，就是从收到的 Request 中拿到数据 RpcInfo，里边包含了 rpc 的服务名、方法名、参数类型签名、参数值。EventHandleThread#doInvoke 方法就是根据以上这些进行服务接口实现类方法的调用。可以看到它先从 BeehiveContext 中拿到了一个 Invoker 实例，其实它就是在服务端启动时创建的 Invoker 链。其最后一个节点就封装了服务接口的实现类。当我们进行 invoker 链的 invoke 方法调用时，最终就会触发服务接口的实现类对应方法的调用，返回的就是该方法的执行结果。拿到该结果后，就是将它填充到 Response 实例中，调用 tx.writeAndFlush(response); 将响应结果返回，这样一个完成的 rpc 过程就算完成了。\nTODO-LIST\n底层通信框架的支持有待完善，比如 Mina（我没接触过）\n\n缺少一个服务的管理模块，框架当前提供了相应的 filter 接口，通过实现该接口即可对 rpc 请求进行拦截，由此来获取部分监控信息\n\nSPI 拓展机制没有完成相应的组件筛选功能，比如 filter 接口实现类，框架没有提供基础的选择性获取方式\n\n异步消息处理的线程池的构建应该更加灵活，相应的拒绝执行策略有待完善\n\n负载均衡策略缺陷严重，应该需要根据实际的 provider 负载情况来动态的调整\n\n\n","categories":["后台开发"],"tags":["RPC"]},{"title":"Spring AOP 实现原理分析","url":"/2019/07/21/2019-07-21-Spring-AOP-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","content":"前言本文是关于 spring aop 实现原理的分析文章，因为 spring 源码博大精深，对于 aop 实现的细节部分不可能通过此一篇文章讲解清楚，所以本文只是从整体的角度来看 aop 的实现，虽然细节部分不会细说，但是对于理解其实现及分析其执行过程而言足以。另外本文是建立在你已经对 spring 的 ioc 实现原理有一定的理解基础之上，特别是清楚 spring 的标签解析以及 spring 管理的 bean 的声明周期。在写这篇文章之前我先大致看过了 spring-framework 源码的 aop 部分，在看的过程中还写了一小部分注释来帮助自己理解，这部分内容我已经将其放到了我的 github 之上，欢迎欢迎自取。 整个源码是我从官方 fork 下来的，除了注释部分我没做任何改动，另外在其中加了一个 spring-example 模块，用来写测试样例，方便源码分析。原项目是用 gradle 构建的，对于不熟悉 gradle 项目的同学可以参考项目根目录下的 import-into-xxx.md 文档来将项目导入到自己熟悉的 ide 中（其实我 fork 下来也是第一次接触 gradel 工程），原项目 build.gradle 文件中有很多不必要的 task，我已经将其注释掉，由此来提高 build 的速度。\naop 测试样例在分析 aop 实现原理之前，我们需要先看两个 aop 测试代码，具体的源码分析过程就是基于这两个测试代码的，源码欢迎自取。\n测试代码一\n主函数 top.aprilyolies.example.aop.AopApp\n\npublic class AopApp &#123;\tpublic static void main(String[] args) &#123;\t\tClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-aop.xml&quot;);\t\tTestBean bean = (TestBean) context.getBean(&quot;test&quot;);\t\tbean.test();\t&#125;&#125;\n\n\n切面定义 top.aprilyolies.example.aop.AspectJBean\n\n@Aspectpublic class AspectJBean &#123;    @Pointcut(&quot;execution(* *.test*(..))&quot;)\t// 这个可能就是引介增强方法，这里可能就是切点    public void test() &#123;&#125;    @Before(&quot;test()&quot;)\t// 这个可能就是切点增强方法    public void beforeTest() &#123;        System.out.println(&quot;beforeTest&quot;);    &#125;    @After(&quot;test()&quot;)\tpublic void afterTest() &#123;\t\tSystem.out.println(&quot;afterTest&quot;);\t&#125;\t@Around(&quot;test()&quot;)\tpublic Object aroundTest(ProceedingJoinPoint p) &#123;\t\tObject o = null;\t\tSystem.out.println(&quot;aroundBefore&quot;);\t\ttry &#123;\t\t\to = p.proceed();\t\t&#125; catch (Throwable throwable) &#123;\t\t\tthrowable.printStackTrace();\t\t&#125;\t\tSystem.out.println(&quot;aroundAfter&quot;);\t\treturn o;\t&#125;&#125;\n\n\n测试 bean top.aprilyolies.example.aop.TestBean\n\npublic class TestBean &#123;\tpublic TestBean() &#123;\t\tSystem.out.println(&quot;TestBean constructor&quot;);\t&#125;\tpublic void test() &#123;\t\tSystem.out.println(&quot;test method....&quot;);\t\tSystem.out.println(&quot;----------&quot;);\t\ttest1();\t\tSystem.out.println(&quot;----------&quot;);\t&#125;\tpublic void test1() &#123;\t\tSystem.out.println(&quot;test1 method....&quot;);\t&#125;&#125;\n\n\nspring-aop.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;\t   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\t   xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;\t   xsi:schemaLocation=&quot;http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd        http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd&quot;&gt;\t&lt;aop:aspectj-autoproxy/&gt;\t&lt;bean id=&quot;test&quot; class=&quot;top.aprilyolies.example.aop.TestBean&quot;/&gt;\t&lt;bean id=&quot;aspectJBean&quot; class=&quot;top.aprilyolies.example.aop.AspectJBean&quot;/&gt;&lt;/beans&gt;\n\n\n执行结果\n\nTestBean constructor    // 构造函数执行aroundBefore    // around 增强beforeTest  // before 增强test method.... // test* 方法----------test1 method....----------aroundAfter // around 增强afterTest   // after 增强\n\n测试样例很简单，其实就是定义了一个切面类，里边描述了一些切面信息，比如这里就是对任意包下的任意类，返回值不限的任意 test* 方法进行增强，分为三种类型的增强，after、before、around。也就是说我在调用 test* 方法时，上述的三个方法会在何时的位置调用，理解这个后再看上边的执行结果应该就很清楚了，至于为什么会进行这样的调用，就是本文分析的重点了，稍后再说，再看第二个示例程序。\n测试代码二\n主函数\n\npublic class AopApp &#123;\tpublic static void main(String[] args) &#123;\t\tClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-aop-expose.xml&quot;);\t\tTestBean bean = (TestBean) context.getBean(&quot;test&quot;);\t\tbean.test();\t&#125;&#125;\n\n\n测试 bean top.aprilyolies.example.aop.TestBean\n\npublic class TestBean &#123;\tpublic TestBean() &#123;\t\tSystem.out.println(&quot;TestBean constructor&quot;);\t&#125;\tpublic void test() &#123;\t\tSystem.out.println(&quot;test method....&quot;);\t\tTestBean testBean = (TestBean) AopContext.currentProxy();\t\tSystem.out.println(&quot;----------&quot;);\t\ttestBean.test1();\t\ttest1();\t\tSystem.out.println(&quot;----------&quot;);\t&#125;\tpublic void test1() &#123;\t\tSystem.out.println(&quot;test1 method....&quot;);\t&#125;&#125;\n\n\nspring-aop-expose.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;\t   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\t   xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;\t   xsi:schemaLocation=&quot;http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd        http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd&quot;&gt;\t&lt;aop:aspectj-autoproxy expose-proxy=&quot;true&quot;/&gt;\t&lt;bean id=&quot;test&quot; class=&quot;top.aprilyolies.example.aop.TestBean&quot;/&gt;\t&lt;bean id=&quot;aspectJBean&quot; class=&quot;top.aprilyolies.example.aop.AspectJBean&quot;/&gt;&lt;/beans&gt;\n\n切面定义类不变，看执行结果：\nTestBean constructoraroundBeforebeforeTesttest method....----------aroundBeforebeforeTesttest1 method....aroundAfterafterTest----------aroundAfterafterTest\n\n其实和测试代码一的逻辑基本一致，只是在 spring 的配置文件中，&lt;aop:aspectj-autoproxy expose-proxy=&quot;true&quot;/&gt; 标签多了一个 expose-proxy&#x3D;”true” 属性，然后 TestBean#test 方法中并不是直接调用 TestBean#test1 方法，而是从 AopContext 中拿到当前的代理类，再调用它的 test1 方法，可以看到，上述的三个增强方法也都执行了，而直接通过用户代码调用 test1 方法，以上的增强方法就不会发生调用。这里说明，如果我们自己的用户代码在内部调用其他方法时，需要被调用的方法同样得到增强，那么就需要采用测试代码二那样的方式获取到当前的代理类，然后进行对应方法的调用，直接进行调用的方式是不对得到增强的。\n&lt;aop:aspectj-autoproxy&#x2F;&gt; 标签解析如果对 spring 的标签解析原理熟悉，那么你在分析 aop 实现原理时，就一定会想到从 &lt;aop:aspectj-autoproxy&#x2F;&gt; 标签的解析开始，它是启动 spring aop 的根本。spring 本身对于标签的解析实现很有规则，总的就是将标签分为默认标签和自定义标签。从 DefaultBeanDefinitionDocumentReader#parseBeanDefinitions 方法就可以看出这个区别。\n\norg.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#parseBeanDefinitions\n\n/**    * Parse the elements at the root level in the document:    * &quot;import&quot;, &quot;alias&quot;, &quot;bean&quot;.    * @param root the DOM root element of the document    */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123;    if (delegate.isDefaultNamespace(root)) &#123;\t// 这个分支是解析默认的 Namespace 标签        NodeList nl = root.getChildNodes();        for (int i = 0; i &lt; nl.getLength(); i++) &#123;            Node node = nl.item(i);            if (node instanceof Element) &#123;                Element ele = (Element) node;                if (delegate.isDefaultNamespace(ele)) &#123;                    parseDefaultElement(ele, delegate);                &#125;                else &#123;                    delegate.parseCustomElement(ele);                &#125;            &#125;        &#125;    &#125;    else &#123;        delegate.parseCustomElement(root);\t// 这个分支就是解析用户自定义的 Namespace 标签    &#125;&#125;\n\n对于默认标签而言，从下面的代码可以看出主要是包含 import、alias、bean、beans 四种标签。\n\norg.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#parseDefaultElement\n\n// 解析默认的标签，可以看出来有 import、alias、bean、beansprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123;    if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123;        importBeanDefinitionResource(ele);    &#125;    else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123;        processAliasRegistration(ele);    &#125;    else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123;        processBeanDefinition(ele, delegate);    &#125;    else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123;        // recurse        doRegisterBeanDefinitions(ele);    &#125;&#125;\n\n而对于非默认的标签，spring 则是通过对应标签命名空间的 NamespaceHandler 来注册对应空间下不同标签的解析器来完成解析的，这种 NamespaceHandler 的命名很规范，比如我们现在是分析 aop 实现，核心标签就是 &lt;aop:aspectj-autoproxy&#x2F;&gt;，其对应的命名空间就是 aop，所以我们只需要打开其对应的 AopNamespaceHandler 就可以分析 spring 对于相应的标签做了啥处理。\n\norg.springframework.aop.config.AopNamespaceHandler\n\npublic class AopNamespaceHandler extends NamespaceHandlerSupport &#123;\t/**\t * Register the &#123;@link BeanDefinitionParser BeanDefinitionParsers&#125; for the\t * &#x27;&#123;@code config&#125;&#x27;, &#x27;&#123;@code spring-configured&#125;&#x27;, &#x27;&#123;@code aspectj-autoproxy&#125;&#x27;\t * and &#x27;&#123;@code scoped-proxy&#125;&#x27; tags.\t */\t@Override\tpublic void init() &#123;\t\t// In 2.0 XSD as well as in 2.1 XSD.\t\tregisterBeanDefinitionParser(&quot;config&quot;, new ConfigBeanDefinitionParser());\t\tregisterBeanDefinitionParser(&quot;aspectj-autoproxy&quot;, new AspectJAutoProxyBeanDefinitionParser());\t\tregisterBeanDefinitionDecorator(&quot;scoped-proxy&quot;, new ScopedProxyBeanDefinitionDecorator());\t\t// Only in 2.0 XSD: moved to context namespace as of 2.1\t\tregisterBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser());\t&#125;&#125;\n\n好了，看到这个后我们就清楚了，对于 aop 命名空间，它下边是有四种类型的标签的，我们这里只用到了 aspectj-autoproxy，就只分析这一个。通过看类名就知道，不同的标签对应着一个 BeanDefinitionParser，这是一个接口，里边只有一个 BeanDefinitionParser#parse 方法，那就直接看 AspectJAutoProxyBeanDefinitionParser#parse 方法如下：\npublic BeanDefinition parse(Element element, ParserContext parserContext) &#123;    AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element);\t// 主要就是注册了一个 AnnotationAwareAspectJAutoProxyCreator，并对 &lt;aop:aspectj-autoproxy/&gt; 标签的 proxy-target-class 和 expose-proxy 属性的处理    extendBeanDefinition(element, parserContext);    return null;&#125;\n\n主要就是两行代码，对于第二行代码，是一个对于当前标签的子标签的处理，因为这里没用到，所以我直接就忽略了。重点关注第一行代码，从名字就知道，核心就是向 spring 容器注册一个 AspectJAnnotationAutoProxyCreator 实例，进去后看实现：\n// 主要就是注册了一个 AnnotationAwareAspectJAutoProxyCreator，并对 &lt;aop:aspectj-autoproxy/&gt; 标签的 proxy-target-class 和 expose-proxy 属性的处理public static void registerAspectJAnnotationAutoProxyCreatorIfNecessary(        ParserContext parserContext, Element sourceElement) &#123;    // 尝试向 DefaultListableBeanFactory 中注册 AnnotationAwareAspectJAutoProxyCreator 对应的 bean，如果已存在，则注册优先级较高的那个    BeanDefinition beanDefinition = AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(            parserContext.getRegistry(), parserContext.extractSource(sourceElement));    useClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement);\t// 对于 &lt;aop:aspectj-autoproxy/&gt; 标签 proxy-target-class 和 expose-proxy 属性的处理    registerComponentIfNecessary(beanDefinition, parserContext);\t// 核心就是注册 AnnotationAwareAspectJAutoProxyCreator 对应的 beanDefinition（封装为 BeanComponentDefinition）&#125;\n\n一共就三行代码，先看第一行，直接点进去可以看到代码是这样的，关于其作用我已经通过注释的方式进行标注了，根本的实现就是一个类似标签解析生成 BeanDefinition 的过程，如果你看过标签解析的话，那么你对这串代码一定不会陌生，而且 BeanDefinition 这个实例你也一定很耳熟。\n@Nullable\t// 尝试向 DefaultListableBeanFactory 中注册 AnnotationAwareAspectJAutoProxyCreator 对应的 bean，如果已存在，则注册优先级较高的那个public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(        BeanDefinitionRegistry registry, @Nullable Object source) &#123;    // 尝试向 DefaultListableBeanFactory 中注册 AnnotationAwareAspectJAutoProxyCreator 对应的 bean，如果已存在，则注册优先级较高的那个    return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);&#125;@Nullable\t// 尝试向 DefaultListableBeanFactory 中注册 cls 对应的 bean，如果已存在，则注册优先级较高的那个private static BeanDefinition registerOrEscalateApcAsRequired(        Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123;    Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;);    if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123;\t// 这里是指已存在对应的 bean，那么就看谁的优先级高        BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME);        if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123;            int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName());            int requiredPriority = findPriorityForClass(cls);            if (currentPriority &lt; requiredPriority) &#123;                apcDefinition.setBeanClassName(cls.getName());            &#125;        &#125;        return null;    &#125;    RootBeanDefinition beanDefinition = new RootBeanDefinition(cls);    beanDefinition.setSource(source);    beanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE);    beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\t// 指明该 bean 在 spring 容器中的身份    registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition);    return beanDefinition;&#125;\n\n细节就不在深究了，因为牵扯的代码非常多，这里我们只需要清楚第一行代码就是向 spring 容器注册了一个 AnnotationAwareAspectJAutoProxyCreator 类型的类，在 spring 容器启动过程中，会根据既定的条件完成该类的初始化及生命周期方法的调用，对了需要注意，该类对应的实例在 spring 容器中的唯一标志符就是 AUTO_PROXY_CREATOR_BEAN_NAME = &quot;org.springframework.aop.config.internalAutoProxyCreator&quot;;。\n再看第二行代码，逻辑很简单，就是看当前标签的属性，如果有 proxy-target-class 或者 expose-proxy 属性，那么就将该属性的值设置到第一行代码注册的 AnnotationAwareAspectJAutoProxyCreator 类对应的 BeanDefinition 中去。这样在通过 BeanDefinition 构建 bean 实例时，通过标签设置的属性值就会被注入到该 bean 中了。具体实现就是通过下边的代码，每个方法的作用我也进行了注释，很容易理解。还记得我们开篇的第二个测试代码嘛？标签中的 expose-proxy=&quot;true&quot; 属性值就是在这里被解析的。\n// 对于 &lt;aop:aspectj-autoproxy/&gt; 标签 proxy-target-class 和 expose-proxy 属性的处理private static void useClassProxyingIfNecessary(BeanDefinitionRegistry registry, @Nullable Element sourceElement) &#123;    if (sourceElement != null) &#123;        boolean proxyTargetClass = Boolean.parseBoolean(sourceElement.getAttribute(PROXY_TARGET_CLASS_ATTRIBUTE));        if (proxyTargetClass) &#123;            AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);        &#125;        boolean exposeProxy = Boolean.parseBoolean(sourceElement.getAttribute(EXPOSE_PROXY_ATTRIBUTE));        if (exposeProxy) &#123;            AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);        &#125;    &#125;&#125;// 为 AUTO_PROXY_CREATOR_BEAN_NAME 对应的 BeanDefinition 添加一个 proxyTargetClass 属性，值为 truepublic static void forceAutoProxyCreatorToUseClassProxying(BeanDefinitionRegistry registry) &#123;    if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123;        BeanDefinition definition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME);        definition.getPropertyValues().add(&quot;proxyTargetClass&quot;, Boolean.TRUE);    &#125;&#125;// 为 AUTO_PROXY_CREATOR_BEAN_NAME 对应的 BeanDefinition 添加一个 exposeProxy 属性，值为 truepublic static void forceAutoProxyCreatorToExposeProxy(BeanDefinitionRegistry registry) &#123;    if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123;        BeanDefinition definition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME);        definition.getPropertyValues().add(&quot;exposeProxy&quot;, Boolean.TRUE);    &#125;&#125;\n\n再看第三行代码，没啥其他内容，就仅仅是一个注册 BeanDefinition 的过程，对于我们的 aop 原理分析而言，不是很紧要，仅贴出来实现就行。\n// 核心就是注册 AnnotationAwareAspectJAutoProxyCreator 对应的 beanDefinition（封装为 BeanComponentDefinition）private static void registerComponentIfNecessary(@Nullable BeanDefinition beanDefinition, ParserContext parserContext) &#123;    if (beanDefinition != null) &#123;        parserContext.registerComponent(                new BeanComponentDefinition(beanDefinition, AopConfigUtils.AUTO_PROXY_CREATOR_BEAN_NAME));    &#125;&#125;\n\n好了，到这里关于 &lt;aop:aspectj-autoproxy&#x2F;&gt; 标签的解析过程就算完成了，进行总结一下该过程，核心就是根据 AnnotationAwareAspectJAutoProxyCreator 类创建一个对应的 BeanDefinition，然后看该标签是否有上述的两个属性值，如果就的话，就将对应的属性值填充到当前 BeanDefinition 中，最后就是将该 BeanDefinition 封装为 BeanComponentDefinition 注册到 parserContext 中。\n代理类的生成上边已经说完了标签解析的过程，知道了现在 spring 容器中存在一个 AnnotationAwareAspectJAutoProxyCreator 类对应的 BeanDefinition，在接下来的过程，spring 会根据 BeanDefinition 实现的不同声明周期接口，在不同的初始化阶段来完成对应方法的调用。既然这样，我们现在就关注一下 AnnotationAwareAspectJAutoProxyCreator 实现了什么接口。直接查看它的继承关系图。\n\n\nAnnotationAwareAspectJAutoProxyCreator 继承图\n\n\n\n直接看好像没有什么熟悉的声明周期接口对吧，但是如果你顺着继承关系逐个往上找，就会看到在其父类 AbstractAutoProxyCreator 中实现了一个 SmartInstantiationAwareBeanPostProcessor 接口，看过 spring ioc 实现原理的小伙伴应该对 BeanPostProcessor 这样的接口十分敏感，它意味着在 bean 的初始化不同阶段，spring 会完成对实现该类接口的 bean 的对应方法的调用，这里也不例外。当然直接通过 idea 的 diagram 绘制能更清楚的看出 AnnotationAwareAspectJAutoProxyCreator 实现的其它接口，但是这里我们只关心 SmartInstantiationAwareBeanPostProcessor。\n\n\nAnnotationAwareAspectJAutoProxyCreator 继承体系\n\n\n\n这里的 SmartInstantiationAwareBeanPostProcessor 接口又继承自 InstantiationAwareBeanPostProcessor，这样 AnnotationAwareAspectJAutoProxyCreator 要实现的方法就多了，应该重点关注哪个呢？其实我也不是很清楚，但是可以通过 debug 的方式来跟踪，下大致看一下全部的实现方法，发现所有的实现方法中，只有两个方法的实现逻辑稍微复杂且在 bean 的构建过程中被调用到，他们就是 AbstractAutoProxyCreator#postProcessBeforeInstantiation 和 AbstractAutoProxyCreator#postProcessAfterInitialization，我在这个两个方法第一行代码处各打一个断点，通过 debug 的方式，可以知道第一个方法的出口是返回的 null，跟我们期望的代理类生成没有关系，直接排除，那么可以暂时认定代理类的生成是通过 AbstractAutoProxyCreator#postProcessAfterInitialization 方法实现的。那么接下来就看在该方法中做了什么。\n@Override\t// 尝试从缓存中获取代理 bean，没有的话进行构建，核心就是构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123;    if (bean != null) &#123;        Object cacheKey = getCacheKey(bean.getClass(), beanName);        if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123;            return wrapIfNecessary(bean, beanName, cacheKey);\t// 核心就是构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中        &#125;    &#125;    return bean;&#125;\n\n从上述代码可以看到这里是一个从缓存中获取代理类，如果获取的结果和参数传入的 bean 不一致，就对传入的 bean 进行尝试代理的过程。那么这个参数传入的 bean 究竟是什么呢？？我通过 debug 的方式进行查看，结果如下：\n\n\n被处理的 bean 类型\n\n\n\n原来就是我们样例代码中的 TestBean，所以到这里一个大致的过程就需要明白了，在 spring 配置文件中，我们指定了 TestBean 来交给 spring 容器管理，在 spring 对该 bean 进行创建时，spring 会用各种 BeanPostProcessor 接口实现类对应的方法来对正在构建的 bean 进行处理，拿我们的样例程序来说就是：实现了 BeanPostProcessor 接口的 AnnotationAwareAspectJAutoProxyCreator 实例的 AbstractAutoProxyCreator#postProcessAfterInitialization 方法来对 TestBean 进行处理，具体的处理过程是啥样呢？就是上边代码框中那样，从注释可以知道就是一个对原 bean（TestBean）进行代理的过程。下边继续看这个代理 bean 如何构建的。\n/**    * Wrap the given bean if necessary, i.e. if it is eligible for being proxied.    * @param bean the raw bean instance    * @param beanName the name of the bean    * @param cacheKey the cache key for metadata access    * @return a proxy wrapping the bean, or the raw bean instance as-is    */\t// 判断是否需要代理，如果是，获取满足 beanClass 的 advisor，然后构建代理类：验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123;    if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123;        return bean;    &#125;    if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123;        return bean;\t// 无需代理，直接返回    &#125;    if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123;        this.advisedBeans.put(cacheKey, Boolean.FALSE);        return bean;\t// 基础类和应跳过的类直接返回    &#125;    // Create proxy if we have advice.\t// 获取满足 beanClass 的 advisor，进行过排序    Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);    if (specificInterceptors != DO_NOT_PROXY) &#123;        this.advisedBeans.put(cacheKey, Boolean.TRUE);\t// 所以这个集合存放的是对应的 bean 是否增强的信息        Object proxy = createProxy(\t// 验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中                bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));        this.proxyTypes.put(cacheKey, proxy.getClass());        return proxy;    &#125;    // 所以这个集合存放的是对应的 bean 是否增强的信息    this.advisedBeans.put(cacheKey, Boolean.FALSE);    return bean;&#125;\n\n上边的代码很好理解，前半部分就是一些验证，看被处理的 bean 是否满足被代理需求。如果不满足就会直接返回 bean，否则就会获取 specificInterceptors 集合，这个 specificInterceptors 集合的获取过程很麻烦，反正我是没有去逐行的看源码。仅仅是从方法名来判断各个步骤做了啥事情，我将能够展示程序执行脉络的代码贴出来，然后给出执行的结果，这样就算不通读源码，也能够理解其原理。\n@Override@Nullable\t// 获取满足 beanClass 的 advisor，进行过排序protected Object[] getAdvicesAndAdvisorsForBean(        Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123;    // 获取满足 beanClass 的 advisor，进行过排序    List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName);    if (advisors.isEmpty()) &#123;        return DO_NOT_PROXY;\t// 如果没有增强器，就不需要进行代理    &#125;    return advisors.toArray();&#125;protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123;    List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();\t// 获取候选的增强器    List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);\t// 获取能够使用的增强器    extendAdvisors(eligibleAdvisors);\t// 看 advisors 是否有切面增强器，有的话就在首位添加一个 DefaultPointcutAdvisor（ExposeInvocationInterceptor.ADVISOR）    if (!eligibleAdvisors.isEmpty()) &#123;        eligibleAdvisors = sortAdvisors(eligibleAdvisors);\t// 对 advisors 进行排序    &#125;    return eligibleAdvisors;&#125;\n\n代码的主干就上边那些，其实就是一个获取有效增强的过程，什么是有效增强嗯？通过 debug 的方式直接查看其内容如下，不难看出所谓的增加就是我们在切面类中定义的那些切面方法，即通过 @Before、@After、@Around 注解标注的方法。\n\n\n候选的增强集合\n\n\n\n\n\n增强对应的方法\n\n\n\n我们已经知道获取的结果了，那么该结果怎么来的呢？还是上边的代码，一共就四条逻辑，第一条逻辑 findCandidateAdvisors，看方法名就知道是获取候选的增强。里边的代码比较冗长，但核心就是获取所有切面类中所有定义的增强。至于我们的  @Before、@After、@Around 注解式如何被解析为 Advisor 呢？我没研究过，但就算是猜也能猜出大概了，切面类不是有 @Aspect 注解吗？它也是交由 spring 管理的，那么 spring 自然是会关注这个注解的，当对 bean 进行构建时，如果发现该 bean 有 @Aspect 注解，就遍历该 bean 的所有方法，看方法上是否有上述的三种增强注解（或许其他注解也是被解释为增强哈），如果有就将当前切面 bean 和对应的增强缓存起来，以便后边获取。当然这只是我的个人猜想，没去看源码，如果我猜的不对，还请指出。总之第一条逻辑就是获取全部切面类的增强就对了。\n第二条逻辑由 findAdvisorsThatCanApply 来实现，看方法名就知道是从全部的增强中获取当前被处理的 bean 能够使用的增强。怎么实现呢？我也不想看源码，直接猜吧，猜错也没事，方法名确实就是这个意思（其实还是大致看了一下源码的）。我们在切面类中不是指定了切点信息吗？？就是这个  @Pointcut(&quot;execution(* *.test*(..))&quot;) 意思就是当前切面类的增强适用于指定的全部切点。那么 findAdvisorsThatCanApply 方法就一定是根据切点表达式来分析我们当前正在处理的 bean 是否满足切点规则。如果满足的话，那么该增强就会被添加到返回集合，否则直接丢弃。最终 findAdvisorsThatCanApply 返回的就是能够应用在当前 bean 的增强了。\n第三条逻辑由 extendAdvisors 实现，没错的话我们在切面类中定义的增强只有三个对吗？？为什么最终返回结果有四个呢？？其实就是在这条逻辑中添加的，根本是执行的下边的代码，也就是说如果我们获取的可用增强中，如果有切面增强类，那么就一定会在增强链表的第一个位置加入一个 ExposeInvocationInterceptor.ADVISOR，至于作用嘛，暂时没研究，这个不影响后边的分析。\n// 看 advisors 是否有切面增强器，有的话就在首位添加一个 DefaultPointcutAdvisor（ExposeInvocationInterceptor.ADVISOR）public static boolean makeAdvisorChainAspectJCapableIfNecessary(List&lt;Advisor&gt; advisors) &#123;    // Don&#x27;t add advisors to an empty list; may indicate that proxying is just not required    if (!advisors.isEmpty()) &#123;        boolean foundAspectJAdvice = false;        for (Advisor advisor : advisors) &#123;            // Be careful not to get the Advice without a guard, as this might eagerly            // instantiate a non-singleton AspectJ aspect...            if (isAspectJAdvice(advisor)) &#123;\t// 看是否是切面增强器                foundAspectJAdvice = true;                break;            &#125;        &#125;\t// (ExposeInvocationInterceptor.ADVISOR 是放在首位的        if (foundAspectJAdvice &amp;&amp; !advisors.contains(ExposeInvocationInterceptor.ADVISOR)) &#123;            advisors.add(0, ExposeInvocationInterceptor.ADVISOR);            return true;        &#125;    &#125;    return false;&#125;\n\n最后一个逻辑就是对所有的增强进行排序，根本就是链表的排序，采用的是自定义的排序比较器，详细的可以自行分析源码，所以上边展示的最终返回的四个 eligibleAdvisor，就是通过上边四个逻辑来得到。回到我们的出发点，即AbstractAutoProxyCreator#wrapIfNecessary 方法的的 getAdvicesAndAdvisorsForBean 这一行，我们已经拿到了四个增强，接下来我们就是根据这个增强数组来构建代理类。\n代理类的构建过程也很麻烦，如果要逐行看代码那又是个大工程，这里实质是从宏观的角度来看代码逻辑，能够理解 aop 实现原理即可，直接进入到 AbstractAutoProxyCreator#createProxy 方法中，我已经写了蛮多注释了，所以这里只是总结性的说一下逻辑，其实核心就是构建 proxyFactory，最后通过它来构建代理类，准备的工作包括设置代理类型，是采用 jdk 原生代理呢还是采用 cglib 进行代理。将增强填充到这里构建的 proxyFactory 中，包括之前获取到的增强（本例是四个）和 spring 容器中存在的共用增强。将当前实例的必要字段填充到 proxyFactory 代理工厂中。\nprotected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName,        @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123;\t// TargetSource 封装了我们的目标实例    if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123;        AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);    &#125;    ProxyFactory proxyFactory = new ProxyFactory();    proxyFactory.copyFrom(this);\t// 当前类的属性复制到 ProxyFactory 中    if (!proxyFactory.isProxyTargetClass()) &#123;\t// 这里就是判断代理目标类还是接口分别对应 cglib 和 jdk 代理方式        if (shouldProxyTargetClass(beanClass, beanName)) &#123;\t// 看是否属性值指定了 org.springframework.aop.framework.autoproxy.AutoProxyUtils.preserveTargetClass，这种情况采用目标类代理方式 cglib            proxyFactory.setProxyTargetClass(true);\t// 这里设置代理方式为 cglib        &#125;        else &#123;\t// 看目标 class 是否有可以代理的接口，有的话将接口 class 添加到 proxyFactory 中，否则设置代理方式为代理目标类            evaluateProxyInterfaces(beanClass, proxyFactory);        &#125;    &#125;    // 获取公有的 interceptors，然后和 specificInterceptors 一起构建为 advisors 返回    Advisor[] advisors = buildAdvisors(beanName, specificInterceptors);    proxyFactory.addAdvisors(advisors);    proxyFactory.setTargetSource(targetSource);\t// 这个参数持有了代理目标    customizeProxyFactory(proxyFactory);    proxyFactory.setFrozen(this.freezeProxy);    if (advisorsPreFiltered()) &#123;\t// advisors 预过滤        proxyFactory.setPreFiltered(true);    &#125;    // 验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中    return proxyFactory.getProxy(getProxyClassLoader());&#125;\n\n这样通过上边的代码，我们构建出了 proxyFactory 代理工厂，向其中填充了增强集合，同时设置了代理类型，还将当前实例的一些字段值拷贝到了 proxyFactory 代理工厂，最后就是根据该代理工厂来构建代理类。核心就是 ProxyFactory#getProxy(java.lang.ClassLoader) 方法，它就一行代码 return createAopProxy().getProxy(classLoader);，先看第一段其根本执行的是：\npublic AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123;    if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123;        Class&lt;?&gt; targetClass = config.getTargetClass();\t// 执行到这里，说明采用 cglib 代理方式        if (targetClass == null) &#123;            throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; +                    &quot;Either an interface or a target is required for proxy creation.&quot;);        &#125;\t// 目标类是接口或者是 Proxy 接口实现类，那么进行 jdk 代理        if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123;            return new JdkDynamicAopProxy(config);        &#125;        return new ObjenesisCglibAopProxy(config);    &#125;    else &#123;        return new JdkDynamicAopProxy(config);\t// 这里就是进行 jdk 代理方式    &#125;&#125;\n\n就是一个创建 AopProxy 的过程，创建出来的感觉就像是一个工厂类吧，因为我们最终还是调用了它的 getProxy 方法。我们的正在处理的目标 bean 为 TestBean，在经过上边代码的条件判断后会返回 ObjenesisCglibAopProxy 实例， 也就是说我们的代理类应该是采用的 cglib 代理方式，至于为什么那就看上边代码逻辑喽。本文只会对 cglib 的代理方式进行说明，jdk 的代理方式应该整体的逻辑差不多，自行分析即可。\nreturn createAopProxy().getProxy(classLoader);，先看第一段就是获取了 ObjenesisCglibAopProxy 实例，我们调用它的 getProxy 方法，它的根本实现就是调用的下边的代码。这里我们看到了用于创建代理类的 Enhancer 实例，所以后边的代码也就不用再深究了，只需要知道这里最终返回的就是一个正在被处理的 bean 的代理类就行了。\n@Override\t// 验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中public Object getProxy(@Nullable ClassLoader classLoader) &#123;    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Creating CGLIB proxy: &quot; + this.advised.getTargetSource());    &#125;    try &#123;\t// advised 就是代理工厂实例        Class&lt;?&gt; rootClass = this.advised.getTargetClass();        Assert.state(rootClass != null, &quot;Target class must be available for creating a CGLIB proxy&quot;);        Class&lt;?&gt; proxySuperClass = rootClass;        if (rootClass.getName().contains(ClassUtils.CGLIB_CLASS_SEPARATOR)) &#123;\t// 这里目标类本身就是 cglib 代理类            proxySuperClass = rootClass.getSuperclass();            Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces();            for (Class&lt;?&gt; additionalInterface : additionalInterfaces) &#123;                this.advised.addInterface(additionalInterface);\t// 获取真实类的接口信息存入代理工厂实例            &#125;        &#125;        // Validate the class, writing log messages as necessary.        validateClassIfNecessary(proxySuperClass, classLoader);\t// 验证被代理类的信息，包括方法的修饰符        // Configure CGLIB Enhancer...        Enhancer enhancer = createEnhancer();\t// cglib 代理增强器        if (classLoader != null) &#123;            enhancer.setClassLoader(classLoader);            if (classLoader instanceof SmartClassLoader &amp;&amp;                    ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) &#123;                enhancer.setUseCache(false);            &#125;        &#125;        enhancer.setSuperclass(proxySuperClass);        enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised));        enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);\t// 命名规则        enhancer.setStrategy(new ClassLoaderAwareUndeclaredThrowableStrategy(classLoader));        // 获取 Callback 数组，包括 mainCallbacks 和 fixedCallbacks 两个部分        Callback[] callbacks = getCallbacks(rootClass);        Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length];        for (int x = 0; x &lt; types.length; x++) &#123;            types[x] = callbacks[x].getClass();        &#125;        // fixedInterceptorMap only populated at this point, after getCallbacks call above        enhancer.setCallbackFilter(new ProxyCallbackFilter(                this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset));        enhancer.setCallbackTypes(types);        // Generate the proxy class and create a proxy instance.        return createProxyClassAndInstance(enhancer, callbacks);    &#125;\t// 根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中    catch (CodeGenerationException | IllegalArgumentException ex) &#123;        throw new AopConfigException(&quot;Could not generate CGLIB subclass of &quot; + this.advised.getTargetClass() +                &quot;: Common causes of this problem include using a final class or a non-visible class&quot;,                ex);    &#125;    catch (Throwable ex) &#123;        // TargetSource.getTarget() failed        throw new AopConfigException(&quot;Unexpected AOP exception&quot;, ex);    &#125;&#125;\n\n上边的代码就是通过 Enhancer 实例构建代理类的过程，唯一需要注意的就是 Callback[] callbacks = getCallbacks(rootClass); 这行代码，怎么实现的我没管，但是它的返回结果要注意，如下图，可以看到本例中它的长度为 7，且持有了代理工厂和目标类引用，目标类就是我们当前正在处理的 TestBean 实例。\n\n\ncallbacks 数组内容\n\n\n\n代理工厂中的内容就更加重要了，可以看到它是持有了我们之前分析得到的全部四个增强信息的。\n\n\n代理工厂中持有的增强信息\n\n\n\n执行到这里我们的代理类创建就完成了，直接回到 AbstractAutoProxyCreator#wrapIfNecessary 方法的 createProxy 这行代码处，接下来它就是缓存了创建的代理类，这样下次获取时就能从缓存中拿，不必重新构建，我们来看看最终得到的代理类内部都有啥信息吧，记下这些信息，后边的代理类方法调用要用上。\n\n\n构建的代理类内部字段信息\n\n\n\n\n再总结一下代理类的构建过程，在构建我们在 spring 配置文件中指定的 TestBean 时，实现了 BeanPostProcessor 接口的 AspectJAwareAdvisorAutoProxyCreator 实例会对当前构建的 TestBean 进行处理，其规则就是看它是否能够被代理，如果能，就获取匹配当前实例的全部增强，然后根据这些增强及相关信息构建代理类，包括 jdk 和 cglib 两种方式。我们这里使用到的是 cglib 方式，他根本是通过 Enhancer 来构建代理类，最终的代理类是持有了我们获取的全部增强的，在调用代理的的对应方法时，相应的增强会按照一定的顺序执行，这是我们下一部分要说的内容。\n代理类方法的执行经过上文的分析，我们可以知道在主函数中获取到的 TestBean 其实是通过 cglib 构建出来的代理类，这个类的内部如上图所示有 7 个 CALLBACK 字段，如果我们调用该代理类的用户方法，就像测试代码中调用的 test 方法，那么就会触发第一个字段对应的 interceptor 实例的 intercept 方法，因为我 debug 就是进入了该实例的 intercept 方法，所以代理类方法的执行流程就是从该方法开始的。\npublic Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123;    Object oldProxy = null;    boolean setProxyContext = false;    Object target = null;    TargetSource targetSource = this.advised.getTargetSource();    try &#123;        if (this.advised.exposeProxy) &#123;            // Make invocation available if necessary.            oldProxy = AopContext.setCurrentProxy(proxy);\t// 如果要暴露代理类，那么就将代理类保存到 AopContext            setProxyContext = true;        &#125;        // Get as late as possible to minimize the time we &quot;own&quot; the target, in case it comes from a pool...        target = targetSource.getTarget();        Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null);        List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);        Object retVal;\t// 尝试从缓存中获取 interceptorList，没有的话就从当前实例中获取（获取 Advised 的全部 advisors，看 advisor 是否适配当前方法，适配的话从 advisor 中获取到 Advice，然后将其添加到 interceptorList 集合返回）        // Check whether we only have one InvokerInterceptor: that is,        // no real advice, but just reflective invocation of the target.        if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123;            // We can skip creating a MethodInvocation: just invoke the target directly.            // Note that the final invoker must be an InvokerInterceptor, so we know            // it does nothing but a reflective operation on the target, and no hot            // swapping or fancy proxying.            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);            retVal = methodProxy.invoke(target, argsToUse);\t// 这里是没有拦截器的方法调用方式        &#125;        else &#123;            // We need to create a method invocation...\t// 将代理相关的参数构建为 CglibMethodInvocation，进行处理，也就是说通过 CglibMethodInvocation 来触发 advice 的调用            retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();        &#125;        retVal = processReturnType(proxy, target, method, retVal);        return retVal;    &#125;    finally &#123;        if (target != null &amp;&amp; !targetSource.isStatic()) &#123;            targetSource.releaseTarget(target);        &#125;        if (setProxyContext) &#123;            // Restore old proxy.            AopContext.setCurrentProxy(oldProxy);        &#125;    &#125;&#125;\n\n入口方法如上，这里需要注意的就两点，首先会有一个 if (this.advised.exposeProxy) 的判断，就拿我们的第二个测试用例来说，我们配置了 expose-proxy=&quot;true&quot; 属性，那么这个判断条件就会为真，那么程序就会将 proxy 代理类保存到 AopContext 中，这也就是我们能够在测试代码中从 AopContext 拿到代理类的原因。其次是 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); 这一行代码，它会尝试从缓存中获取 interceptorList，没有的话就从代理工厂即 advised 中获取，过程比较繁琐，不用去细究，只给出获取的结果如下图就行，一共是四个，正好和上文中分析出来的四个增强相对应。\n\n\nadvice 链图\n\n\n\n接下来就是构建 CglibMethodInvocation 实例，它持有了很多关键的信息，从构造函数的参数就可以知道有代理类、目标 bean、目标方法、目标类型、上边得到的四个 advice、以及代理方法。构建的这个 CglibMethodInvocation 它有一个重要的功能就是控制 advice 的调用，我们直接看接下来的 proceed 方法就知道了。\npublic Object proceed() throws Throwable &#123;    //\tWe start with an index of -1 and increment early.    if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123;        return invokeJoinpoint();\t// 这里就是触发连接点方法    &#125;    Object interceptorOrInterceptionAdvice =\t// 逐个获取 interceptorOrInterceptionAdvice            this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);    if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123;        // Evaluate dynamic method matcher here: static part will already have        // been evaluated and found to match.        InterceptorAndDynamicMethodMatcher dm =                (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;        Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());        if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123;            return dm.interceptor.invoke(this);        &#125;        else &#123;            // Dynamic matching failed.            // Skip this interceptor and invoke the next in the chain.            return proceed();        &#125;    &#125;    else &#123;        // It&#x27;s an interceptor, so we just invoke it: The pointcut will have        // been evaluated statically before this object was constructed.\t// 对逐个获取的 interceptorOrInterceptionAdvice 进行 invoke 调用        return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);\t// 参数为通过代理各项参数构建的 CglibMethodInvocation    &#125;&#125;\n\n这个方法中的 interceptorsAndDynamicMethodMatchers 就是构造函数中传进去的四个 advice，这个方法通过 currentInterceptorIndex 来决定进行哪个 advice 的调用。默认是从第一个 advice 开始的，也就是直接调用它的 invoke 方法，从上文知道，第一个 advice 是 ExposeInvocationInterceptor 实例，它的核心就只是将 CglibMethodInvocation 实例保存到线程本地变量中，执行完这步就是继续调用 CglibMethodInvocation 的 proceed 方法，下边就是 ExposeInvocationInterceptor#invoke 方法的实现。\n@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123;    MethodInvocation oldInvocation = invocation.get();    invocation.set(mi);    try &#123;        return mi.proceed();\t// 继续下一个 advice 的调用    &#125;    finally &#123;        invocation.set(oldInvocation);    &#125;&#125;\n\n调用 CglibMethodInvocation 的 proceed 方法后，就会继续下一个 advice 的方法的调用，这时 currentInterceptorIndex 已经变为 1 了，根据上图，我们可以知道现在拿到的就是 AspectJAfterAdvice 实例，看他的 invoke 方法实现如下，其实现在已经可以猜想出来 AspectJAfterAdvice 代表的增强是在最后执行的，因为它是在 finally 中执行的调用逻辑，而调用 finally 代码块之前只是交由 CglibMethodInvocation 的 proceed 方法，继续下一个 advice 的调用。\n@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123;    try &#123;        return mi.proceed();    &#125;    finally &#123;        invokeAdviceMethod(getJoinPointMatch(), null, null);    &#125;&#125;\n\n这时 currentInterceptorIndex 变为 2，根据上图的信息知道现在将会进行 AspectJAroundAdvice 的 invoke 调用，它的实现如下，关键就是最后一行代码，它的实现我也贴在了下边，根本还是调用了 invokeAdviceMethodWithGivenArgs 方法，在该方法中，argBinding 方法对参数进行了一系列处理，这也不是关注的重点，因为我们现在只是想知道方法具体是怎样调用的，那就直接看invokeAdviceMethodWithGivenArgs 方法实现。\n@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123;    if (!(mi instanceof ProxyMethodInvocation)) &#123;        throw new IllegalStateException(&quot;MethodInvocation is not a Spring ProxyMethodInvocation: &quot; + mi);    &#125;    ProxyMethodInvocation pmi = (ProxyMethodInvocation) mi;    ProceedingJoinPoint pjp = lazyGetProceedingJoinPoint(pmi);    JoinPointMatch jpm = getJoinPointMatch(pmi);    return invokeAdviceMethod(pjp, jpm, null, null);&#125;// As above, but in this case we are given the join point.protected Object invokeAdviceMethod(JoinPoint jp, @Nullable JoinPointMatch jpMatch,        @Nullable Object returnValue, @Nullable Throwable t) throws Throwable &#123;    return invokeAdviceMethodWithGivenArgs(argBinding(jp, jpMatch, returnValue, t));&#125;\n\n下边就是 invokeAdviceMethodWithGivenArgs 方法的实现，注意根据调用链的关系，我们知道现在是在调用 AspectJAroundAdvice 实例的方法。在该方法中 ，我们根本是调用了 aspectJAdviceMethod 的 invoke 方法，此 aspectJAdviceMethod 是 jdk 原生 Method 类的实例，我们调用它的 invoke 方法，就会触发它所对应实例方法的调用，那么它代表的什么实例方法呢？通过下图的 debug 结果便很清楚了，其实就是我们切面类的 @Around 增强对应的那个方法。\nprotected Object invokeAdviceMethodWithGivenArgs(Object[] args) throws Throwable &#123;    Object[] actualArgs = args;    if (this.aspectJAdviceMethod.getParameterCount() == 0) &#123;        actualArgs = null;    &#125;    try &#123;        ReflectionUtils.makeAccessible(this.aspectJAdviceMethod);        // TODO AopUtils.invokeJoinpointUsingReflection        return this.aspectJAdviceMethod.invoke(this.aspectInstanceFactory.getAspectInstance(), actualArgs);\t// 这里就是触发真正的增强方法的调用    &#125;    catch (IllegalArgumentException ex) &#123;        throw new AopInvocationException(&quot;Mismatch on arguments to advice method [&quot; +                this.aspectJAdviceMethod + &quot;]; pointcut expression [&quot; +                this.pointcut.getPointcutExpression() + &quot;]&quot;, ex);    &#125;    catch (InvocationTargetException ex) &#123;        throw ex.getTargetException();    &#125;&#125;\n\n\n\n另外要注意这里的调用传入了参数 actualArgs，他就是上边 argBinding 方法拼凑出来的结果，里边的内容主要的就是一个 CglibMethodInvocation 实例，它持有了我们代理相关的大部分信息，如下图所示。\n\n\nCglibMethodInvocation 实例信息\n\n\n\n知道这些后，我们就直接转到切面类的 AspectJBean#aroundTest 方法中，不用多说控制台就会首先打印我们开篇测试代码的第二条语句了。接着调用参数的 proceed 方法如下，这里的 methodInvocation 刚好就是我上边说的 CglibMethodInvocation 实例，它持有了我们代理相关的大部分信息，同时 advice 的顺序调用也是由他控制的。\n@Overridepublic Object proceed() throws Throwable &#123;    return this.methodInvocation.invocableClone().proceed();&#125;\n\n通过前边的分析，我们知道现在的 currentInterceptorIndex 将会变为 3，这样我们获取到的就是最后一个 advice 了，也就是 MethodBeforeAdviceInterceptor 实例，这一点通过上边的 advice 链图就能知道了，它就持有了一个 AspectJMethodBeforeAdvice 实例，在 MethodBeforeAdviceInterceptor 的 invoke 方法中就是调用了 AspectJMethodBeforeAdvice 的 before 方法如下，而这个 before 方法最终就是调用的 AspectJMethodBeforeAdvice 实例持有的一个 jdk 原生 Method 实例的 invoke 方法，该实例对应的就是切面类中 @Before 注解对应的那个实例方法，所以对其进行调用，就会触发切面类中 AspectJBean#beforeTest 方法的调用，这样我们控制台就会打印 “beforeTest” 字符串了。\n\norg.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor#invoke\n\n@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123;    this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis());    return mi.proceed();&#125;\n\n上边的 before 方法执行完成后就会继续调用 mi.proceed(); 方法，这时 currentInterceptorIndex 值满足 ReflectiveMethodInvocation#proceed 方法的第一个 if 条件，就会执行 ReflectiveMethodInvocation#invokeJoinpoint 方法，它会触发目标方法的执行，这个的执行过程比较特殊，我没太看懂，但是 debug 执行的结果就是会跳转到 TestBean#test 方法中去，这也就是我们的目标方法，执行完后，控制台打印出我们预期的几行字符。\n好了再回到上一个调用点即 AspectJBean#aroundTest 方法的 o = p.proceed(); 处，继续往下走很清楚控制台将会打印 “aroundAfter” 字符串了，这一点很清楚，那么继续回退，也就是退到 AspectJAfterAdvice#invoke 方法处，这里还有一个 finally 方法没有执行呢，该方法就和 before 方法的执行一样，根本就是调用 jdk 原生 Method 实例的  invoke 方法，而它对应的就是切面类的 AspectJBean#afterTest 方法，这样控制台就会打印 “afterTest” 字符串。\n执行到这里，整个的代理方法调用过程算是完成了，总结一下，代理类有七个 CALLBACK 字段，当我们进行目标方法的调用时，代理类实际是调用的第一个 CALLBACK 字段的方法，它对应的是 DynamicAdvisedInterceptor#intercept 方法，我们通过在 DynamicAdvisedInterceptor#intercept 方法中构建 CglibMethodInvocation 实例来控制 advice 链的调用，这样构建代理类时填充进去的增强就会按照一定的顺序在目标方法的前后先后执行。这就是 aop 的实现原理，当然这里是以 cglib 为例进行说明，jdk 代理的方式还请自行分析。\n","categories":["源码分析"],"tags":["Spring","AOP"]},{"title":"HashMap实现原理分析","url":"/2019/08/01/2019-08-01-HashMap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","content":"前言本文是关于 HashMap 实现原理的分析文章，网上关于 HashMap 实现原理分析的文章已经足够多了，所以我这里写这篇文章仅仅是对自己看过的那些文章进行汇总，方便自己以后进行查阅。\n本文大部分内容转载自思否作者 ChiuCheng 深入理解HashMap 系列文章，感谢大佬，另外他写的其他几篇文章也十分值得阅读。\nHashMap 解决了什么问题任何数据结构的产生总对应着要解决一个实际的问题，HashMap的产生要解决问题就是：如何有效的 存&#x2F;取 一组 key-vaule 键值对。key-value 键值对是最常使用的数据形式，如何有效地存取他们是众多语言都需要关注的问题。注意这里有四个关键字如下，下面我们逐个来思考。\n\nkey-value键值对\n\n一组\n\n存\n\n取\n\n\n如何表示 key-value 键值对在java这种面向对象的语言中，表示一个数据结构自然要用到类，由于对于键值对的数据类型事先并不清楚，显而易见这里应该要用泛型，则表示key-value键值对最简单的形式可以是：\nclass Node&lt;K，V&gt; &#123;    K key;    V value;&#125;\n\n这里我们自定义一个 Node 类，它只有两个属性，一个 key 属性表示键，一个 value 属性表示值，则这个类就代表了一个 key-value 键值对。\n当然，我们还需要定义一些方法来操纵这两个属性，例如 get 和 set 方法等，不过根据设计原则，我们应该面向接口编程，所以应该定义一个接口来描述需要执行的操作，这个接口就是 Entry&lt;K，V&gt;，它只不过是对于 Node&lt;K，V&gt; 这个类的抽象，在 java 中，这个接口定义在 Map 这个接口中，所以上面的类可以改为：\nclass Node&lt;K，V&gt; implements Map。Entry&lt;K，V&gt;&#123;    K key;    V value;&#125;\n\n这里我们总结一下，我们定义了一个Node类来表示一个键值对，为了面向接口编程，我们抽象出一个 Entry 接口，并使 Node 类实现了这个接口。至于这个接口需要定义哪些方法，我们暂不细表。这样，我们完成了对于 key-value 键值对的表示。\n如何存储 key-value 键值对在常见的业务逻辑中，我们常常需要处理一组键值对的集合，将一组键值对存储在一处，并根据 key 值去查找对应的 value 。那么我们要如何存储这些键值对的集合呢?其实换个问法可能更容易回答，应该怎样存储一组对象?(毕竟键值对已经被我们表示为 Node 对象了)，在 java 中，存储一个对象的集合无外乎两种方式：数组或者链表，关于数组和链表的优缺点大家已经耳熟能详了：\n\n数组大小有限，查找性能好，插入和删除性能差\n\n链表大小不限，查找性能差，插入和删除性能好\n\n\n这里应该选哪种形式呢？那得看实际的应用了，在使用键值对时，查找和插入，删除等操作都会用到，但是在实际的应用场景中，对于键值对的查找操作居多，所以我们当然选择数组形式，在 HashMap 中该数组被表示为：\n\nNode&lt;K,V&gt;[] table;\n\n总结：我们选择数组形式来存储 key-value 对象。为了便于下文描述，我们将数组的下标称为索引(index)，将数组中的一个存储位置称为数组的一个存储桶(bucket)。\n如何有效地根据key值查找value前面已经讲到，我们选择数组形式来存储 key-value 对象，以利用其优良的查找性能，数组之所以查找迅速，是因为可以根据索引(数组下标)直接定位到对应的存储桶(数组所存储对象的位置)。但是实际应用中，我们都是通过 key 值来查找 value 值，怎么办呢？\n一种方式就是遍历数组中的每一个对象，查看它的 key 是不是我们要找的key，但是很明显，这种方式效率低下(而且这不就是链表的顺序查找方式吗？) 完全违背了我们选择数组来存储键值对的初衷。\n为了利用索引来查找，我们需要建立一个 key -&gt; index 的映射关系，这样每次我们要查找一个 key 时，首先根据映射关系，计算出对应的数组下标，然后根据数组下标，直接找到对应的 key-value 对象，这样基本能以 o(1) 的时间复杂度得到结果。\n这里，将 key 映射成 index 的方法称为hash算法，我们希望它能将 key 均匀的分布到数组中。\n这里插一句，使用 Hash 算法同样补足了数组插入和删除性能差的短板，我们知道，数组之所以插入删除性能差是因为它是顺序存储的，在一个位置插入节点或者删除节点需要一个个移动它的后续节点来腾出位或者覆盖位置。使用hash算法后，数组不再按顺序存储，插入删除操作只需要关注一个存储桶即可，而不需要额外的操作。\n如何解决hash冲突这个问题其实是由上一个问题引出的，虽然我们要求 hash 算法能将 key 均匀的分布到数组中，但是它只能尽量做到，并不是绝对的，更何况我们的数组大小是有限的，保不齐我们的 hash 算法将就两个不同的 key 映射成了同一个 index 值，这就产生了 hash 冲突，也就是两个 Node 要存储在数组的同一个位置该怎么办?\n解决hash冲突的方法有很多，在 HashMap 中我们选择链地址法，即在产生冲突的存储桶中改为单链表存储。此外还有一些其它的用于解决 hash 冲突的的办法如下，详细的请参考文章 解决哈希（HASH）冲突的主要方法。\n\n开放地址法：线性探查法、线性补偿探测法 、随机探测 \n\n拉链法：HashMap 即采用该方式\n\n\n其实，最理想的效果是，Entry 数组中每个位置都只有一个元素，这样查询的时候效率最高，不需要遍历单链表，也不需要通过equals 去比较 Key，而且空间利用率最大。链地址法使我们的数组转变成了链表的数组，其结构如下：\n\n\nHashMap 的数组加链表结构\n\n\n\n至此，我们对key-value键值对的表示变为:\nclass Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;    final int hash;    final K key;    V value;    Node&lt;K,V&gt; next;        Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;        this.hash = hash;        this.key = key;        this.value = value;        this.next = next;    &#125;    ...&#125;\n\n链表长度过长怎么办我们知道，链表查找只能通过顺序查找来实现，因此，时间复杂度为 o(n)，如果很不巧，我们的 key 值被 Hash 算法映射到一个存储桶上，将会导致存储桶上的链表长度越来越长，此时，数组查找退化成链表查找，则时间复杂度由原来的 o(1) 退化成 o(n)。\n为了解决这一问题，在 java8 中，当链表长度超过 8 之后，将会自动将链表转换成红黑树，以实现 o(log n) 的时间复杂度，从而提升查找性能。\n\n\nHashMap 的数组加链表或者红黑树结构\n\n\n\n什么时候扩容前面已经说到，数组的大小是有限的，在新建的时候就要指定，如果加入的节点已经到了数组容量的上限，已经没有位置能够存储 key-value 键值对了，此时就需要扩容。\n但是很明显，我们不会等到火烧眉毛了才想起来要扩容，在实际的应用中，数组空间已使用 3&#x2F;4 之后，我们就会括容。为什么是0.75呢，官方文档的解释是：\n\nthe default load factor (.75) offers a good tradeoff between time and space costs.\n\n再说回扩容，有的同学就要问了，咱上面不是将数组的每一个元素转变成链表了吗? 就算此时节点数超过了数组大小，新加的节点会存在数组某一个位置的链表里啊，链表的大小不限，可以存储任意数量的节点啊！\n没错，理论上来说这样确实是可行的，但这又违背了我们一开始使用数组来存储一组键值对的初衷，还记得我们选择数组的原因是什么吗？为了利用索引快速的查找！如果我们试图指望利用链表来扩容的话，当一个存储桶的中的链表越来越大，在这个链表上的查找性能就会很差(退化成顺序查找了)，为此，在数组容量不足时，为了继续维持利用数组索引查找的优良性能，我们必须对数组进行扩容。\n每次扩容扩多大我们知道，数组的扩容是一个很耗费 CPU 资源的动作，需要将原数组的内容复制到新数组中去，因此频繁的扩容必然会导致性能降低，所以不可能数组满了之后，每多加一个 node，我们就扩容一次。\n但是，一次扩容太大，导致大量的存储空间用不完，势必又造成很大的浪费，因此，必须根据实际情况设定一个合理的扩容大小。在 HashMap 的实现中，每次扩容我们都会将新数组的大小设为原数组大小的两倍。\nHash 算法原理为了利用数组索引进行快速查找，我们需要先将 key 值映射成数组下标。因为数组的下标是有限的集合，所以我们可以先通过 hash 算法将 key 映射成整数，再将整数映射成有限的数组下标，即 Object -&gt; int -&gt; index。\n对于 Object -&gt; int 部分，使用的就是 hash function，而对于 int -&gt; index 部分，我们可以简单的使用对数组大小取模来实现。在 java 中，hash 函数是一个 native 方法，这个方法定义在 Object 类中，所以所有的对象都会继承。因为这是一个本地方法，所以我们无法看到它的具体实现，但是从函数签名上可以看出，该方法将任意对象映射成一个整型值。调用该方法，我们就完成了 Object -&gt; int的映射。\n所以将 key 映射成 index 的方式可以是：\nkey.hashCode() % table.length\n\n那么 HashMap 是这样做的吗？事实上，HashMap 定义了自己的散列方法：\nstatic final int hash(Object key) &#123;    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;\n\n我们知道 int 类型是 32 位的，h ^ h &gt;&gt;&gt; 16 其实就是将 hashCode 的高 16 位和低 16 位进行异或，这充分利用了高半位和低半位的信息，对低位进行了扰动，目的是为了使该 hashCode 映射成数组下标时可以更均匀。另外从这个函数中，我们还可以得到一个意外收获：HashMap 中 key 值可以为 null，且 null 值一定存储在数组的第一个位置。\n前面我们提到，将 hash 值转换成数组下标我们可以采用取模运算，但是取模运算是十分耗时的。另一方面，我们知道，当一个数是 2^n 时，任意整数对2^n取模等效于:\nh % 2^n = h &amp; (2^n -1)\n\n这样我们就将取模操作转换成了位操作，而位操作的速度远远快于取模操作。因此在 HashMap 中，table 的大小都是 2 的 n 次方大小，即使你在构造函数中指定了 table 的大小，HashMap 也会将该值扩大为距离它最近的 2 的整数次幂的值. 这在我们下面分析构造函数的时候就能看到了。\nHashMap 构造函数HashMap 共有四个构造函数如下：\npublic class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123;    // 默认初始大小 16    static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16    // 默认负载因子 0.75    static final float DEFAULT_LOAD_FACTOR = 0.75f;         final float loadFactor;        /**     * The next size value at which to resize (capacity * load factor).     *     * @serial     */    // (The javadoc description is true upon serialization.    // Additionally, if the table array has not been allocated, this    // field holds the initial array capacity, or zero signifying    // DEFAULT_INITIAL_CAPACITY.)    int threshold;        transient Node&lt;K,V&gt;[] table;         // 没有指定时, 使用默认值    // 即默认初始大小16, 默认负载因子 0.75    public HashMap() &#123;        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted    &#125;        // 指定初始大小, 但使用默认负载因子    // 注意这里其实是调用了另一个构造函数    public HashMap(int initialCapacity) &#123;        this(initialCapacity, DEFAULT_LOAD_FACTOR);    &#125;        // 指定初始大小和负载因子    public HashMap(int initialCapacity, float loadFactor) &#123;        if (initialCapacity &lt; 0)            throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +                                               initialCapacity);        if (initialCapacity &gt; MAXIMUM_CAPACITY)            initialCapacity = MAXIMUM_CAPACITY;        if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))            throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +                                               loadFactor);        this.loadFactor = loadFactor;        this.threshold = tableSizeFor(initialCapacity);    &#125;        // 利用已经存在的map创建HashMap    public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;        this.loadFactor = DEFAULT_LOAD_FACTOR;        putMapEntries(m, false);    &#125;&#125;\n\n从代码我们知道，即使我们在构造函数中指定了 initialCapacity，这个值也只被用来计算 threshold，代码如下：\nthis.threshold = tableSizeFor(initialCapacity);\n\n而 threshold 这个值在初始化 table 时，就代表了数组的初始大小，我们看看 tableSizeFor 函数的实现，可以知道它就是得到了大于等于参数的最小的 2 的幂级数。\n/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123;    int n = cap - 1;    n |= n &gt;&gt;&gt; 1;    n |= n &gt;&gt;&gt; 2;    n |= n &gt;&gt;&gt; 4;    n |= n &gt;&gt;&gt; 8;    n |= n &gt;&gt;&gt; 16;    return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;\n\n最后我们来看最后一个构造函数，它调用了 putMapEntries 方法：\nfinal void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123;    int s = m.size();    if (s &gt; 0) &#123;        if (table == null) &#123; // pre-size            float ft = ((float)s / loadFactor) + 1.0F;            int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ?                     (int)ft : MAXIMUM_CAPACITY);            if (t &gt; threshold)                threshold = tableSizeFor(t);        &#125;        else if (s &gt; threshold)            resize();        for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123;            K key = e.getKey();            V value = e.getValue();            putVal(hash(key), key, value, false, evict);        &#125;    &#125;&#125;\n\n我们知道，当使用构造函数HashMap(Map&lt;? extends K，? extends V&gt; m) 时，我们并没有为 table 赋值，所以，table 值一定为null，我们先根据传入 Map 的大小计算 threshold 值，然后判断需不需要扩容，最后调用 putVal 方法将传入的 Map 插入 table 中。\nHashMap 的 resize 扩容resize 用于以下两种情况之一：\n\n初始化table\n\n在table大小超过threshold之后进行扩容\n\n\n下面我们直接来对照源码分析:\nfinal Node&lt;K,V&gt;[] resize() &#123;    Node&lt;K,V&gt;[] oldTab = table;    int oldCap = (oldTab == null) ? 0 : oldTab.length;    int oldThr = threshold;    int newCap, newThr = 0;        // 原table中已经有值    if (oldCap &gt; 0) &#123;            // 已经超过最大限制, 不再扩容, 直接返回        if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;            threshold = Integer.MAX_VALUE;            return oldTab;        &#125;                // 注意, 这里扩容是变成原来的两倍        // 但是有一个条件: `oldCap &gt;= DEFAULT_INITIAL_CAPACITY`        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)    // DEFAULT_INITIAL_CAPACITY 为 16            newThr = oldThr &lt;&lt; 1; // double threshold    &#125;        // 在构造函数一节中我们知道    // 如果没有指定initialCapacity, 则不会给threshold赋值, 该值被初始化为0    // 如果指定了initialCapacity, 该值被初始化成大于initialCapacity的最小的2的次幂        // 这里是指, 如果构造时指定了initialCapacity, 则用threshold作为table的实际大小    else if (oldThr &gt; 0) // initial capacity was placed in threshold        newCap = oldThr;        // 如果构造时没有指定initialCapacity, 则用默认值    else &#123;               // zero initial threshold signifies using defaults        newCap = DEFAULT_INITIAL_CAPACITY;        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    &#125;        // 计算指定了initialCapacity情况下的新的 threshold    if (newThr == 0) &#123;        float ft = (float)newCap * loadFactor;        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?                  (int)ft : Integer.MAX_VALUE);    &#125;    threshold = newThr;            //从以上操作我们知道, 初始化HashMap时,     //如果构造函数没有指定initialCapacity, 则table大小为16    //如果构造函数指定了initialCapacity, 则table大小为threshold, 即大于指定initialCapacity的最小的2的整数次幂            // 从下面开始, 初始化table或者扩容, 实际上都是通过新建一个table来完成的    @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;)        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];    table = newTab;        // 下面这段就是把原来table里面的值全部搬到新的table里面    if (oldTab != null) &#123;        for (int j = 0; j &lt; oldCap; ++j) &#123;            Node&lt;K,V&gt; e;            if ((e = oldTab[j]) != null) &#123;                // 这里注意, table中存放的只是Node的引用, 这里将oldTab[j]=null只是清除旧表的引用, 但是真正的node节点还在, 只是现在由e指向它                oldTab[j] = null;                                // 如果该存储桶里面只有一个bin, 就直接将它放到新表的目标位置                if (e.next == null)                    newTab[e.hash &amp; (newCap - 1)] = e;                                // 如果该存储桶里面存的是红黑树, 则拆分树                else if (e instanceof TreeNode)                    //红黑树的部分以后有机会再讲吧                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);                                // 下面这段代码很精妙, 我们单独分一段详细来讲                else &#123; // preserve order                    Node&lt;K,V&gt; loHead = null, loTail = null;                    Node&lt;K,V&gt; hiHead = null, hiTail = null;                    Node&lt;K,V&gt; next;                    do &#123;                        next = e.next;                        if ((e.hash &amp; oldCap) == 0) &#123;                            if (loTail == null)                                loHead = e;                            else                                loTail.next = e;                            loTail = e;                        &#125;                        else &#123;                            if (hiTail == null)                                hiHead = e;                            else                                hiTail.next = e;                            hiTail = e;                        &#125;                    &#125; while ((e = next) != null);                    if (loTail != null) &#123;                        loTail.next = null;                        newTab[j] = loHead;                    &#125;                    if (hiTail != null) &#123;                        hiTail.next = null;                        newTab[j + oldCap] = hiHead;                    &#125;                &#125;            &#125;        &#125;    &#125;    return newTab;&#125;\n\n下面我们单独来看看这段设计的很精妙的代码，首先是定义了四个 Node 的引用，从变量命名上，我们初步猜测，这里定义了两个链表，我们把它称为 lo 链表 和 hi 链表， loHead 和 loTail 分别指向 lo 链表的头节点和尾节点， hiHead 和 hiTail 以此类推。\nNode&lt;K,V&gt; loHead = null, loTail = null;Node&lt;K,V&gt; hiHead = null, hiTail = null;\n\n接着是一个 do while 循环代码块如下，其逻辑很简单就是按顺序遍历该存储桶位置上的链表中的节点。如果 (e.hash &amp; oldCap) &#x3D;&#x3D; 0，我们就将该节点放入 lo 链表，否则放入 hi 链表。如果 lo 链表非空，我们就把整个 lo 链表放到新 table 的 j 位置上，如果 hi 链表非空, 我们就把整个 hi 链表放到新 table 的 j+oldCap 位置上。\ndo &#123;    next = e.next;    if ((e.hash &amp; oldCap) == 0) &#123;        if (loTail == null)            loHead = e;        else            loTail.next = e;        loTail = e;    &#125;    else &#123;        if (hiTail == null)            hiHead = e;        else            hiTail.next = e;        hiTail = e;    &#125;&#125; while ((e = next) != null);\n\n综上我们知道，这段代码的意义就是将原来的链表拆分成两个链表，并将这两个链表分别放到新的 table 的 j 位置和 j+oldCap 上, j 位置就是原链表在原 table 中的位置，拆分的标准就是下边的代码，具体的过程可以通过下边的示意图进行说明。\n(e.hash &amp; oldCap) == 0\n\n\n\nHashMap resize 过程链表拆分示意图\n\n\n\n关于两个链表的存放位置，可能会有些疑惑，为什么一定是 j 和 j+oldCap 这两个位置呢？\n我们假设 oldCap &#x3D; 16，即 2^4，16 - 1 &#x3D; 15，二进制表示为 0000 0000 0000 0000 0000 0000 0000 1111 可见除了低 4 位，其他位置都是 0（简洁起见，高位的 0 后面就不写了），则 (16-1) &amp; hash 自然就是取 hash 值的低 4 位，我们假设它为 abcd。\n以此类推，当我们将 oldCap 扩大两倍后，新的 index 的位置就变成了 (32-1) &amp; hash，其实就是取 hash 值的低 5 位. 那么对于同一个 Node，低 5 位的值无外乎下面两种情况：\n0abcd1abcd\n\n其中，0abcd 与原来的 index 值一致，而 1abcd &#x3D; 0abcd + 10000 &#x3D; 0abcd + oldCap，故虽然数组大小扩大了一倍，但是同一个 key 在新旧 table 中对应的 index 却存在一定联系：要么一致，要么相差一个 oldCap。\n而新旧index是否一致就体现在 hash 值的第 4 位(我们把最低为称作第 0 位)，怎么拿到这一位的值呢，只要通过下边这个计算表达式即可，即 hash &amp; oldCap。\nhash &amp; 0000 0000 0000 0000 0000 0000 0001 0000\n\n因此可以有如下结论：\n\n如果 (e.hash &amp; oldCap) &#x3D;&#x3D; 0 则该节点在新表的下标位置与旧表一致都为 j\n\n\n如果 (e.hash &amp; oldCap) &#x3D;&#x3D; 1 则该节点在新表的下标位置 j + oldCap\n\nHashMap 的 put 方法put 方法在接口中的定义为，第一个参数为 key 所对应的 hash 值，key 和 value 代表我们要进行存储的键值对。第四个参数 onlyIfAbsent 用于决定待存储的 key 已经存在的情况下，要不要用新值覆盖原有的value，如果为true，则保留原有值，false 则覆盖原有值，从下边的调用看，该值为false，说明当key值已经存在时，会直接覆盖原有值。最后一个参数 evict 用来区分当前是否是构造模式，我们在讲解构造函数的时候曾经提到，HashMap 的第四个构造函数可以通过已经存在的 Map 初始化一个 HashMap，如果为 false，说明在构造模式下，这里我们是用在 put 函数而不是构造函数里面，所以为 true。\npublic V put(K key, V value) &#123;    return putVal(hash(key), key, value, false, true);    /*final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) */&#125;\n\nputVal 方法的具体实现如下，\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;        // 首先判断table是否是空的    // 我们知道, HashMap的三个构造函数中, 都不会初始Table, 因此第一次put值时, table一定是空的, 需要初始化    // table的初始化用到了resize函数, 这个我们上一篇文章已经讲过了    // 由此可见table的初始化是延迟到put操作中的    if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;            // 这里利用 `(n-1) &amp; hash` 方法计算 key 所对应的下标    // 如果key所对应的桶里面没有值, 我们就新建一个Node放入桶里面    if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);        // 到这里说明目标位置桶里已经有东西了    else &#123;        Node&lt;K,V&gt; e; K k;        // 这里先判断当前待存储的key值和已经存在的key值是否相等        // key值相等必须满足两个条件        //    1. hash值相同        //    2. 两者 `==` 或者 `equals` 等        if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p; // key已经存在的情况下, e保存原有的键值对                // 到这里说明要保存的桶已经被占用, 且被占用的位置存放的key与待存储的key值不一致                // 前面已经说过, 当链表长度超过8时, 会用红黑树存储, 这里就是判断存储桶中放的是链表还是红黑树        else if (p instanceof TreeNode)            // 红黑树的部分以后有机会再说吧            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);                //到这里说明是链表存储, 我们需要顺序遍历链表        else &#123;            for (int binCount = 0; ; ++binCount) &#123;                // 如果已经找到了链表的尾节点了,还没有找到目标key, 则说明目标key不存在，那我们就新建一个节点, 把它接在尾节点的后面                if ((e = p.next) == null) &#123;                    p.next = newNode(hash, key, value, null);                    // 如果链表的长度达到了8个, 就将链表转换成红黑数以提升查找性能                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st                        treeifyBin(tab, hash);                    break;                &#125;                // 如果在链表中找到了目标key则直接退出                // 退出时e保存的是目标key的键值对                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                p = e;            &#125;        &#125;                // 到这里说明要么待存储的key存在, e保存已经存在的值        // 要么待存储的key不存在, 则已经新建了Node将key值插入, e的值为Null                // 如果待存储的key值已经存在        if (e != null) &#123; // existing mapping for key            V oldValue = e.value;                        // 前面已经解释过, onlyIfAbsent的意思            // 这里是说旧值存在或者旧值为null的情况下, 用新值覆盖旧值            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e); //这个函数只在LinkedHashMap中用到, 这里是空函数            // 返回旧值            return oldValue;        &#125;    &#125;        // 到这里说明table中不存在待存储的key, 并且我们已经将新的key插入进数组了        ++modCount; // 这个暂时用不到        // 因为又插入了新值, 所以我们得把数组大小加1, 并判断是否需要重新扩容    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict); //这个函数只在LinkedHashMap中用到, 这里是空函数    return null;&#125;\n\nput 函数的总结就是：\n\n在 put 之前会检查 table 是否为空，这说明 table 真正的初始化并不是发生在构造函数中，而是发生在第一次 put 的时候。\n\n查找当前 key 是否存在的条件是 p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))。\n\n如果插入的key值不存在，则值会插入到链表的末尾。\n\n每次插入操作结束后，都会检查当前 table 节点数是否大于 threshold，若超过，则扩容。\n\n当链表长度超过TREEIFY_THRESHOLD（默认是8）个时，会将链表转换成红黑树以提升查找性能。\n\n\n","categories":["数据结构"],"tags":["Java","数据结构"]},{"title":"Spring事务机制实现原理","url":"/2019/07/22/2019-07-22-Spring%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","content":"前言在我的上一篇文章中已经比较详细的对 Spring 的 AOP 实现原理进行了说明，而 Spring 的事务实现原理呢又跟 Spring 的 AOP 实现有着较大的关系，所以这里选择成热打铁，对 Spring 的事务实现机制进行一下说明。上一篇文章在对 AOP 实现进行解释时，只分析了它的 cglib 代理实现，因为提供的例子中被代理类没有实现相应的接口，导致不能通过 jdk 原生方式进行代理，而本文将要解释的 Spring 事务实现中，例子是实现了用户服务接口的，所以代理方式是采用的 jdk 原生方式，正好能够对上文进行补充。同样的示例代码我已经提交到我的 github 上，欢迎自取。在阅读本文之前，十分的建议先看我的上一篇 Spring AOP 实现原理文章，因为分析 Spring 事务实现原理的方式和分析 Spring AOP 实现原理的方式十分相似，如果对上一篇文章理解得好，Spring 的事务实现完全可以按照同样的方式来进行分析。\n示例程序实例程序很简单，已经同步到上文 github 链接上了，在 spring-example 模块的 top.aprilyolies.example.tx 包之下，执行前还需要先在数据库中创建数据表，sql 文件在当前模块下的 db 文件夹下。\n\n主函数 top.aprilyolies.example.tx.TxApp\n\npublic class TxApp &#123;\tpublic static void main(String[] args) &#123;\t\tClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-tx.xml&quot;);\t\tUserService userService = (UserService) context.getBean(&quot;userService&quot;);\t\tUser user = new User();\t\tuser.setSex(&quot;man&quot;);\t\tuser.setName(&quot;eva&quot;);\t\tuser.setAge(23);\t\tuserService.save(user);\t&#125;&#125;\n\n\npojo 类省略 getter 和 setter 方法 top.aprilyolies.example.tx.User\n\npublic class User &#123;\tprivate int id;\tprivate String name;\tprivate int age;\tprivate String sex;&#125;\n\n\ntop.aprilyolies.example.tx.UserRowMapper\n\npublic class UserRowMapper implements RowMapper &#123;\t@Override\tpublic Object mapRow(ResultSet rs, int rowNum) throws SQLException &#123;\t\tUser user = new User();\t\tuser.setAge(rs.getInt(&quot;age&quot;));\t\tuser.setId(rs.getInt(&quot;id&quot;));\t\tuser.setName(rs.getString(&quot;name&quot;));\t\tuser.setSex(rs.getString(&quot;sex&quot;));\t\treturn user;\t&#125;&#125;\n\n\ntop.aprilyolies.example.tx.UserService\n\npublic interface UserService &#123;\tvoid save(User user);&#125;\n\n\ntop.aprilyolies.example.tx.UserServiceImpl\n\n@Transactionalpublic class UserServiceImpl implements UserService &#123;\tprivate JdbcTemplate template = new JdbcTemplate();\tpublic void setDataSource(DataSource dataSource) &#123;\t\tthis.template.setDataSource(dataSource);\t&#125;\t@Override\tpublic void save(User user) &#123;\t\ttemplate.update(&quot;insert into user(name,age,sex) values (?,?,?)&quot;, user.getName(), user.getAge(), user.getSex());\t\tthrow new RuntimeException(&quot;Test tx&quot;);\t&#125;&#125;\n\n\ntop.aprilyolies.example.tx.UserService\n\npublic interface UserService &#123;\tvoid save(User user);&#125;\n\n\nspring-tx.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;\t   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\t   xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;\t   xsi:schemaLocation=&quot;       http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd       http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd&quot;&gt;\t&lt;tx:annotation-driven/&gt;\t&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;\t\t&lt;!-- 关联数据源 --&gt;\t\t&lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;\t&lt;/bean&gt;\t&lt;!-- 基于Druid数据库链接池的数据源配置 --&gt;\t&lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;clone&quot;&gt;\t\t&lt;!-- 基本属性driverClassName、 url、user、password --&gt;\t\t&lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;\t\t&lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/common&quot;/&gt;\t\t&lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;\t\t&lt;property name=&quot;password&quot; value=&quot;kuaile1..&quot;/&gt;\t&lt;/bean&gt;\t&lt;bean id=&quot;userService&quot; class=&quot;top.aprilyolies.example.tx.UserServiceImpl&quot;&gt;\t\t&lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;\t&lt;/bean&gt;&lt;/beans&gt;\n\n执行主函数，会发现程序抛出运行时异常，查看数据库可以看到我们准备插入的数据没有出现。如果我们将 top.aprilyolies.example.tx.UserServiceImpl 类的 @Transactional 注解去掉，再执行主函数，这时可以看到程序同样是抛出了运行时异常，但是当前这条记录却被插入了数据库中。\n解释就是当我们使用 @Transactional 注解时，那么 spring 在执行对应的方法时会开启事务，这样如果在事务中 java 程序出现异常，spring 就会自动完成事务的回滚。当把 @Transactional 注解去掉后，我们就是执行的普通方法，这样默认的事务机制是自动提交，当执行完 template.update 方法时，记录已经进入数据库，此时再抛出异常，将不会对结果产生影响。当然这只是直观的感受，具体的实现还是要看源码，本文的主要内容也就是这个。\n标签解析在我们的 spring 配置文件中只有一个特殊标签 &lt;tx:annotation-driven&#x2F;&gt;，根据上文中的介绍，我们直接定位到 TxNamespaceHandler#init 方法如下，很明显这里应该关注 &lt;tx:annotation-driven&#x2F;&gt; 标签对应的 AnnotationDrivenBeanDefinitionParser。\n@Overridepublic void init() &#123;    registerBeanDefinitionParser(&quot;advice&quot;, new TxAdviceBeanDefinitionParser());    registerBeanDefinitionParser(&quot;annotation-driven&quot;, new AnnotationDrivenBeanDefinitionParser());    registerBeanDefinitionParser(&quot;jta-transaction-manager&quot;, new JtaTransactionManagerBeanDefinitionParser());&#125;\n\nAnnotationDrivenBeanDefinitionParser 类实现了 BeanDefinitionParser 接口，直接看接口的 parse 方法实现。第一行代码就是向 spring 容器注册了一个 TransactionalEventListenerFactory 相关的 bean，这个 bean 的作用暂时没有深究。接下来就是一个 if-else 分支，也就是说 spring 的事务实现有两种模式，如果在 &lt;tx:annotation-driven&#x2F;&gt; 标签中指定了 mode 属性为 “aspectj”，那么就会实现 aspectj 模式的事务机制，否则就是通过代理的方式实现事务，当然 spring 默认情况下就是采用的代理方式来实现事务处理，这也就是开篇说 Spring 事务机制跟 Spring AOP 实现原理有关的原因。aspectj 模式这里没做深入的了解，以后如果用上了就再看。\npublic BeanDefinition parse(Element element, ParserContext parserContext) &#123;    registerTransactionalEventListenerFactory(parserContext);\t// 根本就是向 spring 容器注册了一个 TransactionalEventListenerFactory 相关的 bean    String mode = element.getAttribute(&quot;mode&quot;);\t// 默认是通过 proxy 的方式    if (&quot;aspectj&quot;.equals(mode)) &#123;\t// 这里说明事务支持的实现有两种方式，aspectj 和 proxy 的方式        // mode=&quot;aspectj&quot;\t// 这种模式没接触过，暂不了解        registerTransactionAspect(element, parserContext);        if (ClassUtils.isPresent(&quot;javax.transaction.Transactional&quot;, getClass().getClassLoader())) &#123;            registerJtaTransactionAspect(element, parserContext);        &#125;    &#125;    else &#123;// 主要是向 spring 容器注册了四个 BeanDefinition，包括 AnnotationTransactionAttributeSource、TransactionInterceptor、BeanFactoryTransactionAttributeSourceAdvisor        // mode=&quot;proxy&quot; 以及 CompositeComponentDefinition，都完成了一些属性的设置        AopAutoProxyConfigurer.configureAutoProxyCreator(element, parserContext);    &#125;    return null;&#125;\n\n直接看 else 分支，它就是调用了 AopAutoProxyConfigurer.configureAutoProxyCreator(element, parserContext); 方法，里边的实现其实就是跟 Spring AOP 的实现一样的套路，代码如下，不过这里注册的 bean 稍多，有五个包括 InfrastructureAdvisorAutoProxyCreator(实现了 SmartInstantiationAwareBeanPostProcessor 接口，负责代理类的生成)、AnnotationTransactionAttributeSource（主要是用来存储一些事务相关的属性信息）、TransactionInterceptor（事务实现的核心拦截器，事务的回滚都是在其中完成）、BeanFactoryTransactionAttributeSourceAdvisor（增强器）以及 CompositeComponentDefinition（上述三种 bean 的组合）。请留意这些 bean，因为在后边的事务实现中，除了最后一个组合 bean，均有涉及到。还有就是要注意这句代码 advisorDef.getPropertyValues().add(&quot;adviceBeanName&quot;, interceptorName);，advisorDef 代表的就是 BeanFactoryTransactionAttributeSourceAdvisor 类对应的 BeanDefinition，而 interceptorName 就是 TransactionInterceptor 实例在 spring 容器中的唯一标识符，当执行完这条代码后，那么 advisor 就算是持有了 TransactionInterceptor 的唯一标识符了，也就能够间接的获取到 spring 容器中的 TransactionInterceptor 实例了。interceptorDef.getPropertyValues().add(&quot;transactionAttributeSource&quot;, new RuntimeBeanReference(sourceName)); 这句代码的作用同理。\npublic static void configureAutoProxyCreator(Element element, ParserContext parserContext) &#123;    // 核心就是注册了 InfrastructureAdvisorAutoProxyCreator 对应的 bean，并设置了它创建代理的方式    AopNamespaceUtils.registerAutoProxyCreatorIfNecessary(parserContext, element);    String txAdvisorBeanName = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME;\t// 和事务相关的增强器唯一标识符    if (!parserContext.getRegistry().containsBeanDefinition(txAdvisorBeanName)) &#123;        Object eleSource = parserContext.extractSource(element);        // Create the TransactionAttributeSource definition.        RootBeanDefinition sourceDef = new RootBeanDefinition(\t// 这一部分就是创建一个 RootBeanDefinition，持有了 eleSource，角色为 ROLE_INFRASTRUCTURE，并进行了注册                &quot;org.springframework.transaction.annotation.AnnotationTransactionAttributeSource&quot;);        sourceDef.setSource(eleSource);        sourceDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);        String sourceName = parserContext.getReaderContext().registerWithGeneratedName(sourceDef);        // Create the TransactionInterceptor definition.\t// TransactionInterceptor 实现了 MethodInterceptor 接口，说明它可以被当做方法拦截器使用        RootBeanDefinition interceptorDef = new RootBeanDefinition(TransactionInterceptor.class);\t// 这一部分就是创建了一个 TransactionInterceptor 对应的 RootBeanDefinition        interceptorDef.setSource(eleSource);\t// 持有了 eleSource，角色为 ROLE_INFRASTRUCTURE        interceptorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);        registerTransactionManager(element, interceptorDef);\t// 为当前 BeanDefinition 添加了一个 transactionManagerBeanName 属性        interceptorDef.getPropertyValues().add(&quot;transactionAttributeSource&quot;, new RuntimeBeanReference(sourceName));\t// 为当前 BeanDefinition 添加了一个 transactionAttributeSource 属性        String interceptorName = parserContext.getReaderContext().registerWithGeneratedName(interceptorDef);\t// 注册当前的 RootBeanDefinition        // Create the TransactionAttributeSourceAdvisor definition.\t// Advisor 后缀，猜测它能当做增强使用        RootBeanDefinition advisorDef = new RootBeanDefinition(BeanFactoryTransactionAttributeSourceAdvisor.class);\t// 构建 BeanFactoryTransactionAttributeSourceAdvisor 对应的 RootBeanDefinition        advisorDef.setSource(eleSource);        advisorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);        advisorDef.getPropertyValues().add(&quot;transactionAttributeSource&quot;, new RuntimeBeanReference(sourceName));\t// 指定了 transactionAttributeSource 和 adviceBeanName 属性        advisorDef.getPropertyValues().add(&quot;adviceBeanName&quot;, interceptorName);        if (element.hasAttribute(&quot;order&quot;)) &#123;            advisorDef.getPropertyValues().add(&quot;order&quot;, element.getAttribute(&quot;order&quot;));        &#125;        parserContext.getRegistry().registerBeanDefinition(txAdvisorBeanName, advisorDef);        CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), eleSource);        compositeDef.addNestedComponent(new BeanComponentDefinition(sourceDef, sourceName));        compositeDef.addNestedComponent(new BeanComponentDefinition(interceptorDef, interceptorName));        compositeDef.addNestedComponent(new BeanComponentDefinition(advisorDef, txAdvisorBeanName));        parserContext.registerComponent(compositeDef);    &#125;&#125;\n\n到这里 &lt;tx:annotation-driven&#x2F;&gt; 标签的解析过程就算完成了，总结下来就是注册了一个 TransactionalEventListenerFactory，然后根据标签属性来确定事务的实现模式是 aspectj 还是 proxy，如果是 proxy 方式，那么就是向 spring 容器中注册了上述的五个 bean。\n构建事务代理类上文已经提到了在 &lt;tx:annotation-driven&#x2F;&gt; 标签的解析过程中会向 spring 容器注册五个类型的 bean，我这里再罗列一下，因为事务代理类的构建和事务机制的实现都和前四个类型的 bean 息息相关，关于他们的作用我都进行了说明，其中第一个 bean 就是用来构建事务代理类的，它的实现模式跟 spring aop 基本一致。\n\nInfrastructureAdvisorAutoProxyCreator(实现了 SmartInstantiationAwareBeanPostProcessor 接口，负责代理类的生成)\n\nAnnotationTransactionAttributeSource（主要是用来存储一些事务相关的属性信息）\n\nTransactionInterceptor（事务实现的核心拦截器，事务的回滚都是在其中完成）\n\nBeanFactoryTransactionAttributeSourceAdvisor（增强器）\n\nCompositeComponentDefinition（上述三种 bean 的组合）\n\n\nInfrastructureAdvisorAutoProxyCreator 实现了 SmartInstantiationAwareBeanPostProcessor 接口，按照上一篇文章所说的，我们直接关注到事务代理类创建的方法如下：\n\norg.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#postProcessAfterInitialization\n\n@Override\t// 尝试从缓存中获取代理 bean，没有的话进行构建，核心就是构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123;    if (bean != null) &#123;        Object cacheKey = getCacheKey(bean.getClass(), beanName);        if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123;            return wrapIfNecessary(bean, beanName, cacheKey);\t// 核心就是构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中        &#125;    &#125;    return bean;&#125;\n\n这部分代码在上一篇文章中已经说过了，所以不再赘述，但是在 wrapIfNecessary 方法的实现中，和 spring aop 原理分析中的样例代码不一样，这里通过 getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); 获取到的 specificInterceptors 只有一个如下图所示，这个跟 spring aop 原理分析文章中得到的和 @Before、@After、@Around 三个注解代表的 Advisor 相对应。好了自己看看现在获取到的这个 Advisor 的类型，是不是很熟悉呢？？没错这个 advisor 就是上文中提出的那个五个 bean 当中的一个。\n\n\n本例中唯一的 Advisor\n\n\n\n// 判断是否需要代理，如果是，获取满足 beanClass 的 advisor，然后构建代理类：验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123;    if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123;        return bean;    &#125;    if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123;        return bean;\t// 无需代理，直接返回    &#125;    if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123;        this.advisedBeans.put(cacheKey, Boolean.FALSE);        return bean;\t// 基础类和应跳过的类直接返回    &#125;    // Create proxy if we have advice.\t// 获取满足 beanClass 的 advisor，进行过排序    Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);    if (specificInterceptors != DO_NOT_PROXY) &#123;        this.advisedBeans.put(cacheKey, Boolean.TRUE);\t// 所以这个集合存放的是对应的 bean 是否增强的信息        Object proxy = createProxy(\t// 验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中                bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));        this.proxyTypes.put(cacheKey, proxy.getClass());        return proxy;    &#125;    // 所以这个集合存放的是对应的 bean 是否增强的信息    this.advisedBeans.put(cacheKey, Boolean.FALSE);    return bean;&#125;\n\n拿到这个 advisor 后就是构建代理类，上篇文章中走的是 cglib 代理分支，而现在走的是 jdk 代理方式的分支，判断的逻辑是由下边代码的 evaluateProxyInterfaces(beanClass, proxyFactory); 这一行所决定的，该行代码会看目标 class 是否有可以代理的接口，有的话将接口 class 添加到 proxyFactory 中，否则设置代理方式为代理目标类即 cglib 的方式。因为我们的目标类是 UserServiceImpl，它实现了 UserService 接口，因此是满足 jdk 动态代理条件的。另外需要注意的是下边的方法通过参数传入的 specificInterceptors 被转换为了 Advisor，它又被传入了 proxyFactory 中，所以 proxyFactory 是持有了我们 Advisor 的。\nprotected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName,        @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123;\t// TargetSource 封装了我们的目标实例    if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123;        AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);    &#125;    ProxyFactory proxyFactory = new ProxyFactory();    proxyFactory.copyFrom(this);\t// 当前类的属性复制到 ProxyFactory 中    if (!proxyFactory.isProxyTargetClass()) &#123;\t// 这里就是判断代理目标类还是接口分别对应 cglib 和 jdk 代理方式        if (shouldProxyTargetClass(beanClass, beanName)) &#123;\t// 看是否属性值指定了 org.springframework.aop.framework.autoproxy.AutoProxyUtils.preserveTargetClass，这种情况采用目标类代理方式 cglib            proxyFactory.setProxyTargetClass(true);\t// 这里设置代理方式为 cglib        &#125;        else &#123;\t// 看目标 class 是否有可以代理的接口，有的话将接口 class 添加到 proxyFactory 中，否则设置代理方式为代理目标类            evaluateProxyInterfaces(beanClass, proxyFactory);        &#125;    &#125;    // 获取公有的 interceptors，然后和 specificInterceptors 一起构建为 advisors 返回    Advisor[] advisors = buildAdvisors(beanName, specificInterceptors);    proxyFactory.addAdvisors(advisors);    proxyFactory.setTargetSource(targetSource);\t// 这个参数持有了代理目标    customizeProxyFactory(proxyFactory);    proxyFactory.setFrozen(this.freezeProxy);    if (advisorsPreFiltered()) &#123;\t// advisors 预过滤        proxyFactory.setPreFiltered(true);    &#125;    // 验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中    return proxyFactory.getProxy(getProxyClassLoader());&#125;\n\n知道要采用 jdk 动态代理的方式后，我们就细看这个代理类是如何构建的，对应的 InvocationHandler 又是怎样的，之所以关注 InvocationHandler，是因为 jdk 代理类的根本逻辑还是调用 InvocationHandler 实例的 invoke 方法。我们直接看上边代码块的最后一句即 return proxyFactory.getProxy(getProxyClassLoader()); 。它的实现如下 ：\n// 创建代理类public Object getProxy(@Nullable ClassLoader classLoader) &#123;    return createAopProxy().getProxy(classLoader);\t// jdk：获取必须的接口信息，构建代理类，invocation handler 就是 JdkDynamicAopProxy 实例&#125;\t// cglib：验证代理工厂长持有的目标类，然后构建 enhancer，根据 enhancer 构建代理类 class，然后通过 class 构建代理类实例，最后将 callbacks 设置到其中\n\n逻辑跟 aop 实现的分析是一样的，第一段代码执行的结果可以算作是一个工厂类，通过下边的代码我们知道拿到的是一个 JdkDynamicAopProxy 实例，然后我们调用它的 getProxy 方法。\n@Overridepublic AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123;    if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123;        Class&lt;?&gt; targetClass = config.getTargetClass();\t// 执行到这里，说明采用 cglib 代理方式        if (targetClass == null) &#123;            throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; +                    &quot;Either an interface or a target is required for proxy creation.&quot;);        &#125;\t// 目标类是接口或者是 Proxy 接口实现类，那么进行 jdk 代理        if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123;            return new JdkDynamicAopProxy(config);        &#125;        return new ObjenesisCglibAopProxy(config);    &#125;    else &#123;        return new JdkDynamicAopProxy(config);\t// 这里就是进行 jdk 代理方式    &#125;&#125;\n\n下边就是 JdkDynamicAopProxy#getProxy(java.lang.ClassLoader) 方法的实现，熟悉 jdk 动态代理的小伙伴应该立即就能知道这是一个典型的通过 Proxy 类创建 jdk 代理类的过程。其中 proxiedInterfaces 参数代表着创建的代理类需要实现的接口类型。而紧跟的那个参数 this 其实就是 InvocationHandler 实例了。如果我们执行代理类的方法，那么该实例的 invoke 方法将会被调用，这是本文下一部分将要分析的内容。\n记住这里的 this 代表着 JdkDynamicAopProxy 类，可以肯定它实现了 InvocationHandler 接口，而且它持有了 ProxyFactory 实例，上文我们指出过 ProxyFactory 又持有了本例中唯一的 Advisor，所以可以说我们的 InvocationHandler 也是间接的持有了这个唯一的 Advisor。\nproxiedInterfaces 是一个数组类型，这就说明我们的代理类可以实现多个接口，就拿本例来说，我把所有的接口类型贴在下边，可以看到我们最关心的 UserService 接口就在其中，至于其它的几个接口怎么来的请自行查看 AopProxyUtils.completeProxiedInterfaces(this.advised, true); 方法的实现。\n@Override\t// 获取必须的接口信息，构建代理类，invocation handler 就是 JdkDynamicAopProxy 实例public Object getProxy(@Nullable ClassLoader classLoader) &#123;    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Creating JDK dynamic proxy: &quot; + this.advised.getTargetSource());    &#125;\t// 获取全部的代理接口集合，包括 advised 中获取的全部接口集合以及制定的三个接口    Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true);    findDefinedEqualsAndHashCodeMethods(proxiedInterfaces);\t// 看接口中是否定义了 equals 和 hashcode 方法    return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);\t// 构建代理类，invocation handler 就是当前实例&#125;\n\n\n\n本例事务代理类实现的接口\n\n\n\n对代理类的创建过程进行一下总结，我们首先是从环境中获取到了本例中唯一的一个 advisor，将其注入到了 ProxyFactory 中，然后就是通过 ProxyFactory 来构建 JdkDynamicAopProxy 实例，它可以看做是一个工厂类，最后就是通过它来构建我们的代理类，代理类实现了上图中的四个接口，我们本例关心的 UserService 接口就在其中，传入的 InvocationHandler 就是 JdkDynamicAopProxy 实例，下一部分的内容就是看该实例的 invoke 方法实现。\n事务执行过程上文已经指出了代理类在执行目标方法时，会直接调用 InvocationHandler 的 invoke 方法，那么这一部分，我们将分析 invoke 方法的实现是怎样的。我已经将 invoke 方法的实现代码贴出来了，内容比较长，但我们真正需要关心的就是后半部分，前边的代码只是针对特殊方法调用的处理，我暂时没有去深入了解，同样的不影响我们对于 spring 事务机制实现原理的理解。跟 cglib 代理方式一样，本段代码中 if (this.advised.exposeProxy) 这个代码块也对代理类的暴露进行了处理，这样我们就能在我们的用户代码中拿到当前代理类，详细的使用方式参考上一篇文章的示例代码二。\n\norg.springframework.aop.framework.JdkDynamicAopProxy#invoke\n\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;    Object oldProxy = null;    boolean setProxyContext = false;    TargetSource targetSource = this.advised.targetSource;\t// 这里是目标类    Object target = null;    try &#123;        if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123;\t// 对于 equals 方法的处理            // The target does not implement the equals(Object) method itself.            return equals(args[0]);        &#125;        else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123;\t// 对于 hashcode 方法的处理            // The target does not implement the hashCode() method itself.            return hashCode();        &#125;        else if (method.getDeclaringClass() == DecoratingProxy.class) &#123;\t// 对于 DecoratingProxy 接口方法的处理            // There is only getDecoratedClass() declared -&gt; dispatch to proxy config.            return AopProxyUtils.ultimateTargetClass(this.advised);        &#125;        else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp;\t// 对于 Advised 接口实现类方法的处理                method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123;            // Service invocations on ProxyConfig with the proxy config...            return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);        &#125;        Object retVal;        if (this.advised.exposeProxy) &#123;\t// 看是否需要暴露代理类            // Make invocation available if necessary.            oldProxy = AopContext.setCurrentProxy(proxy);            setProxyContext = true;        &#125;        // Get as late as possible to minimize the time we &quot;own&quot; the target,        // in case it comes from a pool.        target = targetSource.getTarget();\t// 获取目标实例        Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null);\t// 获取目标实例类        // 尝试从缓存中获取 interceptorList，没有的话就从当前实例中获取（获取 Advised 的全部 advisors，看 advisor 是否适配当前方法，适配的话从 advisor 中获取到 Advice，然后将其添加到 interceptorList 集合返回）        // Get the interception chain for this method.        List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);        // Check whether we have any advice. If we don&#x27;t, we can fallback on direct        // reflective invocation of the target, and avoid creating a MethodInvocation.        if (chain.isEmpty()) &#123;            // We can skip creating a MethodInvocation: just invoke the target directly            // Note that the final invoker must be an InvokerInterceptor so we know it does            // nothing but a reflective operation on the target, and no hot swapping or fancy proxying.            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);            retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);        &#125;        else &#123;            // We need to create a method invocation...            MethodInvocation invocation =\t// 构建 ReflectiveMethodInvocation 来控制 interceptor 链的调用                    new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);            // Proceed to the joinpoint through the interceptor chain.            retVal = invocation.proceed();        &#125;        // Massage return value if necessary.        Class&lt;?&gt; returnType = method.getReturnType();        if (retVal != null &amp;&amp; retVal == target &amp;&amp;                returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp;                !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123;            // Special case: it returned &quot;this&quot; and the return type of the method            // is type-compatible. Note that we can&#x27;t help if the target sets            // a reference to itself in another returned object.            retVal = proxy;        &#125;        else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123;            throw new AopInvocationException(                    &quot;Null return value from advice does not match primitive return type for: &quot; + method);        &#125;        return retVal;    &#125;    finally &#123;        if (target != null &amp;&amp; !targetSource.isStatic()) &#123;            // Must have come from TargetSource.            targetSource.releaseTarget(target);        &#125;        if (setProxyContext) &#123;            // Restore old proxy.            AopContext.setCurrentProxy(oldProxy);        &#125;    &#125;&#125;\n\n下边代码的后半部分就是我们应该关注的点了，首先是拦截器链的获取，通过 this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); 这段代码进行，上文我们已经指出了 InvocationHandler 持有了 ProxyFactory，而这句代码的 advised 实例其实就是 ProxyFactory，它持有了我们开篇中指出的五个 bean 中的 BeanFactoryTransactionAttributeSourceAdvisor（增强器）对吗？好了那么这里的拦截器链就是通过它来获取的，过程比较繁琐，我也不想细究它每一行代码是怎样的，只需要了解上文中指出的，在进行标签的解析时，BeanFactoryTransactionAttributeSourceAdvisor 对应的 BeanDefinition 是持有了 TransactionInterceptor 实例的唯一标识符的，就凭这一点，再通过 BeanFactoryTransactionAttributeSourceAdvisor 拿到 TransactionInterceptor 就不是什么难以理解的事了，所以这里只给出最终的获取结果就好。特别注意哦这个唯一的拦截器是不是也很熟悉啊？？没错，正好就是本文开篇指出的那个五个 bean 中的 TransactionInterceptor（事务实现的核心拦截器，事务的回滚都是在其中完成）对吗？这是一个很关键的拦截器，事务的实现就是靠它。\n\n\n拦截器链内容\n\n\n\n再回到我们的分析点，就是 JdkDynamicAopProxy#invoke 方法中获取拦截器链的那句，我们已经拿到了必要的拦截器链，里边就只有一个拦截器 TransactionInterceptor。接着就是一个 if-else 分支，我们这里的拦截器链是有内容的，所以走 else 分支如下，里边的逻辑又跟 cglib 的拦截器链调用过程一样了，新构建出来的 ReflectiveMethodInvocation 类持有了代理相关的大部分信息，它还负责着拦截器链的调用流程。\n// We need to create a method invocation...MethodInvocation invocation =\t// 构建 ReflectiveMethodInvocation 来控制 interceptor 链的调用        new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);// Proceed to the joinpoint through the interceptor chain.retVal = invocation.proceed();\n\n想都不用想，invocation.proceed(); 方法将会触发拦截器链第一个节点的逻辑，也就是 TransactionInterceptor 方法，尽管已经猜到了，我还是要贴出 invocation.proceed(); 代码实现如下，因为是第一次调用，所以这里的 currentInterceptorIndex 值为 -1，interceptorsAndDynamicMethodMatchers 其实就是我们的拦截器链，它是在构造函数中被初始化的，里边就只有一个元素为 TransactionInterceptor 实例，根据以上条件，程序将会执行最后一行代码 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);，即 TransactionInterceptor 实例的 invoke 方法了，我们跟进去看实现。\n@Override@Nullablepublic Object proceed() throws Throwable &#123;    //\tWe start with an index of -1 and increment early.    if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123;        return invokeJoinpoint();\t// 这里就是触发连接点方法    &#125;    Object interceptorOrInterceptionAdvice =\t// 逐个获取 interceptorOrInterceptionAdvice            this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);    if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123;        // Evaluate dynamic method matcher here: static part will already have        // been evaluated and found to match.        InterceptorAndDynamicMethodMatcher dm =                (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;        Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());        if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123;            return dm.interceptor.invoke(this);        &#125;        else &#123;            // Dynamic matching failed.            // Skip this interceptor and invoke the next in the chain.            return proceed();        &#125;    &#125;    else &#123;        // It&#x27;s an interceptor, so we just invoke it: The pointcut will have        // been evaluated statically before this object was constructed.\t// 对逐个获取的 interceptorOrInterceptionAdvice 进行 invoke 调用        return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);\t// 参数为通过代理各项参数构建的 CglibMethodInvocation    &#125;&#125;\n\n实现如下，常规操作，只有这里采用了一个特殊的传参方式，传入的是一个方法引用，了解就好，继续往下跟。\npublic Object invoke(MethodInvocation invocation) throws Throwable &#123;    // Work out the target class: may be &#123;@code null&#125;.    // The TransactionAttributeSource should be passed the target class    // as well as the method, which may be from an interface.\t获取目标类的类型    Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);    // Adapt to TransactionAspectSupport&#x27;s invokeWithinTransaction...    return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);&#125;\n\n终于到了我们期待已久的事务实现逻辑代码了，赶紧的贴出源码开心一下，代码主干分为两个分支，就本例而言，我们只使用到了 if 分支，所以就只截取这一部分展示。而没用到的那一部分，我就没有做深入了解了。\n@Nullable\t// 触发真正的业务逻辑，如果发生异常就进行回滚，否则进行事务的提交protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass,        final InvocationCallback invocation) throws Throwable &#123;    if (this.reactiveAdapterRegistry != null) &#123;\t// 暂不做了解        ReactiveAdapter adapter = this.reactiveAdapterRegistry.getAdapter(method.getReturnType());        if (adapter != null) &#123;            return new ReactiveTransactionSupport(adapter).invokeWithinTransaction(method, targetClass, invocation);        &#125;    &#125;    // If the transaction attribute is null, the method is non-transactional.    TransactionAttributeSource tas = getTransactionAttributeSource();    final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null);    final PlatformTransactionManager tm = determineTransactionManager(txAttr);\t// 获取事务管理器，尝试从缓存中获取 PlatformTransactionManager，没有的话就从 BeanFactory 中获取，缓存后进行返回    final String joinpointIdentification = methodIdentification(method, targetClass, txAttr);\t// 获取方法的全限定名，没有的话通过 TransactionAttribute 的描述符代替    if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123;        // Standard transaction demarcation with getTransaction and commit/rollback calls.\t// 将 TransactionAttribute 封装为 DelegatingTransactionAttribute，从 PlatformTransactionManager 中获取 TransactionStatus        TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);\t// 最后构建 TransactionInfo（通过参数构建 TransactionInfo，设置了状态信息， 将事务信心保存到线程本地变量中，同时保留了原先的事务信息，返回）        Object retVal;        try &#123;            // This is an around advice: Invoke the next interceptor in the chain.            // This will normally result in a target object being invoked.            retVal = invocation.proceedWithInvocation();\t// 继续下一个 advice 的调用，如果没有后续的 advice，直接进行目标方法的的调用        &#125;        catch (Throwable ex) &#123;            // target invocation exception            completeTransactionAfterThrowing(txInfo, ex);\t// 对于异常发生后，事物的处理方式，提交或者回滚            throw ex;        &#125;        finally &#123;\t// 恢复线程本地变量中的 TransactionInfo            cleanupTransactionInfo(txInfo);        &#125;        if (vavrPresent &amp;&amp; VavrDelegate.isVavrTry(retVal)) &#123;            // Set rollback-only in case of Vavr failure matching our rollback rules...            TransactionStatus status = txInfo.getTransactionStatus();            if (status != null &amp;&amp; txAttr != null) &#123;                retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status);            &#125;        &#125;        // 正常情况下，进行事务的提交        commitTransactionAfterReturning(txInfo);        return retVal;    &#125;&#125;\n\n先看 TransactionAttributeSource tas = getTransactionAttributeSource(); 这句，它做的事情就是获取它持有的 TransactionAttributeSource 实例，不知道它具体是什么吗？？直接给出结果就知道了，又是一个熟悉的类，没错就是本文开篇中那五个 bean 中的 AnnotationTransactionAttributeSource（主要是用来存储一些事务相关的属性信息）。它有一个属性 attributeCache，是一个 ConcurrentHashMap 实例，本例中里边有 528 项记录。不要慌，其实这些记录中只有两项的值不为空。其他的都是空值，我们所要关注的也就只有这不为空的两项，他们的 key 就是本例中位于 UserService 接口和 UserServiceImpl 实现类中两个 save 方法对应的 MethodClassKey 实例，而对应的值呢，就是对这两个方法进行调用时事务相关的一些属性值，也就是说在这 528 项中，只有值不为空的两项他们对应的方法被调用时会触发事务机制，否则是不会触发事务机制的。如果觉得比较绕，那就还是请继续看后边的分析吧。\n\n\nTransactionAttributeSource 实例内容\n\n\n\n接着就是从 TransactionAttributeSource 中获取事务相关的属性 TransactionAttribute，我们这里调用的是 UserServiceImpl 类的 save 方法，上边已经指出了在 attributeCache 缓存中，该方法对应的值不为空，这样我们获取的 TransactionAttribute 就不是空，再调用 determineTransactionManager(txAttr); 这个方法获取事务管理器，其实就本例而言，获取的过程跟参数没啥关系，因为参数 txAttr 中的 qualifier 属性为空串，所以获取事务管理器时就是依据 TransactionAspectSupport#transactionManagerBeanName 字段来获取的，具体的代码就不贴了，就本例而言，根本拿到的就是我们在 spring 配置文件中指定的那个 “transactionManager”，它持有了配置文件中指定的 dataSource 如下图，了解这个就完事。\n\n\ntransactionManager 实例内容\n\n\n\n\n再往下就是 final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); 这行代码，从方法名就知道这是一个方法的唯一标识符，怎么来的不用深究，直接给出结果。\n\n\n方法的唯一标识符\n\n\n\n再往下就是构建 TransactionInfo 实例，和事务操作相关的信息都封装在其中，代码如下，也没有什么要注意的地方，注释中已经对代码进行了解释，反正最终返回的就是构建出来的 TransactionInfo，它持有了 TransactionManager、TransactionAttribute、方法的唯一标识符信息，知道这些就行了。\n// 将 TransactionAttribute 封装为 DelegatingTransactionAttribute，从 PlatformTransactionManager 中获取 TransactionStatus@SuppressWarnings(&quot;serial&quot;)\t// 最后构建 TransactionInfo（通过参数构建 TransactionInfo，设置了状态信息， 将事务信心保存到线程本地变量中，同时保留了原先的事务信息，返回）protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm,        @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123;    // If no name specified, apply method identification as transaction name.    if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123;\t// 将 TransactionAttribute 封装为 DelegatingTransactionAttribute        txAttr = new DelegatingTransactionAttribute(txAttr) &#123;            @Override            public String getName() &#123;                return joinpointIdentification;            &#125;        &#125;;    &#125;    TransactionStatus status = null;    if (txAttr != null) &#123;        if (tm != null) &#123;            status = tm.getTransaction(txAttr);        &#125;        else &#123;            if (logger.isDebugEnabled()) &#123;                logger.debug(&quot;Skipping transactional joinpoint [&quot; + joinpointIdentification +                        &quot;] because no transaction manager has been configured&quot;);            &#125;        &#125;    &#125;\t// 通过参数构建 TransactionInfo，设置了状态信息， 将事务信心保存到线程本地变量中，同时保留了原先的事务信息，返回    return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);&#125;\n\n再往下走就是执行 retVal = invocation.proceedWithInvocation(); ，这里的 invocation 就是用来控制拦截器链执行的实例的 proceed 方法，是通过函数引用的方式传进来的，这一点上文已经说过了，我们已经执行过一次它的 proceed 方法了，被调用的是 TransactionInterceptor 拦截器，因为一共就只有只有一个拦截器，所以本次 ReflectiveMethodInvocation#proceed 方法的调用就会满足 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) 判断条件，根据上一篇文章的分析，我们知道这将会导致用户代码的调用，也就是业务逻辑中进行数据库的插入操作。因为这个业务逻辑中，我们人为的抛出了一个运行时异常，所以这个异常就会被上层代码所捕获，而捕获点就是 TransactionAspectSupport#invokeWithinTransaction 方法的 catch (Throwable ex) 处，事务的回滚操作也就是在这里完成的。\n在该 catch 代码块中核心就是调用了 completeTransactionAfterThrowing 方法，从方法名就知道其中的核心实现就是完成异常捕获后的事务处理，完整的方法实现如下，根据 if-else 的分支结构，我们就能知道就算是异常出现，那么对于事务的处理也是有两种模式的，if 代码块中的 rollback 方法名我们就能知道这里进行的是回滚操作，而 else 代码块中的 commit 方法名，我们知道是提交操作，也就是说不进行回滚。那么 if 判断成立的条件是什么呢？？第一条很明显，就是事务信息 TransactionInfo 持有的事务属性 transactionAttribute 不能为空，其次就是事务属性 transactionAttribute 的 rollbackOn 方法的返回结果了。\n// 对于异常发生后，事物的处理方式，提交或者回滚protected void completeTransactionAfterThrowing(@Nullable TransactionInfo txInfo, Throwable ex) &#123;    if (txInfo != null &amp;&amp; txInfo.getTransactionStatus() != null) &#123;        if (logger.isTraceEnabled()) &#123;            logger.trace(&quot;Completing transaction for [&quot; + txInfo.getJoinpointIdentification() +                    &quot;] after exception: &quot; + ex);        &#125;\t// 第二个条件主要是判断回滚规则，最基本的就是在发生运行时异常和错误时发生回滚        if (txInfo.transactionAttribute != null &amp;&amp; txInfo.transactionAttribute.rollbackOn(ex)) &#123;            try &#123;                txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus());\t// 事务回滚            &#125;            catch (TransactionSystemException ex2) &#123;                logger.error(&quot;Application exception overridden by rollback exception&quot;, ex);                ex2.initApplicationException(ex);                throw ex2;            &#125;            catch (RuntimeException | Error ex2) &#123;                logger.error(&quot;Application exception overridden by rollback exception&quot;, ex);                throw ex2;            &#125;        &#125;        else &#123;            // We don&#x27;t roll back on this exception.            // Will still roll back if TransactionStatus.isRollbackOnly() is true.            try &#123;\t// 如果捕获到的异常不满足回滚规则，直接进行提交                txInfo.getTransactionManager().commit(txInfo.getTransactionStatus());            &#125;            catch (TransactionSystemException ex2) &#123;                logger.error(&quot;Application exception overridden by commit exception&quot;, ex);                ex2.initApplicationException(ex);                throw ex2;            &#125;            catch (RuntimeException | Error ex2) &#123;                logger.error(&quot;Application exception overridden by commit exception&quot;, ex);                throw ex2;            &#125;        &#125;    &#125;&#125;\n\n我们看 rollbackOn 方法的根本实现如下，上半部分的 rollbackRules 的处理部分我没有看懂它的意思，因为就本例而言，上边的判断条件确实没用上，所以不太好理解它的意思。紧接着下边又有一个判断条件，即 return super.rollbackOn(ex); 这句代码，它是在父类中实现的，我们点进去就能知道，它会对捕获到的异常进行判断，如果是运行时异常或者是 Error 错误，那么就会返回 true，否则返回 false。\n\norg.springframework.transaction.interceptor.RuleBasedTransactionAttribute#rollbackOn\n\n@Override\t// 这里主要是判断回滚规则，最基本的就是在发生运行时异常和错误时发生回滚public boolean rollbackOn(Throwable ex) &#123;    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Applying rules to determine whether transaction should rollback on &quot; + ex);    &#125;    RollbackRuleAttribute winner = null;    int deepest = Integer.MAX_VALUE;    if (this.rollbackRules != null) &#123;        for (RollbackRuleAttribute rule : this.rollbackRules) &#123;            int depth = rule.getDepth(ex);            if (depth &gt;= 0 &amp;&amp; depth &lt; deepest) &#123;                deepest = depth;                winner = rule;            &#125;        &#125;    &#125;    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Winning rollback rule is: &quot; + winner);    &#125;    // User superclass behavior (rollback on unchecked) if no rule matches.    if (winner == null) &#123;        logger.trace(&quot;No relevant rollback rule found: applying default rules&quot;);        return super.rollbackOn(ex);\t// 这里说明只有在发生运行时异常和错误时才会触发回滚    &#125;    return !(winner instanceof NoRollbackRuleAttribute);&#125;\n\n再回到我们 if 分支那里，因为我们在业务代码中抛出的异常是运行时异常，所以 if 判断的第二个条件也是成立的，也就是说我们将要进行事务的回滚操作。但是如果我们将业务代码中的异常修改为非运行异常，那么此时事务就会正常提交。这样带来的结果就是数据入库了。还是看看事务回滚的代码实现吧，根本的就是调用的下边的代码，更加细节的部分我已经没有去深究了，因为到这里对于理解事务机制的实现已经足够了，我这里就仅仅是将代码段的作用给进行标注。\n// 尝试调用事务同步器的前置处理方法,进行事务的回滚操作,逐个触发同步器链每个元素的 afterCompletion 方法，最后事务回滚后的扫尾工作，设置事务的状态， 线程本地变量中移除资源信息（连接信息），设置连接的自动提交，恢复隔离级别，释放连接，恢复 connection holder 的状态信息private void processRollback(DefaultTransactionStatus status, boolean unexpected) &#123;    try &#123;        boolean unexpectedRollback = unexpected;\t// 预期外的回滚        try &#123;\t// 尝试调用事务同步器的前置处理方法            triggerBeforeCompletion(status);            if (status.hasSavepoint()) &#123;\t// 看事务状态是否有保存点                if (status.isDebug()) &#123;                    logger.debug(&quot;Rolling back transaction to savepoint&quot;);                &#125;                status.rollbackToHeldSavepoint();\t// 回滚到保存点            &#125;            else if (status.isNewTransaction()) &#123;\t// 是否是新事务呢？                if (status.isDebug()) &#123;                    logger.debug(&quot;Initiating transaction rollback&quot;);                &#125;\t// 直接进行回滚                doRollback(status);\t// 进行事务的回滚操作            &#125;            else &#123;\t// 不是新事务的处理方式，存在现有的事务处理方式                // Participating in larger transaction                if (status.hasTransaction()) &#123;\t// 检查回滚条件                    if (status.isLocalRollbackOnly() || isGlobalRollbackOnParticipationFailure()) &#123;\t// 如果局部的事务失败，是否设置全局的事务回滚状态                        if (status.isDebug()) &#123;                            logger.debug(&quot;Participating transaction failed - marking existing transaction as rollback-only&quot;);                        &#125;                        doSetRollbackOnly(status);\t// 仅仅是设置回滚的标志                    &#125;                    else &#123;                        if (status.isDebug()) &#123;                            logger.debug(&quot;Participating transaction failed - letting transaction originator decide on rollback&quot;);                        &#125;                    &#125;                &#125;                else &#123;                    logger.debug(&quot;Should roll back transaction but cannot - no transaction available&quot;);                &#125;                // Unexpected rollback only matters here if we&#x27;re asked to fail early                if (!isFailEarlyOnGlobalRollbackOnly()) &#123;                    unexpectedRollback = false;                &#125;            &#125;        &#125;        catch (RuntimeException | Error ex) &#123;\t// 触发            triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN);            throw ex;        &#125;        // 逐个触发同步器链每个元素的 afterCompletion 方法        triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK);        // Raise UnexpectedRollbackException if we had a global rollback-only marker        if (unexpectedRollback) &#123;            throw new UnexpectedRollbackException(                    &quot;Transaction rolled back because it has been marked as rollback-only&quot;);        &#125;    &#125;    finally &#123;\t// 事务回滚后的扫尾工作，设置事务的状态， 线程本地变量中移除资源信息（连接信息），设置连接的自动提交，恢复隔离级别，释放连接，恢复 connection holder 的状态信息        cleanupAfterCompletion(status);    &#125;&#125;\n\n只要注意一点，就是真正的事务回滚是在上边代码中的 doRollback(status); 语句中完成的，而其他部分就只是一些事务回滚生命周期方法的处理，或者是对于事务回滚后的一些善后工作。关于 doRollback(status); 的实现，我们不妨看看，其实就是跟我们自己进行事务回滚的操作一样，根本还是调用的 java.sql.Connection#rollback() 看到这里我想小伙伴已经对 spring 的事务实现有比较清晰的理解了，至于一些其他的细节部分，如果有精力就可以去看。\n@Override\t// 进行事务的回滚操作protected void doRollback(DefaultTransactionStatus status) &#123;    DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction();\t// 数据源事务对象    Connection con = txObject.getConnectionHolder().getConnection();\t// 也就是说和数据库交互相关的信息都保存在 DataSourceTransactionObject 实例中    if (status.isDebug()) &#123;        logger.debug(&quot;Rolling back JDBC transaction on Connection [&quot; + con + &quot;]&quot;);    &#125;    try &#123;        con.rollback();\t// 调用真正的回滚操作    &#125;    catch (SQLException ex) &#123;        throw new TransactionSystemException(&quot;Could not roll back JDBC transaction&quot;, ex);    &#125;&#125;\n\n最后对 spring 事务代理类的执行过程进行一下总结，我们会从环境中获取到 Advisors 信息，然后根据它来得到拦截器链，而拦截器链的执行是由 ReflectiveMethodInvocation 实例控制的，就我们本例而言，这里拦截器链只有一个元素，就是 TransactionInterceptor 实例，我们将要调用它的 invoke 方法，该方法中会继续下一个拦截器的执行，当所有拦截器执行完后，就会触发用户代码，如果此时用户代码中抛出了运行时异常，只要该异常到达 TransactionInterceptor 被捕获，那么该拦截器就会根据必要的条件来进行事务的回滚或者提交操作。\n","categories":["源码分析"],"tags":["Spring"]},{"title":"SpringMVC基本原理分析","url":"/2019/07/25/2019-07-25-SpringMVC%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","content":"前言本文是关于 SpringMVC 实现原理分析的文章，这之前还写了两篇关于 Spring AOP 和事务机制实现原理的文章，总的来说 SpringMVC 的执行流程稍微复杂些，但是根本的分析方法其实还是和上两篇文章差不多的，所以如果你对 spring 源码分析不知道如何开始的话，那么我还是建议先去看看上两篇文章，因为分析的方式基本差不多，所以本文也就从简进行说明，细节的部分也不会去深究，另外对于实现中的视图解析部分，我们是以 jsp 页面为例的，所以它的渲染是由 tomcat 所完成的，不属于本文分析的内容，如果采用的是其它类型的页面，比如 ftl，那么其渲染就是交由 FreeMarker 视图解析器完成的，渲染的过程我也没深究，就只是点到即可，如果对此感兴趣，可自行查找相关文章进行理解。\n示例程序同样的示例程序已经提交到我的 github，需要可以自行获取，而且里边添加了一些自己在分析实现原理时便于自己理解的注释。\n\npojo 类 top.aprilyolies.example.mvc.User\n\npublic class User &#123;\tprivate String name;\tpublic String getName() &#123;\t\treturn name;\t&#125;\tpublic void setName(String name) &#123;\t\tthis.name = name;\t&#125;&#125;\n\ncontroller 类 top.aprilyolies.example.mvc.UserController\n\n@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123;\t@RequestMapping(&quot;/hello&quot;)\tpublic ModelAndView hello() &#123;\t\tSystem.out.println(&quot;accessed....&quot;);\t\tUser user = new User();\t\tuser.setName(&quot;eva&quot;);\t\tUser user1 = new User();\t\tuser1.setName(&quot;johnson&quot;);\t\tArrayList&lt;User&gt; users = new ArrayList&lt;&gt;();\t\tusers.add(user);\t\tusers.add(user1);\t\tModelAndView mv = new ModelAndView(&quot;userlist&quot;, &quot;users&quot;, users);\t\treturn mv;\t&#125;&#125;\n\n\nspring 配置文件\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans            http://www.springframework.org/schema/beans/spring-beans-4.3.xsd            http://www.springframework.org/schema/context            http://www.springframework.org/schema/context/spring-context-4.3.xsd            http://www.springframework.org/schema/mvc            http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd &quot;&gt;    &lt;!-- @Controller注解扫描 --&gt;    &lt;context:component-scan base-package=&quot;top.aprilyolies.example.mvc&quot;/&gt;    &lt;!-- 注解驱动:替我们显示的配置了最新版的注解的处理器映射器和处理器适配器 --&gt;    &lt;mvc:annotation-driven/&gt;    &lt;bean id=&quot;viewResolver&quot; class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;        &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt;        &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;\n\n\nweb 配置文件 web.xml \n\n&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;\t\t xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\t\t xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee                             http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt;\t&lt;display-name&gt;spring&lt;/display-name&gt;\t&lt;welcome-file-list&gt;\t\t&lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;\t&lt;/welcome-file-list&gt;\t&lt;context-param&gt;\t\t&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;\t\t&lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt;\t&lt;/context-param&gt;\t&lt;listener&gt;\t\t&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;\t&lt;/listener&gt;\t&lt;servlet&gt;\t\t&lt;servlet-name&gt;springMvc&lt;/servlet-name&gt;\t\t&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;\t\t&lt;init-param&gt;\t\t\t&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;\t\t\t&lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt;\t\t&lt;/init-param&gt;\t\t&lt;!-- 在tomcat启动的时候就加载这个servlet --&gt;\t\t&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;\t&lt;/servlet&gt;\t&lt;servlet-mapping&gt;\t\t&lt;servlet-name&gt;springMvc&lt;/servlet-name&gt;\t\t&lt;!--        *.action    代表拦截后缀名为.action结尾的        / \t\t\t拦截所有但是不包括.jsp        /* \t\t\t拦截所有包括.jsp         --&gt;\t\t&lt;url-pattern&gt;/&lt;/url-pattern&gt;\t&lt;/servlet-mapping&gt;&lt;/web-app&gt;\n\n很简单的示例程序，但是对于分析 springMVC 的基本实现原理已经足够了，程序启动后，访问对应的请求链接就能在页面获取需要的信息了。\nWebApplicationContext 的初始化我们的程序是从 tomcat 启动的，它其实就是一个 servlet 程序容器，管理着 servlet 的创建、初始化、调用和销毁。在这个 servlet 容器的声明周期中有一项就是在容器的创建和销毁时完成对应监听器方法的调用，如下面这个接口所示，注意这个接口不是我们定义的，而是属于 servlet 规范中的项。我们需要做的就是遵循此规范，完成自己的逻辑。\n\njavax.servlet.ServletContextListener\n\npublic interface ServletContextListener extends EventListener &#123;    public default void contextInitialized(ServletContextEvent sce) &#123;    &#125;    public default void contextDestroyed(ServletContextEvent sce) &#123;    &#125;&#125;\n\n了解这一点后，我们看 web.xml 文件，因为它就是直接跟 tomcat 相关的配置。里边有一个 &lt;listener&#x2F;&gt; 标签，它其实就是上边所说的监听器，我们在里边配置了 org.springframework.web.context.ContextLoaderListener，那么在 tomcat 启动后，该监听器对应的接口方法一定会被调用，这就是我们分析的入口。定位到该类，可以知道它实现了 ServletContextListener 接口，所以该接口对应的方法就是我们分析的入口，该接口中有两个上边已经指出了，我们这里关心 contextInitialized 方法的实现如下。\n/**    * Initialize the root web application context.    */\t// 获取 context class 的类型，然后通过它来构建 WebApplicationContext 实例，让其持有 ServletContext，设置了 spring 配置文件的位置，完成部分属性的替换和设置，然后刷新和启动 ConfigurableWebApplicationContext@Overridepublic void contextInitialized(ServletContextEvent event) &#123;    initWebApplicationContext(event.getServletContext());&#125;\n\n参数的 event.getServletContext() 其实就是获取的 tomcat 容器对应的上下文环境，里边有 tomcat 容器相关的很多信息。进入 initWebApplicationContext 方法，从方法名我们就知道是初始化 WebApplicationContext，注意这个上下文环境就是跟我们的 spring 容器相关了。方法的的实现如下，方法的接口很清晰，我在关键代码处做出了注释，总结下来就是获取我们要创建的 spring 容器 context class 的类型，然后通过它来构建 ApplicationContext 实例，它持有 ServletContext 实例，然后就是设置了 spring 配置文件的位置，完成部分属性的替换和设置，然后刷新和启动 ApplicationContext。\n注意此时启动的 ApplicationContext，我们在 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); 此行代码中，让 servlet 上下文环境持有了本 ApplicationContext，它的属性名是 org.springframework.web.context.WebApplicationContext.ROOT，它将会在后面使用到。\n */\t// 获取 context class 的类型，然后通过它来构建 WebApplicationContext 实例，让其持有 ServletContext，设置了 spring 配置文件的位置，完成部分属性的替换和设置，然后刷新和启动 ConfigurableWebApplicationContextpublic WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123;\t// 参数是 tomcat 中的实例    if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123;        throw new IllegalStateException(\t// 检查可能的重复 application context                &quot;Cannot initialize context because there is already a root application context present - &quot; +                &quot;check whether you have multiple ContextLoader* definitions in your web.xml!&quot;);    &#125;    servletContext.log(&quot;Initializing Spring root WebApplicationContext&quot;);    Log logger = LogFactory.getLog(ContextLoader.class);    if (logger.isInfoEnabled()) &#123;        logger.info(&quot;Root WebApplicationContext: initialization started&quot;);    &#125;    long startTime = System.currentTimeMillis();    try &#123;        // Store context in local instance variable, to guarantee that        // it is available on ServletContext shutdown.        if (this.context == null) &#123;\t// 获取 context class 的类型，然后通过它来构建 WebApplicationContext 实例            this.context = createWebApplicationContext(servletContext);        &#125;        if (this.context instanceof ConfigurableWebApplicationContext) &#123;            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context;            if (!cwac.isActive()) &#123;                // The context has not yet been refreshed -&gt; provide services such as                // setting the parent context, setting the application context id, etc                if (cwac.getParent() == null) &#123;                    // The context instance was injected without an explicit parent -&gt;                    // determine parent for root web application context, if any.                    ApplicationContext parent = loadParentContext(servletContext);                    cwac.setParent(parent);                &#125;\t// ConfigurableWebApplicationContext 持有 ServletContext，设置了 spring 配置文件的位置，完成部分属性的替换和设置，然后刷新和启动 ConfigurableWebApplicationContext                configureAndRefreshWebApplicationContext(cwac, servletContext);            &#125;        &#125;\t// 将启动的 spring context 和 servlet context 绑定，避免重复启动        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);        ClassLoader ccl = Thread.currentThread().getContextClassLoader();        if (ccl == ContextLoader.class.getClassLoader()) &#123;            currentContext = this.context;        &#125;        else if (ccl != null) &#123;            currentContextPerThread.put(ccl, this.context);        &#125;        if (logger.isInfoEnabled()) &#123;            long elapsedTime = System.currentTimeMillis() - startTime;            logger.info(&quot;Root WebApplicationContext initialized in &quot; + elapsedTime + &quot; ms&quot;);        &#125;        return this.context;    &#125;    catch (RuntimeException | Error ex) &#123;        logger.error(&quot;Context initialization failed&quot;, ex);        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex);        throw ex;    &#125;&#125;\n\nContextLoaderListener 类的核心作用就是上文所说的那样，细节部分我们不作深入探讨，但是在我 github 上的源码中，还是有添加部分注释，需要的可以自行查看。\nDispatcherServlet 说明在我们的 web.xml 文件中，除了上文指出的 ContextLoaderListener 外，在我们的 &lt;servlet&#x2F;&gt; 标签中还指定了一个 DispatcherServlet 类，很明显它是一个 servlet 类，它的初始化、使用和销毁将会交给 servlet 容器来管理。我们定位到该类，来看看它的继承体系，以及对应的生命周期方法。\n\n\nDispatcherServlet 继承体系\n\n\n\nDispatcherServlet 类的继承体系如上图，可以知道它继承自 HttpServlet，这是 Servlet 规范中的类，所以我们的分析也就是止于此类。而对于生命周期方法，我们就需要重点关注的点，这里就是 HttpServletBean#init 方法，代码如下。\n// 对于我们的 Servlet 而言，优先调用的是该方法@Override\t// 就这里而言，好像就是将 web.xml 中 servlet 对应的属性值设置到当前 servlet 中，初始化 ApplicationContext，会触发监听器事件，导致标签解析中的 bean 被使用到 Dispatcher Servlet 中public final void init() throws ServletException &#123;\t// 注意 ContextLoaderListener 只是构建的 root ApplicationContext    // Set bean properties from init parameters.\t// 获取 ServletConfig 中的 params，添加到 propertyValueList，如果缺少必须参数，报错    PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties);    if (!pvs.isEmpty()) &#123;        try &#123;            BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);            ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext());            bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment()));            initBeanWrapper(bw);            bw.setPropertyValues(pvs, true);        &#125;        catch (BeansException ex) &#123;            if (logger.isErrorEnabled()) &#123;                logger.error(&quot;Failed to set bean properties on servlet &#x27;&quot; + getServletName() + &quot;&#x27;&quot;, ex);            &#125;            throw ex;        &#125;    &#125;    // Let subclasses do whatever initialization they like.    initServletBean();\t// 初始化 ApplicationContext，会触发监听器事件，导致标签解析中的 bean 被使用到 Dispatcher Servlet 中&#125;\n\n上边方法的第一行构建了一个 ServletConfigPropertyValues 类，需要注意在构建过程中，会完成相关属性的检测，如果缺少必要的属性，将会报错，实现代码如下。\n */\t// 获取 ServletConfig 中的 params，添加到 propertyValueList，如果缺少必须参数，报错public ServletConfigPropertyValues(ServletConfig config, Set&lt;String&gt; requiredProperties)        throws ServletException &#123;    Set&lt;String&gt; missingProps = (!CollectionUtils.isEmpty(requiredProperties) ?            new HashSet&lt;&gt;(requiredProperties) : null);    Enumeration&lt;String&gt; paramNames = config.getInitParameterNames();    while (paramNames.hasMoreElements()) &#123;        String property = paramNames.nextElement();        Object value = config.getInitParameter(property);        addPropertyValue(new PropertyValue(property, value));\t// 将 PropertyValue 添加到 propertyValueList，覆盖式        if (missingProps != null) &#123;            missingProps.remove(property);        &#125;    &#125;    // Fail if we are still missing properties.    if (!CollectionUtils.isEmpty(missingProps)) &#123;        throw new ServletException(                &quot;Initialization from ServletConfig for servlet &#x27;&quot; + config.getServletName() +                &quot;&#x27; failed; the following required properties were missing: &quot; +                StringUtils.collectionToDelimitedString(missingProps, &quot;, &quot;));    &#125;&#125;\n\n接着 HttpServletBean#init 方法中我们需要注意的就是 initServletBean(); 这行，它的具体实现是由子类实现的，代码去掉了日志相关的信息如下，核心就是两行，就本例而言 initFrameworkServlet(); 是空实现，所以就只剩下一行要分析了。\n\nFrameworkServlet#initServletBean\n\n@Override\t// 初始化 ApplicationContext，会触发监听器事件，导致标签解析中的 bean 被使用到 Dispatcher Servlet 中protected final void initServletBean() throws ServletException &#123;    long startTime = System.currentTimeMillis();    try &#123;\t// 初始化 ApplicationContext，会触发监听器事件，导致标签解析中的 bean 被使用到 Dispatcher Servlet 中        this.webApplicationContext = initWebApplicationContext();        initFrameworkServlet();\t// 空    &#125;    catch (ServletException | RuntimeException ex) &#123;        logger.error(&quot;Context initialization failed&quot;, ex);        throw ex;    &#125;&#125;\n\ninitWebApplicationContext(); 方法的实现如下，第一行是获取 rootContext，注意这里获取的 context 其实就是我们上文指出的缓存在 ServletContext 中的那个 ApplicationContext，它是在我们的 ContextLoaderListener 类中完成构建并缓存到 ServletContext 中的。本例中中间那个 if 判断不成立，所以直接跳过。接着就是尝试从环境中获取 ApplicationContext，本例中也是不存在的，所以直接就会到 createWebApplicationContext(rootContext); 这行代码，从名字我们就能知道是手动创建 ApplicationContext，话说我们不是在 ContextLoaderListener 中已经创建了一个 ContextLoaderListener 嘛？为什么这里又创建了一个呢？而且从后边的实现中可以知道，构建方式也跟 ContextLoaderListener 中的构建方式差不多，我这里也没太看懂它的意思，还是先看 createWebApplicationContext(rootContext); 方法的实现吧。\nprotected WebApplicationContext initWebApplicationContext() &#123;    WebApplicationContext rootContext =\t// 获取当前 servlet context 对应的那个 WebApplicationContext            WebApplicationContextUtils.getWebApplicationContext(getServletContext());    WebApplicationContext wac = null;    if (this.webApplicationContext != null) &#123;        // A context instance was injected at construction time -&gt; use it        wac = this.webApplicationContext;        if (wac instanceof ConfigurableWebApplicationContext) &#123;            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac;            if (!cwac.isActive()) &#123;                // The context has not yet been refreshed -&gt; provide services such as                // setting the parent context, setting the application context id, etc                if (cwac.getParent() == null) &#123;                    // The context instance was injected without an explicit parent -&gt; set                    // the root application context (if any; may be null) as the parent                    cwac.setParent(rootContext);                &#125;                configureAndRefreshWebApplicationContext(cwac);            &#125;        &#125;    &#125;    if (wac == null) &#123;        // No context instance was injected at construction time -&gt; see if one        // has been registered in the servlet context. If one exists, it is assumed        // that the parent context (if any) has already been set and that the        // user has performed any initialization such as setting the context id        wac = findWebApplicationContext();    &#125;    if (wac == null) &#123;        // No context instance is defined for this servlet -&gt; create a local one        wac = createWebApplicationContext(rootContext);\t// 根据 rootContext 创建 WebApplicationContext    &#125;    if (!this.refreshEventReceived) &#123;        // Either the context is not a ConfigurableApplicationContext with refresh        // support or the context injected at construction time had already been        // refreshed -&gt; trigger initial onRefresh manually here.        synchronized (this.onRefreshMonitor) &#123;            onRefresh(wac);        &#125;    &#125;    if (this.publishContext) &#123;        // Publish the context as a servlet context attribute.        String attrName = getServletContextAttributeName();        getServletContext().setAttribute(attrName, wac);    &#125;    return wac;&#125;\n\ncreateWebApplicationContext(rootContext); 方法实现根本是调用的如下方法，先是获取 ApplicationContext 对应的类，然后由该 class 来创建 ApplicationContext 实例。注意新创建出来的 ApplicationContext 它持有了 ServletEnviroment 实例，将 ContextLoaderListener 类中创建的 ApplicationContext 作为了自己的 parent 字段，同时还持有了我们 spring 配置文件的位置。\n// 获取 ContextClass，据此创建了一个 ApplicationContext，它持有我们 spring 配置文件的位置，同时将参数的 ApplicationContext 作为父 ApplicationContext，刷新配置和启动protected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) &#123;    Class&lt;?&gt; contextClass = getContextClass();    if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123;        throw new ApplicationContextException(                &quot;Fatal initialization error in servlet with name &#x27;&quot; + getServletName() +                &quot;&#x27;: custom WebApplicationContext class [&quot; + contextClass.getName() +                &quot;] is not of type ConfigurableWebApplicationContext&quot;);    &#125;    ConfigurableWebApplicationContext wac =            (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);    wac.setEnvironment(getEnvironment());    wac.setParent(parent);    String configLocation = getContextConfigLocation();    if (configLocation != null) &#123;        wac.setConfigLocation(configLocation);\t// 持有 spring 配置文件    &#125;\t// 刷新配置和启动    configureAndRefreshWebApplicationContext(wac);    return wac;&#125;\n\n接着就是调用了 configureAndRefreshWebApplicationContext(wac); 方法，该方法对新构建的 ApplicationContext 进行了一定的配置，最后就是调用了 ApplicationContext 的刷新方法，这样我们需要的 spring 容器就算是正式启动了。在对 ApplicationContext 进行配置的过程中，我们需要一点就是 wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener())); 这行代码向 ApplicationContext 注册了一个监听器，那么在 ApplicationContext 的刷新启动过程中，将会触发该监听器的逻辑。\nprotected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) &#123;    if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123;        // The application context id is still set to its original default value        // -&gt; assign a more useful id based on available information        if (this.contextId != null) &#123;            wac.setId(this.contextId);        &#125;        else &#123;            // Generate default id...            wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX +                    ObjectUtils.getDisplayString(getServletContext().getContextPath()) + &#x27;/&#x27; + getServletName());        &#125;    &#125;    wac.setServletContext(getServletContext());    wac.setServletConfig(getServletConfig());    wac.setNamespace(getNamespace());    wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener()));    // The wac environment&#x27;s #initPropertySources will be called in any case when the context    // is refreshed; do it eagerly here to ensure servlet property sources are in place for    // use in any post-processing or initialization that occurs below prior to #refresh    ConfigurableEnvironment env = wac.getEnvironment();    if (env instanceof ConfigurableWebEnvironment) &#123;        ((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig());    &#125;    postProcessWebApplicationContext(wac);    applyInitializers(wac);    wac.refresh();&#125;\n\n定位到上边代码中所说的注册的那个监听器，代码如下，内容很简单，它根本是调用的 DispatcherServlet#initStrategies 方法，该方法中就是将 spring 容器中标签解析出来的那些 bean 逐个的添加到当前类，也就是 DispatcherServlet 中。这样在拦截到请求后就能够根据这些 bean 来完成相应的操作了，至此 springMVC 的启动流程分析就算完成。\nprivate class ContextRefreshListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123;    @Override    public void onApplicationEvent(ContextRefreshedEvent event) &#123;        FrameworkServlet.this.onApplicationEvent(event);    &#125;&#125;// 完成一些 bean 的填充，主要就是在我们的标签解析中得到的那些 bean，还有视图解析器protected void initStrategies(ApplicationContext context) &#123;    initMultipartResolver(context);    initLocaleResolver(context);    initThemeResolver(context);    initHandlerMappings(context);    initHandlerAdapters(context);    initHandlerExceptionResolvers(context);    initRequestToViewNameTranslator(context);    initViewResolvers(context);    initFlashMapManager(context);&#125;\n\n关于 DispatcherServlet 类，我们还要关注有哪些方法是实现或者重写的 sevlet 规范中的方法，我将它们列出来。FrameworkServlet#service、FrameworkServlet#doTrace、FrameworkServlet#doOptions、FrameworkServlet#doDelete、FrameworkServlet#doPut、FrameworkServlet#doPost、FrameworkServlet#doGet 这七个方法都是完成了对于父类方法的重写，如果对于 servlet 的执行流程比较清楚的话，那么不难知道当有请求来访问时，将会首先交给 service 方法处理，这是后边将要分析的内容，对于 DispatcherServlet 类，我们暂时知道这些就行。\n&lt;mvc:annotation-driven&#x2F;&gt; 标签解析在我们的 spring 配置文件中，指定了 &lt;mvc:annotation-driven&#x2F;&gt; 标签，虽然标签名好像有注解这个单词，但其实就源码分析的层面来看，跟注解时没有半点关系的。另外还有一个特殊的标签 &lt;context:component-scan&#x2F;&gt;，它跟 ioc 的实现有关，其实就是让 spring 容器自动扫面指定包下的组件，完成组件的注册，这里就不做分析了，仅仅关注 &lt;mvc:annotation-driven&#x2F;&gt; 标签。\n根据上两篇文章的分析，我们可以很轻松的知道该标签的解析是在 AnnotationDrivenBeanDefinitionParser#parse 方法中完成的，关于标签解析已经说得太多了，所做的事情都差不多，这里也不例外，只是注册的 bean 稍多，所以代码量也非常多，没有太多分析价值，这里就不贴代码了。只是将注册的 bean 列出来，不再一行行看，只要心里明白做了啥事情就行，这些 bean 中的很大一部分都是在上文指出的那个 ContextRefreshListener 监听器中被 DispatcherServlet 所持有，用来完成对于请求的处理。就本例而言，注入这么多 bean，并不是全部使用到，我们也是使用到啥就看啥。\n\nCompositeComponentDefinition\n\nRequestMappingHandlerMapping\t(用来获取 HandlerExecutionChain，Controller 的请求路径和方法的映射关系保存在其中)\n\nConfigurableWebBindingInitializer\n\nRequestMappingHandlerAdapter （用来验证 handler 是否可用）\n\nResponseStatusExceptionResolver\n\nCompositeUriComponentsContributorFactoryBean\n\nConversionServiceExposingInterceptor\n\nDefaultHandlerExceptionResolver\n\nMappedInterceptor\n\nExceptionHandlerExceptionResolver\n\nBeanNameUrlHandlerMapping\n\nRequestHandlerAdapter\t（用来验证 handler 是否可用）\n\nSimpleControllerHandlerAdapter\t（用来验证 handler 是否可用）\n\nHandlerMappingIntrospector\n\n\n请求处理流程上文中已经指出了 DispatcherServlet 类中，有七个方法重写了 servlet 规范类的方法，如果有请求消息，那么这个七个方法中的 FrameworkServlet#service 将会首先被调用。我们在其中打一个断点，通过 debug 的方式来对请求的流程进行跟踪。调用栈信息如下，可以知道现在程序时停在了我们的 FrameworkServlet#service 方法上，而它的上一个调用就是 HttpServlet#service 方法，这是 servlet 规范类中的方法，代码如下，可以知道它最后调用了它的一个重载方法，而我们的 DispatcherServlet 类对其进行了重写，所以现在执行的就是 FrameworkServlet#service 方法。\n\n\nServlet 调用栈信息\n\n\n\npublic void service(ServletRequest req, ServletResponse res)    throws ServletException, IOException &#123;    HttpServletRequest  request;    HttpServletResponse response;    try &#123;        request = (HttpServletRequest) req;        response = (HttpServletResponse) res;    &#125; catch (ClassCastException e) &#123;        throw new ServletException(lStrings.getString(&quot;http.non_http&quot;));    &#125;    service(request, response);&#125;\n\nFrameworkServlet#service 方法中的内容如下，它优先对方法的请求类型进行了判断，如果是 HttpMethod.PATCH 方法，那么就会执行 if 分支，否则执行 else 分支。本例中走 else 分支，可以看到它又调用了被重写的方法。\n@Overrideprotected void service(HttpServletRequest request, HttpServletResponse response)        throws ServletException, IOException &#123;    HttpMethod httpMethod = HttpMethod.resolve(request.getMethod());    if (httpMethod == HttpMethod.PATCH || httpMethod == null) &#123;        processRequest(request, response);\t// 针对 PATCH 请求的处理    &#125;    else &#123;        super.service(request, response);    &#125;&#125;\n\n我们大致看看这个被重写的方法的实现，内容如下，可以看到就是七个分支，对应七种请求，而我们的 DispatcherServlet 完成了对其中六种方法的重写，对应本例来说，我们的请求是 GET 方式，所以就会走 METHOD_GET 分支，可以看到其根本还是调用了 doGet 方法，我们对其完成了重写，所以接下来就会执行到我们的 FrameworkServlet#doGet 方法。\n protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123;    String method = req.getMethod();    if (method.equals(METHOD_GET)) &#123;        long lastModified = getLastModified(req);        if (lastModified == -1) &#123;            // servlet doesn&#x27;t support if-modified-since, no reason            // to go through further expensive logic            doGet(req, resp);        &#125; else &#123;            long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE);            if (ifModifiedSince &lt; lastModified) &#123;                // If the servlet mod time is later, call doGet()                // Round down to the nearest second for a proper compare                // A ifModifiedSince of -1 will always be less                maybeSetLastModified(resp, lastModified);                doGet(req, resp);            &#125; else &#123;                resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED);            &#125;        &#125;    &#125; else if (method.equals(METHOD_HEAD)) &#123;        long lastModified = getLastModified(req);        maybeSetLastModified(resp, lastModified);        doHead(req, resp);    &#125; else if (method.equals(METHOD_POST)) &#123;        doPost(req, resp);            &#125; else if (method.equals(METHOD_PUT)) &#123;        doPut(req, resp);            &#125; else if (method.equals(METHOD_DELETE)) &#123;        doDelete(req, resp);            &#125; else if (method.equals(METHOD_OPTIONS)) &#123;        doOptions(req,resp);            &#125; else if (method.equals(METHOD_TRACE)) &#123;        doTrace(req,resp);            &#125; else &#123;        //        // Note that this means NO servlet supports whatever        // method was requested, anywhere on this server.        //        String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;);        Object[] errArgs = new Object[1];        errArgs[0] = method;        errMsg = MessageFormat.format(errMsg, errArgs);                resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg);    &#125;&#125;\n\nFrameworkServlet#doGet 方法根本又是调用的 FrameworkServlet#processRequest 方法，可以看到前半部分都是一些准备操作，我没有去细看都准备了哪些内容，感兴趣可以自行分析。完成相关信息的准备后，就是执行 doService(request, response); 这句代码。里边大部分都是准备工作，就是向参数 HttpServletRequest 中添加了一些属性，而属性值就是来自于 DispatcherServlet，知道这点后我们继续跟进，可以看到就是调用了 DispatcherServlet#doDispatch 方法。\nprotected final void processRequest(HttpServletRequest request, HttpServletResponse response)\t\t\tthrows ServletException, IOException &#123;    long startTime = System.currentTimeMillis();    Throwable failureCause = null;    LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext();    LocaleContext localeContext = buildLocaleContext(request);\t// 根据 request 构建 LocaleContext，里边包含了一些请求相关的信息    RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes();    ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes);\t// 其实就是封装了 request 和 response    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);    asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());\t// 注册了一个绑定拦截器    // 将 LocaleContext 和 RequestAttributes 分别保存到 LocaleContextHolder 和 RequestContextHolder    initContextHolders(request, localeContext, requestAttributes);    try &#123;        doService(request, response);    &#125;    catch (ServletException | IOException ex) &#123;        failureCause = ex;        throw ex;    &#125;    catch (Throwable ex) &#123;        failureCause = ex;        throw new NestedServletException(&quot;Request processing failed&quot;, ex);    &#125;    finally &#123;        resetContextHolders(request, previousLocaleContext, previousAttributes);        if (requestAttributes != null) &#123;            requestAttributes.requestCompleted();        &#125;        logResult(request, response, failureCause, asyncManager);        publishRequestHandledEvent(request, response, startTime, failureCause);\t// 完成事件的通知    &#125;&#125;\n\nDispatcherServlet#doDispatch 方法的内容如下，它可以算是 springMVC 的核心逻辑实现。为了节省篇幅我将异常捕获和 finally 代码块去掉了，感兴趣的可以自行分析，不影响我们分析 spirngMVC 的实现逻辑。第一个要注意的代码就是 checkMultipart(request); 根据我的理解，它应该是跟文件上传时的处理有关，本例不会涉及，只需要知道这个点就行，用到了可以再深入去看。\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;    HttpServletRequest processedRequest = request;    HandlerExecutionChain mappedHandler = null;    boolean multipartRequestParsed = false;    // 获取 request 中的 WebAsyncManager    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);    try &#123;        ModelAndView mv = null;        Exception dispatchException = null;        try &#123;            processedRequest = checkMultipart(request);\t// 如果指定了 Multipart 处理器，进行处理            multipartRequestParsed = (processedRequest != request);\t// 是否被 multipart 处理的标志            // 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethod，再构建 execution chain 返回            // Determine handler for the current request.            mappedHandler = getHandler(processedRequest);            if (mappedHandler == null) &#123;                noHandlerFound(processedRequest, response);                return;            &#125;            // Determine handler adapter for the current request.            HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());            // Process last-modified header, if supported by the handler.            String method = request.getMethod();            boolean isGet = &quot;GET&quot;.equals(method);            if (isGet || &quot;HEAD&quot;.equals(method)) &#123;\t// Get 或者 HEAD 方法                long lastModified = ha.getLastModified(request, mappedHandler.getHandler());                if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123;                    return;                &#125;            &#125;            // 调用拦截器的前置处理器            if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123;                return;            &#125;            // 核心就是获取 ModelAndView，模型来自用户执行逻辑的代码，视图也是            // Actually invoke the handler.            mv = ha.handle(processedRequest, response, mappedHandler.getHandler());            if (asyncManager.isConcurrentHandlingStarted()) &#123;                return;            &#125;            applyDefaultViewName(processedRequest, mv);            mappedHandler.applyPostHandle(processedRequest, response, mv);\t// 应用后置处理器        &#125;        catch (Exception ex) &#123;            dispatchException = ex;        &#125;        catch (Throwable err) &#123;            // As of 4.3, we&#x27;re processing Errors thrown from handler methods as well,            // making them available for @ExceptionHandler methods and other scenarios.            dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err);        &#125;\t// 处理分发结果        processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);    &#125;&#125;\n\n第二个要留意的点就是 getHandler(processedRequest); 方法的执行，它的实现如下，从方法的主干来看就是从 handlerMappings 中获取 HandlerExecutionChain，如果结果不为 null，就直接返回。那么 handlerMappings 中都是啥呢？通过 debug，我将里边的内容展示出来，可以看到它就是我们在标签解析中注册到 spring 容器中的 bean，所以我们这里也就能知道他们是用来获取对应的 HandlerExecutionChain。继续跟进去，看是如何得到 HandlerExecutionChain 的。\n@Nullable\t// 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethod，再构建 execution chain 返回protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123;    if (this.handlerMappings != null) &#123;        for (HandlerMapping mapping : this.handlerMappings) &#123;            HandlerExecutionChain handler = mapping.getHandler(request);            if (handler != null) &#123;\t// 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethod，再构建 execution chain 返回                return handler;            &#125;        &#125;    &#125;    return null;&#125;\n\n\n\nhandlerMappings 集合的内容\n\n\n\n上边的 handlerMappings 集合中有两个实例，首先处理第一个，也就是 RequestMappingHandlerMapping 实例，代码如下。\n@Nullable\t// 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethod，再构建 execution chain 返回public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123;    Object handler = getHandlerInternal(request);\t// 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethod    if (handler == null) &#123;        handler = getDefaultHandler();    &#125;    if (handler == null) &#123;        return null;    &#125;    // Bean name or resolved handler?    if (handler instanceof String) &#123;        String handlerName = (String) handler;        handler = obtainApplicationContext().getBean(handlerName);    &#125;    // 将 handler 构建为 chain，同时加入了标签解析时注册的 MappedInterceptor 中的 interceptor    HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request);    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Mapped to &quot; + handler);    &#125;    else if (logger.isDebugEnabled() &amp;&amp; !request.getDispatcherType().equals(DispatcherType.ASYNC)) &#123;        logger.debug(&quot;Mapped to &quot; + executionChain.getHandler());    &#125;    if (hasCorsConfigurationSource(handler)) &#123;        CorsConfiguration config = (this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(request) : null);        CorsConfiguration handlerConfig = getCorsConfiguration(handler, request);        config = (config != null ? config.combine(handlerConfig) : handlerConfig);        executionChain = getCorsHandlerExecutionChain(request, executionChain, config);    &#125;    return executionChain;&#125;\n\n第一句就是获取 handler 对吧，它根本是调用的 AbstractHandlerMethodMapping#getHandlerInternal 方法，我将代码贴在下边了。第一句是得到了 lookupPath，根据方法名可以知道就是一个通过 UrlPathHelper 获取 HttpServletRequest 对应的 LookupPath 的过程，我们不必深究，只需要看其结果如下图，可以知道就是我们请求的链接路径信息对吗？好，拿到这个路径信息后，第二行代码将其填充到了 HttpServletRequest 的属性中了。再接着就是执行 lookupHandlerMethod(lookupPath, request); 这行代码。\n\norg.springframework.web.servlet.handler.AbstractHandlerMethodMapping#getHandlerInternal\n\n@Override // 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethodprotected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123;    String lookupPath = getUrlPathHelper().getLookupPathForRequest(request);    request.setAttribute(LOOKUP_PATH, lookupPath);    this.mappingRegistry.acquireReadLock();    try &#123;\t// 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethod        HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request);        return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null);    &#125;    finally &#123;        this.mappingRegistry.releaseReadLock();    &#125;&#125;\n\n\n\nlookupPath 的内容\n\n\n\nlookupHandlerMethod(lookupPath, request); 方法又有点长，但逻辑还算清晰，首先我们创建了一个 List 集合，元素是 Match 类。接着执行 addMatchingMappings(directPathMatches, matches, request); 这行代码，里边的代码内容不再贴了，核心逻辑就是从 directPathMatches 中获取和 request 匹配的项，然后将得到的匹配项封装为 Match 实例，再追加到 List 集合中，那么这个集合中存放的信息是啥呢？？我把内容贴出来，可以看出来其实里边存放的不就是当前请求对应的 controller 类的对应方法吗？？知道这点后，那么后边的代码又是干啥呢？？其实只需要根据 Match bestMatch = matches.get(0); 这句代码就能猜出意思来了，也就是说获取的 matches 集合可能不止一个 Match 元素，那么在对其按照一定规则完成排序后，第一个元素就是最匹配项项，我们根本也就是要拿到这个 Match 实例，最后再通过 return bestMatch.handlerMethod; 这句代码返回最佳匹配项的 handlerMethod，里边有当前请求对应的 controller 的方法信息。\n@Nullable\t// 根据 lookupPath 获取 matches 集合，对其按照匹配度排序，拿到最匹配的项，获取其中的 HandlerMethodprotected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123;    List&lt;Match&gt; matches = new ArrayList&lt;&gt;();    List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath);\t// 根据 lookupPath 获取 matches 集合    if (directPathMatches != null) &#123;        addMatchingMappings(directPathMatches, matches, request);    &#125;    if (matches.isEmpty()) &#123;        // No choice but to go through all mappings...        addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request);    &#125;    if (!matches.isEmpty()) &#123;        Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request));        matches.sort(comparator);\t// 对 matches 集合进行排序        Match bestMatch = matches.get(0);\t// 获取最匹配的项        if (matches.size() &gt; 1) &#123;            if (logger.isTraceEnabled()) &#123;                logger.trace(matches.size() + &quot; matching mappings: &quot; + matches);            &#125;            if (CorsUtils.isPreFlightRequest(request)) &#123;                return PREFLIGHT_AMBIGUOUS_MATCH;            &#125;            Match secondBestMatch = matches.get(1);            if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123;                Method m1 = bestMatch.handlerMethod.getMethod();                Method m2 = secondBestMatch.handlerMethod.getMethod();                String uri = request.getRequestURI();                throw new IllegalStateException(                        &quot;Ambiguous handler methods mapped for &#x27;&quot; + uri + &quot;&#x27;: &#123;&quot; + m1 + &quot;, &quot; + m2 + &quot;&#125;&quot;);            &#125;        &#125;        request.setAttribute(BEST_MATCHING_HANDLER_ATTRIBUTE, bestMatch.handlerMethod);        handleMatch(bestMatch.mapping, lookupPath, request);        return bestMatch.handlerMethod;\t// 拿到最匹配项的 HandlerMethod    &#125;    else &#123;        return handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request);    &#125;&#125;\n\n\n\nmatches 集合的内容\n\n\n\n拿到这个 handler 后，我们退回到构建 HandlerExecutionChain 的方法，即 AbstractHandlerMapping#getHandler 中。既然是构建 ExecutionChain，那自然不会只有一个 handler 吧，这一步就是通过该方法中的 getHandlerExecutionChain(handler, request); 这行代码完成的。里边就是将获取的 handler 构建为 chain，同时加入了标签解析时注册的 MappedInterceptor 中的 interceptor。代码就不再贴了，自行查看即可。得到这个 HandlerExecutionChain，后边的内容基本没有啥紧要的操作，然后就是返回这个 HandlerExecutionChain。\n再回到我们获取 HandlerExecutionChain 的入口处，即 DispatcherServlet#doDispatch 方法的 getHandler(processedRequest); 这行代码，返回结果就是我们的 HandlerExecutionChain，紧接着又调用了 getHandlerAdapter(mappedHandler.getHandler()); 这行代码，里边的实现如下，核心逻辑就是遍历 handlerAdapters 集合，从中获取出能够和参数 handler 匹配的处理器适配器，那么这个 handlerAdapters 中都有哪些适配器呢？我将内容通过下图展示出来，可以看到其中的两项都是我们在标签解析中注册的 bean。具体的匹配逻辑也就不深入看了，直接返回，可以知道本例中，得到的是 RequestMappingHandlerAdapter 实例。\nprotected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123;    if (this.handlerAdapters != null) &#123;        for (HandlerAdapter adapter : this.handlerAdapters) &#123;            if (adapter.supports(handler)) &#123;                return adapter;            &#125;        &#125;    &#125;    throw new ServletException(&quot;No adapter for handler [&quot; + handler +            &quot;]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler&quot;);&#125;\n\n\n\nhandlerAdapters 集合的内容\n\n\n\n再往下走就是 applyPreHandle(processedRequest, response) 这行代码，这里就是对于得到的 HandlerExecutionChain 调用前置处理方法，属于功能拓展部分，大致理解就好。然后就是 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); 这句，mv 代表就是 springMVC 概念中的 model 和 view。\n该方法根本还是调用的下边这个方法，该方法大部分内容都是进行的一些准备工作，这也不是我们应该关注的内容，只需要注意其中的两个核心逻辑，第一个就是 invokeAndHandle(webRequest, mavContainer); 这句。\n@Nullable\t// 核心就是获取 ModelAndView，模型来自用户执行逻辑的代码，视图也是protected ModelAndView invokeHandlerMethod(HttpServletRequest request,        HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123;    ServletWebRequest webRequest = new ServletWebRequest(request, response);    try &#123;\t// 数据绑定工厂        WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod);        ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory);\t// 模型工厂        // 根据 HandlerMethod 构建 ServletInvocableHandlerMethod        ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);        if (this.argumentResolvers != null) &#123;\t// 参数方法解析器填充到 ServletInvocableHandlerMethod            invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);        &#125;        if (this.returnValueHandlers != null) &#123;\t// 返回值处理器添加到 ServletInvocableHandlerMethod            invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);        &#125;        invocableMethod.setDataBinderFactory(binderFactory);\t// 设置数据绑定工厂        invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer);\t// 参数名发现器        ModelAndViewContainer mavContainer = new ModelAndViewContainer();\t// 模型视图容器        mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request));        modelFactory.initModel(webRequest, mavContainer, invocableMethod);        mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect);        // 异步 web 请求        AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);        asyncWebRequest.setTimeout(this.asyncRequestTimeout);        // web 异步管理器        WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);        asyncManager.setTaskExecutor(this.taskExecutor);        asyncManager.setAsyncWebRequest(asyncWebRequest);        asyncManager.registerCallableInterceptors(this.callableInterceptors);        asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);        if (asyncManager.hasConcurrentResult()) &#123;            Object result = asyncManager.getConcurrentResult();            mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0];            asyncManager.clearConcurrentResult();            LogFormatUtils.traceDebug(logger, traceOn -&gt; &#123;                String formatted = LogFormatUtils.formatValue(result, !traceOn);                return &quot;Resume with async result [&quot; + formatted + &quot;]&quot;;            &#125;);            invocableMethod = invocableMethod.wrapConcurrentResult(result);        &#125;        // 触发用户 bean 的对应方法，完成对于返回结果的处理        invocableMethod.invokeAndHandle(webRequest, mavContainer);        if (asyncManager.isConcurrentHandlingStarted()) &#123;            return null;        &#125;        // 返回模型和视图        return getModelAndView(mavContainer, modelFactory, webRequest);    &#125;    finally &#123;        webRequest.requestCompleted();    &#125;&#125;\n\ninvokeAndHandle(webRequest, mavContainer); 实现如下，总的来说也只有两个核心逻辑，首先是 invokeForRequest(webRequest, mavContainer, providedArgs); 这句代码，它根本是调用了用户的逻辑代码，返回的就是对应方法的返回值，就本例而言，我们返回的是一个 ModelAndView 实例，调用的过程很简单，是通过反射方式进行的，不再给出代码，自行跟踪即可，然后就是对于这个返回结果来进行处理，它体现在 returnValueHandlers.handleReturnValue 这句。\n// 触发用户 bean 的对应方法，完成对于返回结果的处理public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,        Object... providedArgs) throws Exception &#123;    // 触发用户 bean 的对应方法    Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);    setResponseStatus(webRequest);    if (returnValue == null) &#123;        if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123;            disableContentCachingIfNecessary(webRequest);            mavContainer.setRequestHandled(true);            return;        &#125;    &#125;    else if (StringUtils.hasText(getResponseStatusReason())) &#123;        mavContainer.setRequestHandled(true);        return;    &#125;    mavContainer.setRequestHandled(false);    Assert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;);    try &#123;        this.returnValueHandlers.handleReturnValue(                returnValue, getReturnValueType(returnValue), mavContainer, webRequest);    &#125;    catch (Exception ex) &#123;        if (logger.isTraceEnabled()) &#123;            logger.trace(formatErrorForReturnValue(returnValue), ex);        &#125;        throw ex;    &#125;&#125;\n\nreturnValueHandlers.handleReturnValue 方法的实现如下，里边执行了 selectHandler 方法，选择的是啥呢？？注意我们现在是调用的 returnValueHandlers 的方法，所以通过查看 returnValueHandlers 实例的内容就能知道是对什么进行选择。从下图我们知道，该实例持有了 15 个 handler，那么可以想到 selectHandler 方法就是从这个 15 个 handler 中选择能够对参数 returnValue 进行处理的合适的 handler 了。换句话来说，我们的用户代码这里返回的是 ModelAndView 实例，那么 selectHandler 方法就是从 15 个 handler 中选择一个能够对 ModelAndView 实例进行处理 handler。拿到这个 handler 后，就是对用户代码的结果进行处理，本例中拿到的 handler 是 ModelAndViewMethodReturnValueHandler 实例，接着看它的 handleReturnValue 方法。\n@Override\t// 根据 MethodParameter 从 returnValueHandlers 中选择合适的 handler，使用获得的 handler 处理响应结果public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,        ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123;    // 根据 MethodParameter 从 returnValueHandlers 中选择合适的 handler    HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType);    if (handler == null) &#123;        throw new IllegalArgumentException(&quot;Unknown return value type: &quot; + returnType.getParameterType().getName());    &#125;\t// 使用获得的 handler 处理响应结果    handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);&#125;\n\n\n\nreturnValueHandlers 集合的内容\n\n\n\nModelAndViewMethodReturnValueHandler#handleReturnValue 方法的实现如下，总的来说就是对参数 mavContainer 进行了各项属性的设置，拿本例来说，重要的属性就两个，setViewName(viewName) 方法是设置的视图名字 “userlist”，addAllAttributes(mav.getModel()) 方法设置的是模型信息，本例的内容见下图，这样通过 Handler 对用户代码返回结果进行处理的逻辑就很清楚了。记住一点，模型和视图信息都保存到了参数的 ModelAndViewContainer 中，好了我们逐步返回，看看这个 ModelAndViewContainer 哪里被使用。\n@Overridepublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,        ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123;    if (returnValue == null) &#123;        mavContainer.setRequestHandled(true);        return;    &#125;    ModelAndView mav = (ModelAndView) returnValue;    if (mav.isReference()) &#123;        String viewName = mav.getViewName();        mavContainer.setViewName(viewName);        if (viewName != null &amp;&amp; isRedirectViewName(viewName)) &#123;            mavContainer.setRedirectModelScenario(true);        &#125;    &#125;    else &#123;        View view = mav.getView();        mavContainer.setView(view);        if (view instanceof SmartView &amp;&amp; ((SmartView) view).isRedirectView()) &#123;            mavContainer.setRedirectModelScenario(true);        &#125;    &#125;    mavContainer.setStatus(mav.getStatus());    mavContainer.addAllAttributes(mav.getModel());&#125;\n\n\n\n模型的内容\n\n\n\n回退的位置就是 RequestMappingHandlerAdapter#invokeHandlerMethod 方法的 invokeAndHandle(webRequest, mavContainer); 这行代码处，我们在这里边完成了用户代码逻辑的调用，同时又通过 handler 完成了对于返回结果的处理，最终就是将模型和视图信息保存到了 ModelAndViewContainer。再往下走就是 getModelAndView(mavContainer, modelFactory, webRequest); 这句，参数 mavContainer 中此时已经持有了我们的模型和视图信息，跟进去看看做了啥操作。代码如下，细节也不管了，可以知道核心就是构建了一个 ModelAndView 实例，然后将 ModelAndViewContainer 中的模型和视图信息都填充到了新构建的 ModelAndView 中返回。既然返回，我们就只需要不断地后退，看在哪里会使用我们现在得到的这个 ModelAndView，其结果是 DispatcherServlet#doDispatch 方法的 ha.handle(processedRequest, response, mappedHandler.getHandler()); 这行代码处，也就是说我们是通过最初得到的处理器适配器来得到 ModelAndView 实例的。紧接着再调用 HandlerExecutionChain 的后置处理方法，思想跟前置处理方法差不多，了解就好。接着就是使用这个我们好不容易得到的 ModelAndView 实例了，它在 DispatcherServlet#processDispatchResult 方法中完成，该方法做了很多附加操作，但核心其实就只有 render(mv, request, response); 这一句。\n@Nullableprivate ModelAndView getModelAndView(ModelAndViewContainer mavContainer,        ModelFactory modelFactory, NativeWebRequest webRequest) throws Exception &#123;    modelFactory.updateModel(webRequest, mavContainer);    if (mavContainer.isRequestHandled()) &#123;        return null;    &#125;    ModelMap model = mavContainer.getModel();\t// 模型 map，里边存放的是，数据 key 和数据 value    ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model, mavContainer.getStatus());\t// ModelAndView 里边包含了模型和视图信息    if (!mavContainer.isViewReference()) &#123;        mav.setView((View) mavContainer.getView());    &#125;    if (model instanceof RedirectAttributes) &#123;        Map&lt;String, ?&gt; flashAttributes = ((RedirectAttributes) model).getFlashAttributes();        HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class);        if (request != null) &#123;            RequestContextUtils.getOutputFlashMap(request).putAll(flashAttributes);        &#125;    &#125;    return mav;&#125;\n\nrender 方法具体的实现如下，核心逻辑就只有两个，获取视图实例，然后使用该实例进行渲染。先看视图实例如何获取吧。\n */\t// 尝试根据环境中的视图解析器来创建视图，优先从缓存中获取视图，如果没有的话，进行创建（判断视图名字，redirect: 和 forward: 单独处理，否则获取设置的 view class 对应的视图实例，完成相关信息的设置，应用生命周期方法返回）并返回。protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123;\t// 获取全部的模型，将模型以参数的形式添加到 request 中，拿到跳转的路径，获取 RequestDispatcher，进行请求转发    // Determine locale for request and apply it to the response.    Locale locale =\t// 地区信息            (this.localeResolver != null ? this.localeResolver.resolveLocale(request) : request.getLocale());    response.setLocale(locale);    View view;    String viewName = mv.getViewName();\t// 视图名字    if (viewName != null) &#123;        // We need to resolve the view name.        view = resolveViewName(viewName, mv.getModelInternal(), locale, request);        if (view == null) &#123;\t// 尝试根据环境中的视图解析器来创建视图，优先从缓存中获取视图，如果没有的话，进行创建（判断视图名字，redirect: 和 forward: 单独处理，否则获取设置的 view class 对应的视图实例，完成相关信息的设置，应用生命周期方法返回）并返回。            throw new ServletException(&quot;Could not resolve view with name &#x27;&quot; + mv.getViewName() +                    &quot;&#x27; in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;);        &#125;    &#125;    else &#123;        // No need to lookup: the ModelAndView object contains the actual View object.        view = mv.getView();        if (view == null) &#123;            throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a &quot; +                    &quot;View object in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;);        &#125;    &#125;    // Delegate to the View object for rendering.    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Rendering view [&quot; + view + &quot;] &quot;);    &#125;    try &#123;        if (mv.getStatus() != null) &#123;            response.setStatus(mv.getStatus().value());        &#125;\t// 获取全部的模型，将模型以参数的形式添加到 request 中，拿到跳转的路径，获取 RequestDispatcher，进行请求转发        view.render(mv.getModelInternal(), request, response);    &#125;    catch (Exception ex) &#123;        if (logger.isDebugEnabled()) &#123;            logger.debug(&quot;Error rendering view [&quot; + view + &quot;]&quot;, ex);        &#125;        throw ex;    &#125;&#125;\n\n视图实例获取是在 DispatcherServlet#resolveViewName 方法中完成的，差不多就是通过视图解析器完成的，本例中视图解析器只有一个就是 spring 配置文件中给出的那个 InternalResourceViewResolver。它是如何获取我们需要的视图实例的代码，本文就不在深究了，但是在我的源码中，还是有添加一些注释，感兴趣的可以自己了解，这里只给出我们获取的视图实例类型为 JstlView。\n获取视图实例只是上边 DispatcherServlet#render 方法的第一个核心逻辑，第二个就是通过现在获取的这个 JstlView 视图实例来完成渲染操作，它根本是调用的 InternalResourceView#renderMergedOutputModel 方法。\n@Nullable\t// 尝试根据环境中的视图解析器来创建视图，优先从缓存中获取视图，如果没有的话，进行创建（判断视图名字，redirect: 和 forward: 单独处理，否则获取设置的 view class 对应的视图实例，完成相关信息的设置，应用生命周期方法返回）并返回。protected View resolveViewName(String viewName, @Nullable Map&lt;String, Object&gt; model,        Locale locale, HttpServletRequest request) throws Exception &#123;    if (this.viewResolvers != null) &#123;        for (ViewResolver viewResolver : this.viewResolvers) &#123;            View view = viewResolver.resolveViewName(viewName, locale);            if (view != null) &#123;\t// 尝试从缓存中获取视图，如果没有的话，进行创建（判断视图名字，redirect: 和 forward: 单独处理，否则获取设置的 view class 对应的视图实例，完成相关信息的设置，应用生命周期方法返回）并返回。                return view;            &#125;        &#125;    &#125;    return null;&#125;\n\nInternalResourceView#renderMergedOutputModel 方法代码实现如下，根据我们使用原生 servlet 的经验，这段代码中，我们应该关注的就三个，第一就是 exposeModelAsRequestAttributes(model, request); 这句代码是将模型信息填充到 HttpServletRequest 的属性中，这样 jsp 页面能够通过相应的语法来完成值的获取。第二个就是 RequestDispatcher rd = getRequestDispatcher(request, dispatcherPath); 这句代码，注意这里的 dispatcherPath，它的值是 /WEB-INF/jsp/userlist.jsp 这个正好就是 controller 中指定的视图名称对应的 jsp 页面，我们的原生 servlet 使用过程中也是让 RequestDispatcher 持有了 jsp 的路径信息。最后就是 rd.forward(request, response); 这行代码的调用，内部的逻辑已经不属于我们分析的范畴了，但是我们可以知道这句执行完成后就会通过 jsp 生成 servlet，然后完成响应信息到客户端的发送。这样整个 springMVC 的执行流程就算分析完毕了。\n@Override\t// 将模型以参数的形式添加到 request 中，拿到跳转的路径，获取 RequestDispatcher，进行请求转发protected void renderMergedOutputModel(        Map&lt;String, Object&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123;    // Expose the model object as request attributes.    exposeModelAsRequestAttributes(model, request);\t// 将模型全部添加到 request 属性中    // Expose helpers as request attributes, if any.    exposeHelpers(request);    // Determine the path for the request dispatcher.    String dispatcherPath = prepareForRendering(request, response);    // Obtain a RequestDispatcher for the target resource (typically a JSP).    RequestDispatcher rd = getRequestDispatcher(request, dispatcherPath);    if (rd == null) &#123;        throw new ServletException(&quot;Could not get RequestDispatcher for [&quot; + getUrl() +                &quot;]: Check that the corresponding file exists within your web application archive!&quot;);    &#125;    // If already included or response already committed, perform include, else forward.    if (useInclude(request, response)) &#123;        response.setContentType(getContentType());        if (logger.isDebugEnabled()) &#123;            logger.debug(&quot;Including [&quot; + getUrl() + &quot;]&quot;);        &#125;        rd.include(request, response);    &#125;    else &#123;        // Note: The forwarded resource is supposed to determine the content type itself.        if (logger.isDebugEnabled()) &#123;            logger.debug(&quot;Forwarding to [&quot; + getUrl() + &quot;]&quot;);        &#125;        rd.forward(request, response);\t// 这里就是进行请求转发了，也就是跳转到我们指定的那个视图    &#125;&#125;\n\n整个的 springMVC 请求处理过程还算是很长的，这里进行一下总结，首先我们的 DispatcherServlet 重写了 HttpServlet 的 service 方法，那么在收到请求时，首先会调用该方法，而该方法实际又是调用了父类 HttpServlet 中的 service 方法，在该方法中，它会根据请求的类型来判断调用那个 doXXX 方法。我们的 DispatcherServlet 完成了对 doXXX 方法的重写，所以根本还是会调用 DispatcherServlet 的 doXXX 重写方法。就本例而言，我们是调用的 doGet 方法，此方法根本是调用的 DispatcherServlet#doDispatch 方法，在该方法中，我们会首先根据 request 信息从处理器映射集合中得到合适的处理器映射器，再从处理器映射器保存的处理器信息中获取最佳的处理器。接着就是根据获得的处理器来得到匹配的处理器适配器，利用这个处理器适配器，我们完成了用户代码的调用，对于调用返回的结果，我们选择了合适的返回值处理器完成了对于结果的处理，就本例而言，我们的结果处理器就是将结果的模型和视图信息填充到了 ModelAndViewContainer 中。接着就是根据 ModelAndViewContainer 构建 ModelAndView 实例，拿到这个 ModelAndView 实例后进行渲染操作，核心逻辑就两个，得到合适的视图实例，然后通过该实例完成渲染操作，以上就是整个 springMVC 的执行流程。\n","categories":["源码分析"],"tags":["Spring","SpringMVC"]}]